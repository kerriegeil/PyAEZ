{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook I - Climate Regime\n",
    "<hr>\n",
    "This module performs climate data analysis and compiling general agro-climatic indicators. These general agro-climatic indicators summarize climatic profiles in the study area for each grid. The key input data for this module is the climatic data, and the geographical and terrain data.\n",
    "\n",
    "Prepared by Geoinformatics Center, AIT\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google drive connection\n",
    "In this step, we will connect to Google Drive service and mount the drive where we will start our PyAEZ project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, installing any additional python packages that required to run PyAEZ.\n",
    "If working on your own PC/machine, these additional installation will vary depending on what is already installed in your Python library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Installing neccessary packages'\n",
    "# !pip install gdal\n",
    "# # !pip install pyaez==2.0.0\n",
    "\n",
    "\n",
    "# K:\\projects\\unfao\\pyaez_gaez\\repos\\PyAEZ_kerrie\\PyAEZ\\pyaez_v2.1_2023JUL10\\NB1_ClimateRegime_v2_1_China.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will import the specific Python packages we need for PyAEZ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import supporting libraries'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "import os\n",
    "try:\n",
    "    from osgeo import gdal\n",
    "except:\n",
    "    import gdal\n",
    "import sys\n",
    "\n",
    "from time import time as timer\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray as rio\n",
    "\n",
    "import dask.array as da\n",
    "import dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the working directory -- where our PyAEZ project is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# branch version tag\n",
    "revname='v21pv'\n",
    "\n",
    "# # HPC Orion\n",
    "# # Replace with path to your PyAEZ folder under your username\n",
    "# work_dir = '/work/hpc/users/kerrie/UN_FAO/repos/PyAEZ/pyaez2.1_vectorize/'\n",
    "# # Replace with whatever location you want to output data under your username\n",
    "# out_path = '/work/hpc/users/kerrie/UN_FAO/pyaez_results/china_8110/'+revname+'/' \n",
    "# # these are the same for everyone on HPC Orion\n",
    "# data_dir = '/work/hpc/datasets/un_fao/pyaez/china_8110/daily/npy/'\n",
    "# maskfile = '/work/hpc/datasets/un_fao/pyaez/china_static/netcdf/mask.nc'\n",
    "# elevfile = '/work/hpc/datasets/un_fao/pyaez/china_static/tif/elev.tif'\n",
    "\n",
    "\n",
    "# # Kerrie desktop\n",
    "# work_dir = 'K:/projects/unfao/pyaez_gaez/repos/PyAEZ_kerrie/PyAEZ/pyaez2.1_parvec/' # path to your PyAEZ repo\n",
    "# out_path = work_dir+'NB1outputs/' # path for saving output data\n",
    "# data_dir = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_china_03272023/npy/' # path to your data\n",
    "# maskfile = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_china_03272023/tif/mask.tif'# subset for no antarctica, 1800 lats\n",
    "# elevfile = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_china_03272023/tif/elev.tif'\n",
    "\n",
    "# work_dir = 'K:/projects/unfao/pyaez_gaez/repos/PyAEZ_kerrie/PyAEZ/pyaez2.1_parvec/' # path to your PyAEZ repo\n",
    "# out_path = work_dir+'NB1outputs/' # path for saving output data\n",
    "# data_dir = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_global_NOTPRODUCTION/npy/' # path to your data\n",
    "# maskfile = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_global_NOTPRODUCTION/tif/mask_2268708_5m.tif'# subset for no antarctica, 1800 lats\n",
    "# elevfile = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_global_NOTPRODUCTION/tif/Elevation_2268708_5m.tif'\n",
    "\n",
    "\n",
    "# # # Kerrie laptop china\n",
    "# work_dir = 'C://Users/kerrie/Documents/01_LocalCode/repos/PyAEZ/pyaez2.1_parvec/' # path to your PyAEZ repo\n",
    "# out_path = work_dir+'NB1outputs/' # path for saving output data\n",
    "# # data_dir = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/china/npy/' # path to your data\n",
    "# # maskfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/china/tif/mask.tif'# subset for no antarctica, 1800 lats\n",
    "# # elevfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/china/tif/elev.tif'\n",
    "# data_dir = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/5GB/' # path to your data\n",
    "# maskfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/5GB/mask.tif'# subset for no antarctica, 1800 lats\n",
    "# elevfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/5GB/elev.tif'\n",
    "\n",
    "# Kerrie laptop global\n",
    "work_dir = 'C://Users/kerrie/Documents/01_LocalCode/repos/PyAEZ/pyaez2.1_parvec/' # path to your PyAEZ repo\n",
    "out_path = work_dir+'NB1outputs/' # path for saving output data\n",
    "data_dir = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/global_NOTPRODUCTION/npy/' # path to your data\n",
    "maskfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/global_NOTPRODUCTION/tif/mask_2268708_5m.tif'# subset for no antarctica, 1800 lats\n",
    "elevfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/global_NOTPRODUCTION/tif/Elevation_2268708_5m.tif'\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(out_path)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(out_path)\n",
    "   print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## MODULE 1: CLIMATE REGIME\n",
    "Now, we will start executing the routines in Module 1\n",
    "\n",
    "\n",
    "First, we initiate Module 1 Class instance by invoking the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# Import Module 1 and initate Class intance\n",
    "# from pyaez import ClimateRegime\n",
    "# clim_reg = ClimateRegime.ClimateRegime()\n",
    "\n",
    "# # Importing UtilitiesCalc\n",
    "# from pyaez import UtilitiesCalc\n",
    "# obj_util = UtilitiesCalc.UtilitiesCalc()\n",
    "sys.path.append(work_dir)\n",
    "import ClimateRegime_v21pv as ClimateRegime\n",
    "clim_reg = ClimateRegime.ClimateRegime()\n",
    "\n",
    "import UtilitiesCalc_v21pv as UtilitiesCalc\n",
    "obj_utilities=UtilitiesCalc.UtilitiesCalc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the climate dataset and the geographical data/rasters.\n",
    "\n",
    "The package expects six climate variables, as daily or monthly observations, as Numpy arrays.\n",
    "Arrays must be 3-dimensional, with the third axes containing the time dimension.\n",
    "Unit of measures are expected as follows:\n",
    "- Minimum temperature = Degree Celsius\n",
    "- Maximum temperature = Degree Celsius\n",
    "- Precipitation = Accumulated mm / day (or per month)\n",
    "- Solar radiation = W/m^2\n",
    "- Wind speed = Average m/s\n",
    "- Relative humidity = Average fraction (0 to 1)\n",
    "\n",
    "In addition to climate data, the system requires:\n",
    "- A binary admin_mask, with 0 and 1 values. 0 pixels values will be not executed, while 1 pixels values will be executed\n",
    "- An elevation layer\n",
    "- Soil/terrain/special land cover classes\n",
    "  \n",
    "\n",
    "**All the datasets must have the same shape.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect 2 seconds run time for china\n",
    "# expect s run time for global\n",
    "\n",
    "start=timer()\n",
    "\n",
    "# '''reading climate data'''\n",
    "\n",
    "# Importing the climate data\n",
    "# this data is for 1980 without the leap day, so 365 total days\n",
    "\n",
    "# HPC Orion\n",
    "# same file structure for Kerrie's SSC desktop\n",
    "# max_temp = np.load(data_dir+'Tmax-2m365/0.npy')[:,0:266,:].astype('float32')  # maximum temperature\n",
    "# min_temp = np.load(data_dir+'Tmin-2m365/0.npy')[:,0:266,:].astype('float32')  # minimum temperature\n",
    "# precipitation = np.load(data_dir+'Precip365/0.npy')[:,0:266,:].astype('float32')  # precipitation\n",
    "# rel_humidity = np.load(data_dir+'Rhum365/0.npy')[:,0:266,:].astype('float32')  # relative humidity\n",
    "# wind_speed = np.load(data_dir+'Wind-2m365/0.npy')[:,0:266,:].astype('float32') # wind speed measured at two meters\n",
    "# short_rad = np.load(data_dir+'Srad365/0.npy')[:,0:266,:].astype('float32')  # shortwave radiation\n",
    "# mask=gdal.Open(maskfile).ReadAsArray()[:,0:266]\n",
    "# elevation=gdal.Open(elevfile).ReadAsArray()[:,0:266]\n",
    "# soil_terrain_lulc = gdal.Open(r'./data_input/LAO_soil_terrain_lulc.tif').ReadAsArray()\n",
    "# I don't know how to create the soil_terrain_lulc.tif for global\n",
    "\n",
    "# max_temp = np.load(data_dir+'Tmax-2m365/0.npy')[:,1000:1266,:].astype('float32')  # maximum temperature\n",
    "# min_temp = np.load(data_dir+'Tmin-2m365/0.npy')[:,1000:1266,:].astype('float32')  # minimum temperature\n",
    "# precipitation = np.load(data_dir+'Precip365/0.npy')[:,1000:1266,:].astype('float32')  # precipitation\n",
    "# rel_humidity = np.load(data_dir+'Rhum365/0.npy')[:,1000:1266,:].astype('float32')  # relative humidity\n",
    "# wind_speed = np.load(data_dir+'Wind-2m365/0.npy')[:,1000:1266,:].astype('float32') # wind speed measured at two meters\n",
    "# short_rad = np.load(data_dir+'Srad365/0.npy')[:,1000:1266,:].astype('float32')  # shortwave radiation\n",
    "# mask=gdal.Open(maskfile).ReadAsArray()[:,1000:1266]\n",
    "# elevation=gdal.Open(elevfile).ReadAsArray()[:,1000:1266]\n",
    "\n",
    "# max_temp = np.load(data_dir+'Tmax-2m365/0.npy').astype('float32')  # maximum temperature\n",
    "# min_temp = np.load(data_dir+'Tmin-2m365/0.npy').astype('float32')  # minimum temperature\n",
    "# precipitation = np.load(data_dir+'Precip365/0.npy').astype('float32')  # precipitation\n",
    "# rel_humidity = np.load(data_dir+'Rhum365/0.npy').astype('float32')  # relative humidity\n",
    "# wind_speed = np.load(data_dir+'Wind-2m365/0.npy').astype('float32') # wind speed measured at two meters\n",
    "# short_rad = np.load(data_dir+'Srad365/0.npy').astype('float32')  # shortwave radiation\n",
    "# mask=gdal.Open(maskfile).ReadAsArray()\n",
    "# elevation=gdal.Open(elevfile).ReadAsArray()\n",
    "\n",
    "\n",
    "max_temp = da.from_npy_stack(data_dir+'Tmax-2m365/').astype('float32')  # maximum temperature\n",
    "min_temp = da.from_npy_stack(data_dir+'Tmin-2m365/').astype('float32')  # minimum temperature\n",
    "precipitation = da.from_npy_stack(data_dir+'Precip365/').astype('float32')  # precipitation\n",
    "rel_humidity = da.from_npy_stack(data_dir+'Rhum365/').astype('float32')  # relative humidity\n",
    "wind_speed = da.from_npy_stack(data_dir+'Wind-2m365/').astype('float32') # wind speed measured at two meters\n",
    "short_rad = da.from_npy_stack(data_dir+'Srad365/').astype('float32')  # shortwave radiation\n",
    "mask=da.from_array(gdal.Open(maskfile).ReadAsArray())\n",
    "elevation=da.from_array(gdal.Open(elevfile).ReadAsArray())\n",
    "\n",
    "# max_temp = da.from_npy_stack(data_dir+'Tmax-2m365/')[:,1000:2064,:].astype('float32')  # maximum temperature\n",
    "# min_temp = da.from_npy_stack(data_dir+'Tmin-2m365/')[:,1000:2064,:].astype('float32')  # minimum temperature\n",
    "# precipitation = da.from_npy_stack(data_dir+'Precip365/')[:,1000:2064,:].astype('float32')  # precipitation\n",
    "# rel_humidity = da.from_npy_stack(data_dir+'Rhum365/')[:,1000:2064,:].astype('float32')  # relative humidity\n",
    "# wind_speed = da.from_npy_stack(data_dir+'Wind-2m365/')[:,1000:2064,:].astype('float32') # wind speed measured at two meters\n",
    "# short_rad = da.from_npy_stack(data_dir+'Srad365/')[:,1000:2064,:].astype('float32')  # shortwave radiation\n",
    "# mask=da.from_array(gdal.Open(maskfile).ReadAsArray())[:,1000:2064]\n",
    "# elevation=da.from_array(gdal.Open(elevfile).ReadAsArray())[:,1000:2064]\n",
    "\n",
    "# max_temp = da.from_npy_stack(data_dir+'Tmax-2m365/')[:,1000:1266,:].astype('float32')  # maximum temperature\n",
    "# min_temp = da.from_npy_stack(data_dir+'Tmin-2m365/')[:,1000:1266,:].astype('float32')  # minimum temperature\n",
    "# precipitation = da.from_npy_stack(data_dir+'Precip365/')[:,1000:1266,:].astype('float32')  # precipitation\n",
    "# rel_humidity = da.from_npy_stack(data_dir+'Rhum365/')[:,1000:1266,:].astype('float32')  # relative humidity\n",
    "# wind_speed = da.from_npy_stack(data_dir+'Wind-2m365/')[:,1000:1266,:].astype('float32') # wind speed measured at two meters\n",
    "# short_rad = da.from_npy_stack(data_dir+'Srad365/')[:,1000:1266,:].astype('float32')  # shortwave radiation\n",
    "# mask=da.from_array(gdal.Open(maskfile).ReadAsArray())[:,1000:1266]\n",
    "# elevation=da.from_array(gdal.Open(elevfile).ReadAsArray())[:,1000:1266]\n",
    "\n",
    "print(min_temp.shape,mask.shape)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(max_temp.nbytes+min_temp.nbytes+precipitation.nbytes+rel_humidity.nbytes+wind_speed.nbytes+short_rad.nbytes+mask.nbytes+elevation.nbytes)/1E9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask,elevation\n",
    "mask.shape,elevation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains parameters that can be modified by the user:\n",
    "- lat_min = minimum latitude of analysis\n",
    "- lat_max = maximum latitude of analysis\n",
    "- mask_value = the value in the admin_mask to exclude from the analysis (typically 0)\n",
    "- daily = whether climate input data are daily (True) or monthly (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Area-Of-Interest's geographical extents\n",
    "\n",
    "# if lat_min/lat_max values defined below are located at pixel center --> set lat_centers to True \n",
    "# if they are located at the exterior pixel edge --> set lat_centers to False\n",
    "lat_centers=True \n",
    "\n",
    "# provide min and max latitudes (either set manually or read from a data file)\n",
    "# lat_min = 18.04167\n",
    "# lat_max = 53.625\n",
    "lats=rio.open_rasterio(maskfile)['y'].data   # get array of latitudes from maskfile\n",
    "lat_min = np.trunc(lats.min()*100000)/100000 # min lat value at pixel center, limit precision to 5 decimal places\n",
    "lat_max = np.trunc(lats.max()*100000)/100000 # max lat value at pixel center, limit precision 5 decimal places\n",
    "\n",
    "# mask information\n",
    "mask_value = 0  # pixel value in admin_mask to exclude from the analysis\n",
    "mask_path=maskfile\n",
    "\n",
    "# time resolution information\n",
    "daily = True #Type of climate data = True: daily, False: monthly\n",
    "parallel=True#False#True#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the imported data into the Object Class ('*clim_reg*' Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "start=timer()\n",
    "\n",
    "clim_reg.setParallel(max_temp,parallel)#,nchunks=288)#,nchunks=864)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.__dict__.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key,value in clim_reg.__dict__.items():\n",
    "#     print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "start=timer()\n",
    "\n",
    "clim_reg.setStudyAreaMask(mask, mask_value)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clim_reg.__dict__.keys()\n",
    "# clim_reg.im_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "start=timer()\n",
    "\n",
    "clim_reg.setLocationTerrainData(lat_min, lat_max, lat_centers, elevation) #KLG\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.__dict__.keys()\n",
    "# clim_reg.latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for global expect ~9.5min\n",
    "# this is computing pet_daily and interp_daily_temp\n",
    "# everything else remains a dask array\n",
    "start=timer()\n",
    "\n",
    "clim_reg.setDailyClimateData(min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.nchunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~50 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "tclimate = clim_reg.getThermalClimate()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETtest(dstart,dend,cdims,lat,alt,tmn,tmx,u2m,srad,rh):\n",
    "    # print('implementing data value limits')\n",
    "    nlats=cdims[0]\n",
    "    nlons=cdims[1]\n",
    "\n",
    "    # print('tavg,lam,dayoyr,ndays')\n",
    "    tavg = 0.5*(tmn + tmx)  # Averaged temperature  #KLG\n",
    "    lam = 2.501 - 0.002361 * tavg  # Latent heat of vaporization\n",
    "    dayoyr = np.arange(dstart, dend+1)  # Julien Days #KLG\n",
    "    ndays=len(dayoyr)  #KLG            \n",
    "\n",
    "    # print('es_tmin,es_tmax,es,ea')\n",
    "    es_tmin = 0.6108 * np.exp((17.27 * tmn) / (tmn + 237.3))\n",
    "    es_tmax = 0.6108 * np.exp((17.27 * tmx) / (tmx + 237.3))\n",
    "    es = 0.5*(es_tmin + es_tmax)\n",
    "    ea = rh * es  # Actual Vapor Pressure derived from relative humidity\n",
    "\n",
    "    # print('dlmx,dlmn,dl')\n",
    "    dlmx = 4098. * es_tmax / (tmx + 237.3)**2\n",
    "    dlmn = 4098. * es_tmin / (tmn + 237.3)**2\n",
    "    del es_tmin, es_tmax  #KLG\n",
    "    dl = 0.5* (dlmx + dlmn)\n",
    "    del dlmx,dlmn  #KLG\n",
    "\n",
    "    # print('ap and constants')\n",
    "    ap = 101.3*np.power(((293-(0.0065*alt))/293), 5.256)\n",
    "    ap = np.tile(ap[:,:,np.newaxis],(1,1,ndays))  \n",
    "    gam = 0.0016286 * ap/lam\n",
    "    hw = 200.\n",
    "    ht = 190.\n",
    "    hc = 12\n",
    "    Rl = 100  \n",
    "    RLAI = 24 * 0.12\n",
    "    rhoc = Rl/(0.5*RLAI)  \n",
    "    del ap\n",
    "\n",
    "    # print('rhoa,gamst')\n",
    "    rhoa = 208/u2m\n",
    "    gamst = gam * (1. + rhoc/rhoa)\n",
    "\n",
    "    # print('lat,sdcl')\n",
    "    latr = lat * np.pi/180.\n",
    "    latr3D = np.tile(latr[:,:,np.newaxis],(1,1,ndays))\n",
    "    del latr\n",
    "    sdcl = 0.4093 * np.sin(0.017214206 * dayoyr - 1.405)\n",
    "    sdcl3D = np.tile(sdcl[np.newaxis, np.newaxis,:], (nlats,nlons,1))\n",
    "    del sdcl\n",
    "\n",
    "    # print('xx,yy,zz')\n",
    "    xx = np.sin(sdcl3D) * np.sin(latr3D)\n",
    "    yy = np.cos(sdcl3D) * np.cos(latr3D)\n",
    "    zz = xx/yy\n",
    "\n",
    "    # print('omg,dayhr')\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        omg = np.tan(zz / (1. - zz*zz)**0.5) + 1.5708\n",
    "    dayhr = 24. * (omg/np.pi)\n",
    "\n",
    "    omg=np.where((np.abs(zz)>=0.9999)&(zz>0),np.pi,omg)\n",
    "    dayhr=np.where((np.abs(zz) >= 0.9999)&(zz > 0), 23.999,dayhr)\n",
    "    omg=np.where((np.abs(zz) >= 0.9999)&(zz <= 0),0,omg)\n",
    "    dayhr=np.where((np.abs(zz) >= 0.9999)&(zz <= 0), 0.001,dayhr)\n",
    "    del latr3D,sdcl3D,zz\n",
    "\n",
    "    # print('sdst,ra')\n",
    "    sdst = 1.0 + 0.033 * np.cos(0.017214206 * dayoyr)\n",
    "    sdst3D = np.tile(sdst[np.newaxis, np.newaxis,:], (nlats,nlons,1))\n",
    "    del sdst\n",
    "    ra = 37.586 * sdst3D * (omg*xx + np.sin(omg)*yy)\n",
    "    # ra = 37.586 * sdst3D * (omg_rev2*xx + np.sin(omg_rev2)*yy)\n",
    "    # del sdst3D, sdst, omg, omg_rev1, omg_rev2, dayhr, dayhr_rev1, dayhr_rev2, xx, yy       \n",
    "    del sdst3D, omg, dayhr, xx, yy       \n",
    "\n",
    "    # print('rs,rs0')\n",
    "    rs = srad  \n",
    "    alt3D=np.tile(alt[:,:,np.newaxis],(1,1,ndays)) \n",
    "    del alt\n",
    "    rs0 = (0.75 + 0.00002 * alt3D) * ra\n",
    "    del alt3D\n",
    "\n",
    "    # print('rns,rnl')\n",
    "    rns = 0.77 * rs\n",
    "    sub_cst = 0.000000004903\n",
    "    with np.errstate(invalid='ignore',divide='ignore'):\n",
    "        rs_div_ds0=rs/rs0\n",
    "    rnl = (((273.16+tmx)**4)+((273.16 + tmn)**4)) * \\\n",
    "        (0.34 - (0.14*(ea**0.5))) * \\\n",
    "        ((1.35*(rs_div_ds0))-0.35)*sub_cst/2\n",
    "    del rs0,rs,rs_div_ds0,tmx,tmn\n",
    "\n",
    "    # print('rn')\n",
    "    rn = rns - rnl\n",
    "    del rns,rnl\n",
    "\n",
    "    # print('ta_diff,G')\n",
    "    ta_diff=np.diff(tavg,n=1,axis=2,prepend=tavg[:,:,-1:])  #KLG\n",
    "    G = 0.14 * ta_diff  #KLG\n",
    "    del ta_diff\n",
    "\n",
    "    # print('et0ady')\n",
    "    et0ady = gam/(dl+gamst) * 900./(tavg+273.) * u2m * (es-ea)\n",
    "    del gam,tavg,es,ea\n",
    "\n",
    "    # print('et0rad')\n",
    "    et0rad = dl/(dl+gamst) * (rn-G) / lam\n",
    "    del dl,gamst,rn,G,lam\n",
    "\n",
    "    # print('et0')\n",
    "    et0 = et0ady + et0rad\n",
    "    del et0ady,et0rad\n",
    "\n",
    "    # print('et0_out')\n",
    "    et0_out=np.where(et0<0,0,et0)\n",
    "\n",
    "    return et0_out\n",
    "    # return doy_start,doy_end,chunkdims,latitude,alt,min_temp,max_temp,u2m,shortrad_daily_MJm2day,rel_humidity\n",
    "    # return alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDailyClimateData(self, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity):\n",
    "\n",
    "    self.doy_start=1  #KLG\n",
    "    self.doy_end=min_temp.shape[2]  #KLG \n",
    "    \n",
    "    print('rechunking and delaying inputs')\n",
    "    min_temp=min_temp.rechunk(chunks=self.chunk3D)\n",
    "    max_temp=max_temp.rechunk(chunks=self.chunk3D)\n",
    "    tmn_delay=min_temp.to_delayed()\n",
    "    tmx_delay=max_temp.to_delayed()\n",
    "\n",
    "    short_rad=short_rad.rechunk(chunks=self.chunk3D) # chunk\n",
    "    short_rad=da.where(short_rad < 0, 0, short_rad)  # elim negatives\n",
    "    short_rad = (short_rad*3600.*24.)/1000000.       # convert units\n",
    "    srad_delay=short_rad.to_delayed()\n",
    "    del short_rad\n",
    "\n",
    "    wind_speed=wind_speed.rechunk(chunks=self.chunk3D)     # chunk\n",
    "    # wind_speed=da.where(wind_speed < 0, 0, wind_speed)     # elim negative\n",
    "    wind_speed=da.where(wind_speed < 0.5, 0.5, wind_speed) # elim negative and small values\n",
    "    wind_delay=wind_speed.to_delayed()\n",
    "\n",
    "    rel_humidity=rel_humidity.rechunk(chunks=self.chunk3D)        # chunk\n",
    "    rel_humidity=da.where(rel_humidity > 0.99, 0.99,rel_humidity) # elim high values\n",
    "    rel_humidity=da.where(rel_humidity < 0.05, 0.05,rel_humidity) # elim low values\n",
    "    rh_delay=rel_humidity.to_delayed()\n",
    "    del rel_humidity\n",
    "\n",
    "    lat_delay=self.latitude.to_delayed()\n",
    "    elev_delay=self.elevation.to_delayed()        \n",
    "\n",
    "\n",
    "    print('getting chunk shapes')\n",
    "    chunk_shapes=dask.compute([chunk.shape for chunk in tmn_delay.ravel()])\n",
    "    print('zipping delayed inputs')\n",
    "    zipvars=zip(chunk_shapes[0][:],lat_delay.ravel(),elev_delay.ravel(),tmn_delay.ravel(),tmx_delay.ravel(),wind_delay.ravel(),srad_delay.ravel(),rh_delay.ravel())\n",
    "    print('creating task list')\n",
    "    task_list=[dask.delayed(ETtest)(self.doy_start,self.doy_end,cshape,lat,el,tmn,tmx,u,srad,rh) for cshape,lat,el,tmn,tmx,u,srad,rh in zipvars]\n",
    "\n",
    "    print('COMPUTING')\n",
    "    result_chunks=dask.compute(*task_list)\n",
    "    print('CONCATENATING')\n",
    "    self.pet_daily=np.concatenate(result_chunks,axis=1)\n",
    "    # return result_chunks\n",
    "\n",
    "\n",
    "    print('computing meanT, meanT_daily_sealevel, P_by_PET_daily')\n",
    "    self.meanT_daily = 0.5*(min_temp+max_temp)  #KLG\n",
    "\n",
    "    # sea level temperature\n",
    "    # P over PET ratio (to eliminate nan in the result, nan is replaced with zero)\n",
    "    if self.parallel:\n",
    "        self.meanT_daily_sealevel = self.meanT_daily + (da.tile(self.elevation[:,:,np.newaxis],(1,1,self.doy_end)).rechunk(chunks=self.chunk3D)/100*0.55)\n",
    "        precipitation=precipitation.rechunk(chunks=self.chunk3D)\n",
    "        with np.errstate(invalid='ignore',divide='ignore'):\n",
    "            self.P_by_PET_daily = da.nan_to_num(precipitation / self.pet_daily)\n",
    "    else:\n",
    "        self.meanT_daily_sealevel = self.meanT_daily + np.expand_dims(self.elevation/100*0.55,axis=2) # automatic broadcasting #KLG        \n",
    "        with np.errstate(invalid='ignore',divide='ignore'):\n",
    "            self.P_by_PET_daily = np.nan_to_num(precipitation / self.pet_daily)\n",
    "\n",
    "    self.set_monthly = False\n",
    "\n",
    "    print('computing interp_daily_temp')\n",
    "    # smoothed daily temperature\n",
    "    # create a mask of all 1's if the user doesn't provide a mask\n",
    "    if self.set_mask:\n",
    "        mask=self.im_mask\n",
    "    else:\n",
    "        mask=np.ones((self.im_height,self.im_width),dtype='int')\n",
    "\n",
    "    obj_utilities = UtilitiesCalc.UtilitiesCalc(self.chunk2D,self.chunk3D)  #KLG\n",
    "    self.interp_daily_temp=obj_utilities.smoothDailyTemp(self.doy_start,self.doy_end, mask, self.meanT_daily,self.chunk3D)\n",
    "\n",
    "    print('copying maxT_daily,minT_daily,totalPrec_daily')\n",
    "    self.maxT_daily = max_temp\n",
    "    # self.minT_daily = min_temp\n",
    "    self.totalPrec_daily = precipitation  #KLG   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.chunk3D, clim_reg.chunksize3D_MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setDailyClimateData(clim_reg, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clim_reg.pet_daily # numpy array\n",
    "# clim_reg.meanT_daily  # dask array\n",
    "# clim_reg.meanT_daily_sealevel  # dask_array\n",
    "# clim_reg.P_by_PET_daily  # dask array\n",
    "# clim_reg.maxT_daily  # dask array\n",
    "# clim_reg.totalPrec_daily  # dask array\n",
    "# clim_reg.interp_daily_temp  # numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prsum=clim_reg.totalPrec_daily.sum(axis=2).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.P_by_PET_daily.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this normal numpy calculation works just fine with 5GB inputs\n",
    "\n",
    "print('implementing data value limits')\n",
    "doy_start=1  #KLG\n",
    "doy_end=min_temp.shape[2]  #KLG\n",
    "nlats=min_temp.shape[0]\n",
    "nlons=min_temp.shape[1]\n",
    "\n",
    "rel_humidity=np.where(rel_humidity > 0.99, 0.99,rel_humidity)\n",
    "rel_humidity=np.where(rel_humidity < 0.05, 0.05,rel_humidity)\n",
    "short_rad=np.where(short_rad < 0, 0, short_rad)\n",
    "shortrad_daily_MJm2day = (short_rad*3600.*24.)/1000000.\n",
    "del short_rad\n",
    "# wind_speed=da.where(wind_speed < 0, 0, wind_speed)  \n",
    "u2m=np.where(wind_speed < 0.5, 0.5, wind_speed)\n",
    "\n",
    "print('tavg,lam,dayoyr,ndays')\n",
    "tavg = 0.5*(min_temp + max_temp)  # Averaged temperature  #KLG\n",
    "lam = 2.501 - 0.002361 * tavg  # Latent heat of vaporization\n",
    "\n",
    "dayoyr = np.arange(doy_start, doy_end+1)  # Julien Days #KLG\n",
    "ndays=len(dayoyr)  #KLG            \n",
    "# alt=np.tile(clim_reg.elevation[:,:,np.newaxis],(1,1,ndays))  # 3D altitude #KLG\n",
    "alt=elevation\n",
    "\n",
    "print('es_tmin,es_tmax,es,ea')\n",
    "es_tmin = 0.6108 * np.exp((17.27 * min_temp) / (min_temp + 237.3))\n",
    "es_tmax = 0.6108 * np.exp((17.27 * max_temp) / (max_temp + 237.3))\n",
    "es = 0.5*(es_tmin + es_tmax)\n",
    "ea = rel_humidity * es  # Actual Vapor Pressure derived from relative humidity\n",
    "\n",
    "print('dlmx,dlmn,dl')\n",
    "dlmx = 4098. * es_tmax / (max_temp + 237.3)**2\n",
    "dlmn = 4098. * es_tmin / (min_temp + 237.3)**2\n",
    "# del es_tmin, es_tmax  #KLG\n",
    "dl = 0.5* (dlmx + dlmn)\n",
    "# del dlmx,dlmn  #KLG\n",
    "\n",
    "print('ap and constants')\n",
    "ap = 101.3*np.power(((293-(0.0065*alt))/293), 5.256)\n",
    "ap = np.tile(ap[:,:,np.newaxis],(1,1,ndays))  \n",
    "gam = 0.0016286 * ap/lam\n",
    "hw = 200.\n",
    "ht = 190.\n",
    "hc = 12\n",
    "Rl = 100  \n",
    "RLAI = 24 * 0.12\n",
    "rhoc = Rl/(0.5*RLAI)  \n",
    "# del ap\n",
    "\n",
    "print('rhoa,gamst')\n",
    "rhoa = 208/u2m\n",
    "gamst = gam * (1. + rhoc/rhoa)\n",
    "\n",
    "print('lat,sdcl')\n",
    "latr = clim_reg.latitude * np.pi/180.\n",
    "latr3D = np.tile(latr[:,:,np.newaxis],(1,1,ndays))\n",
    "sdcl = 0.4093 * np.sin(0.017214206 * dayoyr - 1.405)\n",
    "sdcl3D = np.tile(sdcl[np.newaxis, np.newaxis,:], (nlats,nlons,1))\n",
    "\n",
    "print('xx,yy,zz')\n",
    "xx = np.sin(sdcl3D) * np.sin(latr3D)\n",
    "yy = np.cos(sdcl3D) * np.cos(latr3D)\n",
    "zz = xx/yy\n",
    "\n",
    "print('omg,dayhr')\n",
    "omg = np.tan(zz / (1. - zz*zz)**0.5) + 1.5708\n",
    "dayhr = 24. * (omg/np.pi)\n",
    "omg_rev1=np.where((np.abs(zz)>=0.9999)&(zz>0),np.pi,omg)\n",
    "dayhr_rev1=np.where((np.abs(zz) >= 0.9999)&(zz > 0), 23.999,dayhr)\n",
    "omg_rev2=np.where((np.abs(zz) >= 0.9999)&(zz <= 0),0,omg_rev1)\n",
    "dayhr_rev2=np.where((np.abs(zz) >= 0.9999)&(zz <= 0), 0.001,dayhr_rev1)\n",
    "del latr3D,sdcl3D,latr,sdcl,zz\n",
    "\n",
    "print('sdst,ra')\n",
    "sdst = 1.0 + 0.033 * np.cos(0.017214206 * dayoyr)\n",
    "sdst3D = np.tile(sdst[np.newaxis, np.newaxis,:], (nlats,nlons,1))\n",
    "ra = 37.586 * sdst3D * (omg_rev2*xx + np.sin(omg_rev2)*yy)\n",
    "del sdst3D, sdst, omg, omg_rev1, omg_rev2, dayhr, dayhr_rev1, dayhr_rev2, xx, yy       \n",
    "\n",
    "print('rs,rs0')\n",
    "rs = shortrad_daily_MJm2day  \n",
    "alt3D=np.tile(alt[:,:,np.newaxis],(1,1,ndays)) \n",
    "rs0 = (0.75 + 0.00002 * alt3D) * ra\n",
    "del alt3D,alt\n",
    "\n",
    "print('rns,rnl')\n",
    "rns = 0.77 * rs\n",
    "sub_cst = 0.000000004903\n",
    "rs_div_ds0=rs/rs0\n",
    "rnl = (((273.16+max_temp)**4)+((273.16 + min_temp)**4)) * \\\n",
    "    (0.34 - (0.14*(ea**0.5))) * \\\n",
    "    ((1.35*(rs_div_ds0))-0.35)*sub_cst/2\n",
    "del rs0,rs,rs_div_ds0\n",
    "\n",
    "print('rn')\n",
    "rn = rns - rnl\n",
    "del rns,rnl\n",
    "\n",
    "print('ta_diff,G')\n",
    "ta_diff=np.diff(tavg,n=1,axis=2,prepend=tavg[:,:,-1:])  #KLG\n",
    "G = 0.14 * ta_diff  #KLG\n",
    "del ta_diff\n",
    "\n",
    "print('et0ady')\n",
    "et0ady = gam/(dl+gamst) * 900./(tavg+273.) * u2m * (es-ea)\n",
    "del gam,tavg,es,ea\n",
    "\n",
    "print('et0rad')\n",
    "et0rad = dl/(dl+gamst) * (rn-G) / lam\n",
    "del dl,gamst,rn,G,lam\n",
    "\n",
    "print('et0')\n",
    "et0 = et0ady + et0rad\n",
    "del et0ady,et0rad\n",
    "\n",
    "print('et0_out')\n",
    "et0_out=np.where(et0<0,0,et0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam.shape, rhoa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nchunks=238\n",
    "# nlons=min_temp.shape[1]\n",
    "# chunk_nlons=int(da.ceil(nlons/nchunks))\n",
    "# chunks3D=(-1,chunk_nlons,-1)\n",
    "# chunks2D=(-1,chunk_nlons)\n",
    "\n",
    "# lat_vals=da.linspace(lat_min, lat_max, min_temp.shape[0]).astype('float32')  #KLG\n",
    "# lat_map=da.tile(lat_vals[:,np.newaxis],(1,min_temp.shape[1])).rechunk(chunks=chunks2D)  #KLG   \n",
    "# # lat_map=da.broadcast_to(lat_vals,(min_temp.shape[0],min_temp.shape[1]),chunks=chunks2D)\n",
    "# lat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETOCalc(object):\n",
    " \n",
    "    def __init__(self, cycle_begin, cycle_end, latitude, altitude,chunk3D):\n",
    "        \"\"\"Initiate a ETOCalc Class instance\n",
    "\n",
    "        Args:\n",
    "            cycle_begin (int): Julian day for the beginning of crop cycle\n",
    "            cycle_end (int): Julian day for the ending of crop cycle\n",
    "            latitude (float): a latitude value\n",
    "            altitude (float): an altitude value\n",
    "        \"\"\"        \n",
    "        self.cycle_begin = cycle_begin\n",
    "        self.cycle_end = cycle_end\n",
    "        self.latitude = latitude\n",
    "        self.alt = altitude\n",
    "        \n",
    "        self.chunk3D=chunk3D\n",
    "        if self.chunk3D: self.parallel=True\n",
    "        else: self.parallel=False\n",
    "        print('parallel ETO = ',self.parallel)\n",
    "\n",
    "    def setClimateData(self, min_temp, max_temp, wind_speed, short_rad, rel_humidity):\n",
    "        \"\"\"Load the climatic (point) data into the Class\n",
    "\n",
    "        Args:\n",
    "            min_temp (float): Minimum temperature [Celcius]\n",
    "            max_temp (float): Maximum temperature [Celcius]\n",
    "            wind_speed (float): Windspeed at 2m altitude [m/s]\n",
    "            short_rad (float): Radiation [MJ/m2.day]\n",
    "            rel_humidity (float): Relative humidity [decimal percentage]\n",
    "        \"\"\"        \n",
    "\n",
    "        self.minT_daily = min_temp # Celcius\n",
    "        self.maxT_daily = max_temp # Celcius\n",
    "        self.u2m = wind_speed # m/s at 2m\n",
    "        self.shortRad_daily = short_rad # MJ/m2.day\n",
    "        self.rel_humidity = rel_humidity # Fraction\n",
    "\n",
    "    def calculateETO(self):  #KLG\n",
    "        # numba doesn't speed this up in time tests  #KLG\n",
    "        # removing in favor of vectorization which will allow chunking with dask for speed  #KLG\n",
    "\n",
    "        \"\"\"Calculate the reference evapotranspiration with Penmann-Monteith Equation\n",
    "\n",
    "        Returns:\n",
    "            ## float: ETo of a single pixel (function is called pixel-wise)\n",
    "            float: ETo of each pixel  #KLG\n",
    "        \"\"\"        \n",
    "        # if self.parallel:\n",
    "        #     self.minT_daily=self.minT_daily.persist()\n",
    "        #     self.maxT_daily=self.maxT_daily.persist()\n",
    "            # self.windspeed_daily=self.windspeed_daily.persist()\n",
    "            # self.alt=self.alt.persist()\n",
    "            # self.latitude=self.latitude.persist()\n",
    "\n",
    "        # nchunks=238\n",
    "        # nlons=self.alt.shape[1]\n",
    "        # chunk_nlons=int(da.ceil(nlons/nchunks))\n",
    "        # chunks3D=(-1,chunk_nlons,-1)\n",
    "        # chunks2D=(-1,chunk_nlons)\n",
    "\n",
    "        print('tavg,lam,alt')\n",
    "        # constants\n",
    "        # tavg = 0.5*(maxT_daily+minT_daily)  # Averaged temperature\n",
    "        tavg = 0.5*(self.minT_daily + self.maxT_daily)  # Averaged temperature  #KLG\n",
    "        print('tavg.shape=',tavg.shape)\n",
    "        lam = 2.501 - 0.002361 * tavg  # Latent heat of vaporization\n",
    "        # if self.parallel:\n",
    "        #     dayoyr = da.arange(self.cycle_begin, self.cycle_end+1,chunks=-1)  # Julien Days #KLG\n",
    "        #     ndays=len(dayoyr)  #KLG\n",
    "        #     alt=da.tile(self.alt[:,:,np.newaxis],(1,1,ndays)).rechunk(chunks=self.chunk3D)\n",
    "        # else:\n",
    "            # dayoyr = np.arange(self.cycle_begin, self.cycle_end+1)  # Julien Days #KLG\n",
    "            # ndays=len(dayoyr)  #KLG            \n",
    "            # alt=np.tile(self.alt[:,:,np.newaxis],(1,1,ndays))  # 3D altitude #KLG\n",
    "        dayoyr = np.arange(self.cycle_begin, self.cycle_end+1)  # Julien Days #KLG\n",
    "        ndays=len(dayoyr)  #KLG            \n",
    "        alt=np.tile(self.alt[:,:,np.newaxis],(1,1,ndays))  # 3D altitude #KLG\n",
    "\n",
    "        # print('u2m')\n",
    "        # Wind speed\n",
    "        # u2m = windspeed_daily.copy()\n",
    "        # u2m = self.windspeed_daily.copy()  #KLG\n",
    "        # limit to no less than 0.5 m/s; FAO 56, p.63\n",
    "        # u2m[windspeed_daily < 0.5] = 0.5\n",
    "        # print('u2m.where')\n",
    "        # if self.parallel:\n",
    "        #     u2m=da.where(u2m < 0.5, 0.5, u2m)\n",
    "        # else:\n",
    "        #     u2m=np.where(u2m < 0.5, 0.5, u2m)\n",
    "        # u2m=np.where(u2m < 0.5, 0.5, u2m)\n",
    "\n",
    "        print('es_tmin,es_tmax')\n",
    "        # Mean Saturation Vapor Pressure derived from air temperature\n",
    "        # if self.parallel:\n",
    "        #     es_tmin = 0.6108 * da.exp((17.27 * self.minT_daily) / (self.minT_daily + 237.3))  #KLG\n",
    "        #     es_tmax = 0.6108 * da.exp((17.27 * self.maxT_daily) / (self.maxT_daily + 237.3))  #KLG\n",
    "        # else:            \n",
    "        #     es_tmin = 0.6108 * np.exp((17.27 * self.minT_daily) / (self.minT_daily + 237.3))\n",
    "        #     es_tmax = 0.6108 * np.exp((17.27 * self.maxT_daily) / (self.maxT_daily + 237.3))\n",
    "        es_tmin = 0.6108 * np.exp((17.27 * self.minT_daily) / (self.minT_daily + 237.3))\n",
    "        es_tmax = 0.6108 * np.exp((17.27 * self.maxT_daily) / (self.maxT_daily + 237.3))\n",
    "\n",
    "        print('es,ea')\n",
    "        es = 0.5*(es_tmin + es_tmax)\n",
    "        # ea = rel_humidity * es  # Actual Vapor Pressure derived from relative humidity\n",
    "        ea = self.rel_humidity * es  # Actual Vapor Pressure derived from relative humidity  #KLG\n",
    "\n",
    "        print('dlmx,dlmn,dl')\n",
    "        # slope vapour pressure curve\n",
    "        # dlmx = 4098. * es_tmax / (maxT_daily + 237.3)**2\n",
    "        # dlmn = 4098. * es_tmin / (minT_daily + 237.3)**2\n",
    "        dlmx = 4098. * es_tmax / (self.maxT_daily + 237.3)**2  #KLG\n",
    "        dlmn = 4098. * es_tmin / (self.minT_daily + 237.3)**2  #KLG\n",
    "        del es_tmin, es_tmax  #KLG\n",
    "        dl = 0.5* (dlmx + dlmn)\n",
    "        del dlmx,dlmn  #KLG\n",
    "\n",
    "        print('ap,gam')\n",
    "        # Atmospheric pressure\n",
    "        # if self.parallel:\n",
    "        #     ap = 101.3*da.power(((293-(0.0065*alt))/293), 5.256)\n",
    "        # else:\n",
    "        #     ap = 101.3*np.power(((293-(0.0065*alt))/293), 5.256)\n",
    "        ap = 101.3*np.power(((293-(0.0065*alt))/293), 5.256)\n",
    "\n",
    "            \n",
    "        # Psychrometric constant\n",
    "        gam = 0.0016286 * ap/lam\n",
    "        del ap\n",
    "\n",
    "        hw = 200.\n",
    "        ht = 190.\n",
    "        hc = 12.\n",
    "\n",
    "        print('rhoa,Rl,RLAI,rhic,gamst')\n",
    "        # aerodynamic resistance\n",
    "        rhoa = 208/self.u2m\n",
    "\n",
    "        # crop canopy resistance\n",
    "        Rl = 100  # daily stomata resistance of a single leaf (s/m)\n",
    "        # Standard is xLAO = 24\n",
    "        RLAI = 24 * 0.12\n",
    "        rhoc = Rl/(0.5*RLAI)  # crop canopy resistance\n",
    "\n",
    "        gamst = gam * (1. + rhoc/rhoa)\n",
    "\n",
    "        print('latr')\n",
    "        # latr = latitude * np.pi/180.\n",
    "        latr = self.latitude * np.pi/180.\n",
    "        # if self.parallel:\n",
    "        #     latr=da.tile(latr[:,:,np.newaxis],(1,1,ndays)).rechunk(chunks=self.chunk3D)\n",
    "        # else:\n",
    "        #     latr = np.tile(latr[:,:,np.newaxis],(1,1,ndays))\n",
    "        # latr = np.tile(latr[:,:,np.newaxis],(1,1,ndays))\n",
    "\n",
    "        print('sdcl')\n",
    "        # (a) calculate extraterrestrial radiation\n",
    "        # solar declination (rad)\n",
    "        # if self.parallel:\n",
    "        #     sdcl = 0.4093 * da.sin(0.017214206 * dayoyr - 1.405)\n",
    "        #     sdcl=da.broadcast_to(sdcl,(tavg.shape[0],tavg.shape[1],tavg.shape[2]),chunks=self.chunk3D)\n",
    "        # else:\n",
    "        #     sdcl = 0.4093 * np.sin(0.017214206 * dayoyr - 1.405)\n",
    "        #     sdcl = np.tile(sdcl[np.newaxis, np.newaxis,:], (tavg.shape[0],tavg.shape[1],1))\n",
    "        sdcl = 0.4093 * np.sin(0.017214206 * dayoyr - 1.405)\n",
    "        # sdcl = np.tile(sdcl[np.newaxis, np.newaxis,:], (tavg.shape[0],tavg.shape[1],1))\n",
    "        \n",
    "        print('sdst')\n",
    "        # relative distance earth to sun\n",
    "        # if self.parallel:\n",
    "        #     sdst = 1.0 + 0.033 * da.cos(0.017214206 * dayoyr)\n",
    "        #     sdst=da.broadcast_to(sdst,(tavg.shape[0],tavg.shape[1],tavg.shape[2]),chunks=self.chunk3D)\n",
    "        # else:\n",
    "        #     sdst = 1.0 + 0.033 * np.cos(0.017214206 * dayoyr)\n",
    "        #     sdst=np.tile(sdst[np.newaxis, np.newaxis,:], (tavg.shape[0],tavg.shape[1],1))\n",
    "        sdst = 1.0 + 0.033 * np.cos(0.017214206 * dayoyr)\n",
    "        # sdst=np.tile(sdst[np.newaxis, np.newaxis,:], (tavg.shape[0],tavg.shape[1],1))\n",
    "        del dayoyr\n",
    "\n",
    "        print('xx,yy,zz')\n",
    "        # if self.parallel:\n",
    "        #     xx = da.sin(sdcl) * da.sin(latr)\n",
    "        #     yy = da.cos(sdcl) * da.cos(latr)            \n",
    "        # else:\n",
    "        #     xx = np.sin(sdcl) * np.sin(latr)\n",
    "        #     yy = np.cos(sdcl) * np.cos(latr)\n",
    "        xx = np.sin(sdcl) * np.sin(latr)\n",
    "        yy = np.cos(sdcl) * np.cos(latr)\n",
    "        zz = xx/yy\n",
    "\n",
    "        print('omg,dayhr')\n",
    "        # if self.parallel:\n",
    "        #     omg = da.tan(zz / (1. - zz*zz)**0.5) + 1.5708\n",
    "        # else:\n",
    "        #     omg = np.tan(zz / (1. - zz*zz)**0.5) + 1.5708\n",
    "        omg = np.tan(zz / (1. - zz*zz)**0.5) + 1.5708\n",
    "        dayhr = 24. * (omg/np.pi)\n",
    "\n",
    "        # if self.parallel:\n",
    "        #     print('omg.where,dayhr.where,ra')\n",
    "        #     omg=da.where((da.abs(zz)>=0.9999)&(zz>0),np.pi,omg)\n",
    "        #     dayhr=da.where((da.abs(zz) >= 0.9999)&(zz > 0), 23.999,dayhr)\n",
    "\n",
    "        #     omg=da.where((da.abs(zz) >= 0.9999)&(zz <= 0),0,omg)\n",
    "        #     dayhr=da.where((da.abs(zz) >= 0.9999)&(zz <= 0), 0.001,dayhr)\n",
    "\n",
    "        #     print('ra')\n",
    "        #     ra = 37.586 * sdst * (omg*xx + da.sin(omg)*yy)\n",
    "        # else:\n",
    "        #     print('omg.where,dayhr.where,ra')\n",
    "        #     omg=np.where((np.abs(zz)>=0.9999)&(zz>0),np.pi,omg)\n",
    "        #     dayhr=np.where((np.abs(zz) >= 0.9999)&(zz > 0), 23.999,dayhr)\n",
    "\n",
    "        #     omg=np.where((np.abs(zz) >= 0.9999)&(zz <= 0),0,omg)\n",
    "        #     dayhr=np.where((np.abs(zz) >= 0.9999)&(zz <= 0), 0.001,dayhr) \n",
    "            \n",
    "        #     print('ra')\n",
    "        #     ra = 37.586 * sdst * (omg*xx + np.sin(omg)*yy)\n",
    "        print('omg.where,dayhr.where,ra')\n",
    "        omg_rev1=np.where((np.abs(zz)>=0.9999)&(zz>0),np.pi,omg)\n",
    "        dayhr_rev1=np.where((np.abs(zz) >= 0.9999)&(zz > 0), 23.999,dayhr)\n",
    "\n",
    "        omg_rev2=np.where((np.abs(zz) >= 0.9999)&(zz <= 0),0,omg_rev1)\n",
    "        dayhr_rev2=np.where((np.abs(zz) >= 0.9999)&(zz <= 0), 0.001,dayhr_rev1) \n",
    "        \n",
    "        print('ra')\n",
    "        ra = 37.586 * sdst * (omg_rev2*xx + np.sin(omg_rev2)*yy)\n",
    "        del sdcl, latr, sdst, omg, omg_rev1, omg_rev2, dayhr, dayhr_rev1, dayhr_rev2, xx, yy, zz        \n",
    "\n",
    "        print('rs,rs0')\n",
    "        # (b) solar radiation Rs (0.25, 0.50 Angstrom coefficients)\n",
    "        # rs = (0.25 + (0.50 * (sd/dayhr))) * ra\n",
    "        # rs = shortRad_daily\n",
    "        rs = self.shortRad_daily  #KLG\n",
    "        # rs0 = (0.75 + 0.00002 * alt) * ra\n",
    "        rs0 = (0.75 + 0.00002 * self.alt) * ra\n",
    "        \n",
    "        del alt\n",
    "\n",
    "        print('rns,rnl')\n",
    "        # (c) net shortwave radiation Rns = (1 - alpha) * Rs\n",
    "        # (alpha for grass = 0.23)\n",
    "        rns = 0.77 * rs\n",
    "\n",
    "        # (d) net longwave radiation Rnl\n",
    "        # Stefan-Boltzmann constant [MJ K-4 m-2 day-1]\n",
    "        sub_cst = 0.000000004903\n",
    "        rs_div_ds0=rs/rs0\n",
    "        rnl = (((273.16+self.maxT_daily)**4)+((273.16 + self.minT_daily)**4)) * \\\n",
    "            (0.34 - (0.14*(ea**0.5))) * \\\n",
    "            ((1.35*(rs_div_ds0))-0.35)*sub_cst/2\n",
    "        del rs0,rs\n",
    "\n",
    "        print('rn')\n",
    "        # (e) net radiation Rn = Rns - Rnl\n",
    "        rn = rns - rnl\n",
    "        del rns,rnl\n",
    "\n",
    "        print('ta_diff,G')\n",
    "        # (f) soil heat flux [MJ/m2/day]\n",
    "        # if self.parallel:\n",
    "        #     ta_diff=da.diff(tavg,n=1,axis=2,prepend=tavg[:,:,-1:])  #KLG\n",
    "        # else:\n",
    "        #     ta_diff=np.diff(tavg,n=1,axis=2,prepend=tavg[:,:,-1:])  #KLG\n",
    "        ta_diff=np.diff(tavg,n=1,axis=2,prepend=tavg[:,:,-1:])  #KLG\n",
    "        G = 0.14 * ta_diff  #KLG\n",
    "        del ta_diff\n",
    "\n",
    "        print('et0ady')\n",
    "        # (g) calculate aerodynamic and radiation terms of ET0\n",
    "        et0ady = gam/(dl+gamst) * 900./(tavg+273.) * self.u2m * (es-ea)\n",
    "        del gam,tavg,es,ea\n",
    "\n",
    "        print('et0rad')\n",
    "        et0rad = dl/(dl+gamst) * (rn-G) / lam\n",
    "        del dl,gamst,rn,G,lam\n",
    "\n",
    "        print('et0')\n",
    "        et0 = et0ady + et0rad\n",
    "        del et0ady,et0rad\n",
    "\n",
    "        print('et0.where')\n",
    "        # et0[et0 < 0] = 0\n",
    "        # if self.parallel:\n",
    "        #     et0=da.where(et0<0,0,et0)\n",
    "        # else:\n",
    "        #     et0=np.where(et0<0,0,et0)\n",
    "        et0=np.where(et0<0,0,et0)\n",
    "\n",
    "        return et0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pet(doy_start, doy_end, chunk3D, latitude, elevation, min_temp, max_temp, wind_speed, short_rad, rel_humidity):\n",
    "    print('initializing obj_eto')\n",
    "    obj_eto = ETOCalc(doy_start, doy_end, latitude, elevation, chunk3D)  #KLG\n",
    "    \n",
    "    print('adjusting short_rad units')\n",
    "    shortrad_daily_MJm2day = (short_rad*3600.*24.)/1000000. # convert w/m2 to MJ/m2/day  #KLG    \n",
    "\n",
    "    print('obj_eto.setClimateData')\n",
    "    obj_eto.setClimateData(min_temp, max_temp, wind_speed, shortrad_daily_MJm2day, rel_humidity)  #KLG\n",
    "\n",
    "    pet_daily= obj_eto.calculateETO()\n",
    "    return pet_daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDailyClimateData(self, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity):\n",
    "\n",
    "    if self.parallel:\n",
    "        print('rechunking')\n",
    "        min_temp=min_temp.rechunk(chunks=self.chunk3D).to_delayed()\n",
    "        max_temp=max_temp.rechunk(chunks=self.chunk3D).to_delayed()\n",
    "        # precipitation=precipitation.rechunk(chunks=self.chunk3D)\n",
    "        short_rad=short_rad.rechunk(chunks=self.chunk3D)\n",
    "        wind_speed=wind_speed.rechunk(chunks=self.chunk3D)\n",
    "        rel_humidity=rel_humidity.rechunk(chunks=self.chunk3D)\n",
    "        # latitude and elevation are already chunked correctly    \n",
    "\n",
    "        print('removing negative data values')\n",
    "        rel_humidity=da.where(rel_humidity > 0.99, 0.99,rel_humidity)\n",
    "        rel_humidity=da.where(rel_humidity < 0.05, 0.05,rel_humidity)\n",
    "        short_rad=da.where(short_rad < 0, 0, short_rad)\n",
    "        # wind_speed=da.where(wind_speed < 0, 0, wind_speed)  \n",
    "        wind_speed=da.where(wind_speed < 0.5, 0.5, wind_speed)\n",
    "\n",
    "        rel_humidity=rel_humidity.to_delayed()\n",
    "        short_rad=short_rad.to_delayed()\n",
    "        wind_speed=wind_speed.to_delayed()\n",
    "\n",
    "        latitude=self.latitude.to_delayed()\n",
    "        elevation=self.elevation.to_delayed()        \n",
    "\n",
    "    self.doy_start=1  #KLG\n",
    "    self.doy_end=min_temp.shape[2]  #KLG\n",
    "\n",
    "    task_list=[dask.delayed(compute_pet)(self.doy_start,self.doy_end,self.chunk3D, lat_chunk, elev_chunk, minT_chunk, maxT_chunk, wind_chunk, rad_chunk, rhum_chunk) for lat_chunk, elev_chunk, minT_chunk, maxT_chunk, wind_chunk, rad_chunk, rhum_chunk in zip(latitude[0,:], elevation[0,:], min_temp[0,:], max_temp[0,:], wind_speed[0,:], short_rad[0,:], rel_humidity[0,:])]\n",
    "\n",
    "    result_chunks=dask.compute(*task_list)\n",
    "    self.pet_daily=np.concat(result_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setDailyClimateData(clim_reg, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDailyClimateData(self, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity):\n",
    "    # print('converting inputs to dask arrays')\n",
    "    # nchunks=238\n",
    "    # nlons=min_temp.shape[1]\n",
    "    # chunk_nlons=int(np.ceil(nlons/nchunks))\n",
    "    # chunks3D=(-1,chunk_nlons,-1)\n",
    "    # chunks2D=(-1,chunk_nlons)\n",
    "    # print(nchunks,nlons,chunk_nlons,chunks3D)\n",
    "\n",
    "    # min_temp=da.from_array(min_temp,chunks=chunks3D)\n",
    "    # max_temp=da.from_array(max_temp,chunks=chunks3D)\n",
    "    # precipitation=da.from_array(precipitation,chunks=chunks3D)\n",
    "    # short_rad=da.from_array(short_rad,chunks=chunks3D)\n",
    "    # wind_speed=da.from_array(wind_speed,chunks=chunks3D)\n",
    "    # rel_humidity=da.from_array(rel_humidity,chunks=chunks3D)\n",
    "    # latitude=da.from_array(self.latitude,chunks=chunks2D)\n",
    "    # elevation=da.from_array(self.elevation,chunks=chunks2D)\n",
    "    if self.parallel:\n",
    "        print('rechunking')\n",
    "        min_temp=min_temp.rechunk(chunks=self.chunk3D)\n",
    "        max_temp=max_temp.rechunk(chunks=self.chunk3D)\n",
    "        precipitation=precipitation.rechunk(chunks=self.chunk3D)\n",
    "        short_rad=short_rad.rechunk(chunks=self.chunk3D)\n",
    "        wind_speed=wind_speed.rechunk(chunks=self.chunk3D)\n",
    "        rel_humidity=rel_humidity.rechunk(chunks=self.chunk3D)\n",
    "        # latitude and elevation are already chunked correctly\n",
    "\n",
    "        # min_temp=min_temp.persist()\n",
    "        # max_temp=max_temp.persist()\n",
    "        # precipitation=precipitation.persist()\n",
    "        # short_rad=short_rad.persist()\n",
    "        # wind_speed=wind_speed.persist()\n",
    "        # rel_humidity=rel_humidity.persist()        \n",
    "\n",
    "        print('removing negative data values')\n",
    "        rel_humidity=da.where(rel_humidity > 0.99, 0.99,rel_humidity)\n",
    "        rel_humidity=da.where(rel_humidity < 0.05, 0.05,rel_humidity)\n",
    "        short_rad=da.where(short_rad < 0, 0, short_rad)\n",
    "        wind_speed=da.where(wind_speed < 0, 0, wind_speed)  \n",
    "\n",
    "\n",
    "    else:\n",
    "        print('removing negative data values')\n",
    "        rel_humidity[rel_humidity > 0.99] = 0.99\n",
    "        rel_humidity[rel_humidity < 0.05] = 0.05\n",
    "        short_rad[short_rad < 0] = 0\n",
    "        wind_speed[wind_speed < 0] = 0\n",
    "\n",
    "    self.doy_start=1  #KLG\n",
    "    self.doy_end=min_temp.shape[2]  #KLG\n",
    "\n",
    "\n",
    "\n",
    "    # calculation of reference evapotranspiration (ETo)  #KLG\n",
    "    print('initializing obj_eto')\n",
    "    obj_eto = ETOCalc(self.doy_start, self.doy_end, self.latitude, self.elevation,self.chunk3D)  #KLG\n",
    "\n",
    "    print('adjusting short_rad units')\n",
    "    shortrad_daily_MJm2day = (short_rad*3600.*24.)/1000000. # convert w/m2 to MJ/m2/day  #KLG\n",
    "    # shortrad_daily_MJm2day=shortrad_daily_MJm2day.persist()\n",
    "    print('obj_eto.setClimateData')\n",
    "    obj_eto.setClimateData(min_temp, max_temp, wind_speed, shortrad_daily_MJm2day, rel_humidity)  #KLG\n",
    "    del rel_humidity,short_rad,wind_speed,shortrad_daily_MJm2day  #KLG\n",
    "    # print('pet equations')\n",
    "    # pet_daily= obj_eto.calculateETO()   #KLG\n",
    "    # print(pet_daily)\n",
    "    print('computing pet')\n",
    "    if self.parallel:\n",
    "        # self.pet_daily=pet_daily.compute()\n",
    "        self.pet_daily= obj_eto.calculateETO().compute()   #KLG\n",
    "        # self.pet_daily= obj_eto.calculateETO()\n",
    "\n",
    "    else:\n",
    "        self.pet_daily= obj_eto.calculateETO()\n",
    "    del obj_eto\n",
    "\n",
    "    # print('computing meanT, meanT_daily_sealevel, P_by_PET_daily')\n",
    "    # self.meanT_daily = 0.5*(min_temp+max_temp)  #KLG\n",
    "\n",
    "    # # sea level temperature\n",
    "    # # P over PET ratio (to eliminate nan in the result, nan is replaced with zero)\n",
    "    # if self.parallel:\n",
    "    #     self.meanT_daily_sealevel = self.meanT_daily + (da.tile(self.elevation[:,:,np.newaxis],(1,1,self.doy_end)).rechunk(chunks=self.chunk3D)/100*0.55)\n",
    "    #     self.P_by_PET_daily = da.nan_to_num(precipitation / self.pet_daily)\n",
    "    # else:\n",
    "    #     self.meanT_daily_sealevel = self.meanT_daily + np.expand_dims(self.elevation/100*0.55,axis=2) # automatic broadcasting #KLG        \n",
    "    #     self.P_by_PET_daily = np.nan_to_num(precipitation / self.pet_daily)\n",
    "\n",
    "    # self.set_monthly = False\n",
    "\n",
    "    # print('computing interp_daily_temp')\n",
    "    # # smoothed daily temperature\n",
    "    # # create a mask of all 1's if the user doesn't provide a mask\n",
    "    # if self.set_mask:\n",
    "    #     mask=self.im_mask\n",
    "    # else:\n",
    "    #     mask=np.ones((self.im_height,self.im_width),dtype='int')\n",
    "\n",
    "    # obj_utilities = UtilitiesCalc.UtilitiesCalc(self.chunk2D,self.chunk3D)  #KLG\n",
    "\n",
    "    # # if self.parallel:\n",
    "    # self.interp_daily_temp=obj_utilities.smoothDailyTemp(self.doy_start,self.doy_end, mask, self.meanT_daily,self.chunk3D)\n",
    "    # # else:\n",
    "    #     # self.interp_daily_temp=obj_utilities.smoothDailyTemp(self.doy_start,self.doy_end, mask, self.meanT_daily)  \n",
    "\n",
    "    # print('copying maxT_daily,minT_daily,totalPrec_daily')\n",
    "    # self.maxT_daily = max_temp\n",
    "    # # self.minT_daily = min_temp\n",
    "    # self.totalPrec_daily = precipitation  #KLG    \n",
    "    \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setDailyClimateData(clim_reg, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.pet_daily.shape,clim_reg.nchunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels=clim_reg.__dict__.keys()\n",
    "data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clim_reg.set_mask:\n",
    "    mask=clim_reg.im_mask\n",
    "else:\n",
    "    mask=np.ones((clim_reg.im_height,clim_reg.im_width),dtype='int')\n",
    "\n",
    "# this takes 100s\n",
    "# days = np.arange(clim_reg.doy_start,clim_reg.doy_end+1) # x values  #KLG\n",
    "# mask3D = np.tile(mask[:,:,np.newaxis], (1,1,days.shape[0]))  #KLG\n",
    "# data=np.where(mask3D==0,0,clim_reg.meanT_daily)   #KLG\n",
    "# data2D=data.transpose(2,0,1).reshape(days.shape[0],-1) # every column is a set of y values  #KLG\n",
    "# del data  #KLG\n",
    "# quad_spl=np.polynomial.polynomial.polyfit(days,data2D,deg=5)  #KLG\n",
    "# interp_daily_temp=np.polynomial.polynomial.polyval(days,quad_spl)  #KLG\n",
    "# interp_daily_temp=interp_daily_temp.reshape(mask3D.shape[0],mask3D.shape[1],-1)  #KLG\n",
    "# interp_daily_temp=np.where(mask3D==0,np.nan,interp_daily_temp)        \n",
    "# interp_daily_temp.shape\n",
    "\n",
    "# this takes 33s\n",
    "# days = np.arange(clim_reg.doy_start,clim_reg.doy_end+1) # x values  #KLG\n",
    "# mask3D = da.tile(mask[:,:,np.newaxis], (1,1,days.shape[0])).rechunk(chunks=clim_reg.chunk3D)  #KLG\n",
    "# data=da.where(mask3D==0,0,clim_reg.meanT_daily)   #KLG\n",
    "# nlats=data.shape[0]\n",
    "# data2D=data.transpose(2,0,1).reshape(days.shape[0],-1).rechunk(chunks=(clim_reg.chunk3D[0],clim_reg.chunk3D[1]*nlats)) # every column is a set of y values  #KLG\n",
    "# coefs=np.polynomial.polynomial.polyfit(days,data2D,deg=5)  #KLG\n",
    "# interp_daily_temp=np.polynomial.polynomial.polyval(days,coefs)  #KLG\n",
    "# interp_daily_temp.shape\n",
    "\n",
    "\n",
    "# # this takes 33s\n",
    "# days = np.arange(clim_reg.doy_start,clim_reg.doy_end+1) # x values  #KLG\n",
    "# mask3D = da.tile(mask[:,:,np.newaxis], (1,1,days.shape[0])).rechunk(chunks=clim_reg.chunk3D)  #KLG\n",
    "# data=da.where(mask3D==0,0,clim_reg.meanT_daily)   #KLG\n",
    "# nlats=data.shape[0]\n",
    "# data2D=data.transpose(2,0,1).reshape(days.shape[0],-1).rechunk(chunks=(clim_reg.chunk3D[0],clim_reg.chunk3D[1]*nlats))#(-1,-1)) # every column is a set of y values  #KLG\n",
    "# def polyfit(x,y,deg):\n",
    "#     coefs=np.polynomial.polynomial.polyfit(x,y,deg=deg)\n",
    "#     return coefs\n",
    "# deg=5\n",
    "# coefs=da.apply_gufunc(polyfit,\"(t),(t,s),()->(d,s)\",days,data2D,deg,output_dtypes='float32',output_sizes={'t':data2D.shape[0],'s':data2D.shape[1],'d':deg+1},vectorize=True)#.compute()\n",
    "# def polyval(x,coefs):\n",
    "#     spline=np.polynomial.polynomial.polyval(x,coefs)    \n",
    "#     return spline\n",
    "# interp_daily_temp=da.apply_gufunc(polyval,\"(t),(d,s)->(s,t)\",days,coefs,output_dtypes='float32',output_sizes={'t':data2D.shape[0],'s':data2D.shape[1],'d':deg+1},vectorize=True).compute()\n",
    "# interp_daily_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clim_reg.set_mask:\n",
    "    mask=clim_reg.im_mask\n",
    "else:\n",
    "    mask=np.ones((clim_reg.im_height,clim_reg.im_width),dtype='int')\n",
    "\n",
    "days1D = np.arange(clim_reg.doy_start,clim_reg.doy_end+1) # x values  #KLG\n",
    "mask3D = da.tile(mask[:,:,np.newaxis], (1,1,days1D.shape[0])).rechunk(chunks=clim_reg.chunk3D)  #KLG\n",
    "data=da.where(mask3D==0,0,clim_reg.meanT_daily)   #KLG\n",
    "nlats=data.shape[0]\n",
    "data2D=data.transpose(2,0,1).reshape(days1D.shape[0],-1).rechunk({0:-1,1:'auto'})\n",
    "\n",
    "days1D=dask.delayed(days1D)\n",
    "partitions=data2D.to_delayed()\n",
    "\n",
    "def polyfit_polyval(x,y,deg):\n",
    "    coefs=np.polynomial.polynomial.polyfit(x,y,deg=deg)         \n",
    "    spline=np.polynomial.polynomial.polyval(x,coefs) \n",
    "    return spline   \n",
    "\n",
    "deg=5\n",
    "delayed_values = [dask.delayed(polyfit_polyval)(days1D,part,deg) for part in partitions[0,:]]\n",
    "results=dask.compute(*delayed_values)\n",
    "\n",
    "interp_daily_temp=np.concatenate(results).reshape(mask3D.shape[0],mask3D.shape[1],-1)  #KLG\n",
    "# interp_daily_temp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[0].shape\n",
    "test=np.concatenate(results)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clim_reg.set_mask:\n",
    "    mask=clim_reg.im_mask\n",
    "else:\n",
    "    mask=np.ones((clim_reg.im_height,clim_reg.im_width),dtype='int')\n",
    "\n",
    "days1D = np.arange(clim_reg.doy_start,clim_reg.doy_end+1) # x values  #KLG\n",
    "# days1D = da.arange(clim_reg.doy_start,clim_reg.doy_end+1,chunks=-1) # x values  #KLG\n",
    "mask3D = np.tile(mask[:,:,np.newaxis], (1,1,days1D.shape[0])) #KLG\n",
    "data=np.where(mask3D==0,0,clim_reg.meanT_daily)   #KLG\n",
    "data2D=data.transpose(2,0,1).reshape(days1D.shape[0],-1)#.rechunk(chunks=-1)#(clim_reg.chunk3D[0],clim_reg.chunk3D[1]*nlats))#(-1,-1)) # every column is a set of y values  #KLG\n",
    "ngrids=data2D.shape[1]\n",
    "# days2D = da.from_array(np.tile(days1D[:,np.newaxis],(1,data2D.shape[1])),chunks=(clim_reg.chunk3D[0],clim_reg.chunk3D[1]*nlats)) # x values  #KLG\n",
    "\n",
    "# @dask.delayed\n",
    "# def polyfit(x,y,deg):\n",
    "#     coefs=np.polynomial.polynomial.polyfit(x,y,deg=deg)\n",
    "#     return coefs\n",
    "\n",
    "# def polyval(x,coefs):\n",
    "#     spline=np.polynomial.polynomial.polyval(x,coefs)    \n",
    "#     return spline   \n",
    "# days1D=dask.persist(days1D)\n",
    "# data2D=dask.persist(data2D)\n",
    "days1D=dask.delayed(days1D)\n",
    "data2D=dask.delayed(data2D)\n",
    "\n",
    "@dask.delayed\n",
    "def polyfit_polyval(x,y,deg):\n",
    "    coefs=np.polynomial.polynomial.polyfit(x,y,deg=deg)         \n",
    "    spline=np.polynomial.polynomial.polyval(x,coefs) \n",
    "    return spline   \n",
    "\n",
    "deg=5\n",
    "nlats_block=int(np.ceil(ngrids/clim_reg.nchunks))\n",
    "# ngrids,clim_reg.nchunks,nlats_block\n",
    "\n",
    "# interp_T=np.empty((data2D.shape[1],data2D.shape[0]),dtype='float32')\n",
    "\n",
    "task_list=[]\n",
    "for ichunk in range(clim_reg.nchunks)[0:3]:\n",
    "    istart=ichunk*nlats_block\n",
    "    if ichunk < clim_reg.nchunks-1:\n",
    "        iend=istart+nlats_block\n",
    "    else:\n",
    "        iend=ngrids\n",
    "    print(istart,iend)\n",
    "    interp_task=polyfit_polyval(days1D,data2D[:,istart:iend],deg)\n",
    "    task_list.append(interp_task)\n",
    "print('computing')\n",
    "interp_list=dask.compute(*task_list)\n",
    "\n",
    "interp_list[0].shape\n",
    "# interp_temp_daily=np.concat(interp_list,axis=1)\n",
    "\n",
    "# task_list=[]\n",
    "# for ichunk in range(clim_reg.nchunks)[0:3]:\n",
    "#     istart=ichunk*nlats_block\n",
    "#     if ichunk < clim_reg.nchunks-1:\n",
    "#         iend=istart+nlats_block\n",
    "#     else:\n",
    "#         iend=ngrids\n",
    "\n",
    "#     interp_task=polyval(days1D,coefs_list[ichunk])\n",
    "#     task_list.append(coefs_task)\n",
    "# coefs_list=dask.compute(*task_list)\n",
    "\n",
    "#     print(coefs.T)\n",
    "\n",
    "        # T=polyval(days1D,coefs)\n",
    "\n",
    "    # print(istart,iend)\n",
    "# days1D.shape,data2D.shape\n",
    "\n",
    "# for block in data2D.blocks:\n",
    "#     coef_block=polyfit(days1D,block)\n",
    "\n",
    "# data2D.blocks[0,1]\n",
    "\n",
    "# coefs=da.apply_gufunc(polyfit,\"(t),(t,s),()->(d,s)\",days,data2D,deg,output_dtypes='float32',output_sizes={'t':data2D.shape[0],'s':data2D.shape[1],'d':deg+1},vectorize=True)#.compute()\n",
    "# coefs=da.map_blocks(polyfit,days2D,data2D,dtype='float32',chunks=(deg+1,clim_reg.chunk3D[1]*nlats),drop_axis=0,new_axis=0,meta=np.empty((6,data2D.shape[1]),dtype='float32'))#.compute()\n",
    "# coefs.shape\n",
    "# def polyval(x,coefs):\n",
    "#     spline=np.polynomial.polynomial.polyval(x,coefs)    \n",
    "#     return spline\n",
    "# # interp_daily_temp=da.apply_gufunc(polyval,\"(t),(d,s)->(s,t)\",days,coefs,output_dtypes='float32',output_sizes={'t':data2D.shape[0],'s':data2D.shape[1],'d':deg+1},vectorize=True).compute()\n",
    "# interp_daily_temp=da.apply_gufunc(polyval,\"(t),(d,s)->(s,t)\",days1D,coefs,output_dtypes='float32',output_sizes={'t':data2D.shape[0],'s':data2D.shape[1],'d':deg+1},vectorize=True,allow_rechunk=True).compute()\n",
    "# interp_daily_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2D=min_temp.transpose(2,0,1).reshape(365,-1).rechunk(chunks=(-1,7200)) # every column is a set of y values  #KLG\n",
    "data2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.pet_daily.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def setDailyClimateData(self, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity):\n",
    "        \"\"\"Load DAILY climate data into the Class and calculate the Reference Evapotranspiration (ETo)\n",
    "\n",
    "        Args:\n",
    "            min_temp (3D NumPy): Daily minimum temperature [Celcius]\n",
    "            max_temp (3D NumPy): Daily maximum temperature [Celcius]\n",
    "            precipitation (3D NumPy): Daily total precipitation [mm/day]\n",
    "            short_rad (3D NumPy): Daily solar radiation [W/m2]\n",
    "            wind_speed (3D NumPy): Daily windspeed at 2m altitude [m/s]\n",
    "            rel_humidity (3D NumPy): Daily relative humidity [percentage decimal, 0-1]\n",
    "        \"\"\"\n",
    "        self.doy_start=1  #KLG\n",
    "        self.doy_end=min_temp.shape[2]  #KLG\n",
    "\n",
    "        rel_humidity[rel_humidity > 0.99] = 0.99\n",
    "        rel_humidity[rel_humidity < 0.05] = 0.05\n",
    "        short_rad[short_rad < 0] = 0\n",
    "        wind_speed[wind_speed < 0] = 0\n",
    "                \n",
    "        # self.meanT_daily = np.zeros((self.im_height, self.im_width, 365)) \n",
    "        # self.totalPrec_daily = np.zeros((self.im_height, self.im_width, 365)) \n",
    "        # self.pet_daily = np.zeros((self.im_height, self.im_width, 365))  \n",
    "        self.maxT_daily = max_temp\n",
    "        self.minT_daily = min_temp\n",
    "        self.totalPrec_daily = precipitation  #KLG\n",
    "        del max_temp, min_temp, precipitation  #KLG\n",
    "\n",
    "\n",
    "        # calculation of reference evapotranspiration (ETo)  #KLG\n",
    "        obj_eto = ETOCalc.ETOCalc(self.doy_start, self.doy_end, self.latitude, self.elevation)  #KLG\n",
    "        shortrad_daily_MJm2day = (short_rad*3600.*24.)/1000000. # convert w/m2 to MJ/m2/day  #KLG\n",
    "        obj_eto.setClimateData(self.minT_daily, self.maxT_daily, wind_speed, shortrad_daily_MJm2day, rel_humidity)  #KLG\n",
    "        del rel_humidity,short_rad,wind_speed,shortrad_daily_MJm2day  #KLG\n",
    "        self.pet_daily= obj_eto.calculateETO()   #KLG\n",
    "        del obj_eto\n",
    "\n",
    "        # sea level temperature\n",
    "        # self.meanT_daily_sealevel = self.meanT_daily + np.tile(np.reshape(self.elevation/100*0.55, (self.im_height,self.im_width,1)), (1,1,365))\n",
    "        self.meanT_daily = 0.5*(self.minT_daily+self.maxT_daily)  #KLG\n",
    "        self.meanT_daily_sealevel = self.meanT_daily + np.expand_dims(self.elevation/100*0.55,axis=2) # automatic broadcasting #KLG        \n",
    "\n",
    "        # P over PET ratio (to eliminate nan in the result, nan is replaced with zero)\n",
    "        self.P_by_PET_daily = np.nan_to_num(self.totalPrec_daily / self.pet_daily)\n",
    "        self.set_monthly = False\n",
    "\n",
    "        # smoothed daily temperature\n",
    "        obj_utilities = UtilitiesCalc.UtilitiesCalc()  #KLG\n",
    "\n",
    "        if self.set_mask:\n",
    "            mask=self.im_mask\n",
    "        else:\n",
    "            mask=np.ones((self.im_height,self.im_width),dtype='int')\n",
    "\n",
    "        if self.parallel:\n",
    "            self.interp_daily_temp=obj_utilities.smoothDailyTemp(self.doy_start,self.doy_end, mask, self.meanT_daily,self.chunk3D)\n",
    "        else:\n",
    "            self.interp_daily_temp=obj_utilities.smoothDailyTemp(self.doy_start,self.doy_end, mask, self.meanT_daily)\n",
    "\n",
    "\n",
    "        self.chunk3D=(-1,94,-1)\n",
    "        self.chunk2D=(-1,94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expect ~30 seconds run time for china\n",
    "\n",
    "# start=timer()\n",
    "\n",
    "# if daily:\n",
    "#     clim_reg.setDailyClimateData(\n",
    "#         min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)\n",
    "# else:\n",
    "#     clim_reg.setMonthlyClimateData(\n",
    "#         min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)\n",
    "    \n",
    "# task_time=timer()-start\n",
    "# task_time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Releasing the memory of input climate data -- free up some RAM space'\n",
    "# del(min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all the data in the class instance clim_reg\n",
    "\n",
    "data_labels=clim_reg.__dict__.keys()\n",
    "data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity check\n",
    "# # plot 2D & 3D data, print value of scalars \n",
    "\n",
    "# for key in data_labels:\n",
    "#     print(key)    \n",
    "#     try:\n",
    "#         ndims=len(clim_reg.__getattribute__(key).shape)\n",
    "#         # dims=clim_reg.__getattribute__(key).shape\n",
    "#     except:\n",
    "#         ndims=1\n",
    "#     if ndims==1:\n",
    "#         print(key,'=',clim_reg.__getattribute__(key))\n",
    "#     if ndims==2:\n",
    "#         plt.imshow(clim_reg.__getattribute__(key),interpolation='none')\n",
    "#         plt.colorbar(shrink=0.5)\n",
    "#         plt.title(key)\n",
    "#         plt.show()\n",
    "#     if ndims==3:\n",
    "#         plt.imshow(clim_reg.__getattribute__(key)[:,:,0],interpolation='none')\n",
    "#         plt.colorbar(shrink=0.5)\n",
    "#         plt.title(key)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list=[]\n",
    "# for key in data_labels:\n",
    "#     data_list.append(clim_reg.__getattribute__(key))\n",
    "\n",
    "# data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fut_climreg=dask.persist(*data_list)\n",
    "\n",
    "# fut_climreg.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da_vars=clim_reg.meanT_daily\n",
    "# da_vars.store(clim_reg.meanT_daily,return_stored=True)\n",
    "# da_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fut_climreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: After loading the data into the *clim_reg* Class, all the parameters will be converted to DAILY DATA and calculated as other parameters. \n",
    "These new parameters are available and can be called into use as:\n",
    "- *clim_reg.minT_daily* (minimum temperature)\n",
    "- *clim_reg.maxT_daily* (maximum temperature)\n",
    "- *clim_reg.meanT_daily* (mean temperature)\n",
    "- *clim_reg.meanT_daily_sealevel* (mean temperature, corrected to sea-level)\n",
    "- *clim_reg.totalPrec_daily* (total precipitation)\n",
    "- *clim_reg.pet_daily* (reference evapotranspiration, ETo)\n",
    "- *clim_reg.P_by_PET_daily* (ratio of precipitation over ETo)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thermal Climate\n",
    "The Thermal Climate function calculates and classifies latitudinal thermal climate, which will be used later in Module 2 for the assessment of potential crops and land utilization types (LUT) presence in each grid cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~50 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "tclimate = clim_reg.getThermalClimate()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(tclimate, cmap=plt.get_cmap('gist_ncar_r', 12),vmin=-0.3,vmax=12.5,interpolation='none')\n",
    "plt.title('Thermal Climate')\n",
    "plt.colorbar(shrink=0.4)\n",
    "plt.savefig(out_path+\"ThermalClimate.png\",bbox_inches =\"tight\",dpi=300) #Save as PNG image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_utilities.saveRaster(mask_path, out_path+'ThermalClimate_'+revname+'.tif',tclimate) #Save as GeoTIFF raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thermal Zone\n",
    "The thermal zone is classified based on actual temperature which reflects on the temperature regimes of major thermal climates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~35 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "tzone = clim_reg.getThermalZone()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(tzone, cmap=plt.get_cmap('gist_ncar_r', 12),vmin=-0.3,vmax=12.5,interpolation='none')\n",
    "plt.title('Thermal Zones')\n",
    "plt.colorbar(shrink=0.4)\n",
    "plt.savefig(out_path+\"ThermalZone\"+revname+\".png\",bbox_inches =\"tight\",dpi=300) #Save as PNG image\n",
    "plt.show()\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'ThermalZone'+revname+'.tif',tzone) #Save as GeoTIFF raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thermal Length of Growing Period (LGP)\n",
    "The thermal length of growing period (LGPt) is defined as the number of days in a year during which the daily mean temperature (Ta) is conductive to crop growth and development. PyAEZ utilizes the AEZ three standard temperature thresholds for LGPt:\n",
    "- Periods with Ta>0C (LGPt0)\n",
    "- Periods with Ta>5C (LGPt5)  the period conductive to plant growth and development\n",
    "- Periods, and Ta>10C (LGPt10)  a proxy for the period of low risks for late and early frost occurrences and termed frost-free period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~1 second run time for china\n",
    "start=timer()\n",
    "\n",
    "lgpt0 = clim_reg.getThermalLGP0()\n",
    "lgpt5 = clim_reg.getThermalLGP5()\n",
    "lgpt10 = clim_reg.getThermalLGP10()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "#======================\n",
    "# plt.figure(figsize=(20, 4),dpi=300)\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(lgpt0,vmin=0,vmax=366,interpolation='none')\n",
    "plt.title('LGPt 0')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(lgpt5, vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGPt 5')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(lgpt10, vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGPt 10')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.savefig(out_path+\"ThermalLGPs\"+revname+\".png\",\n",
    "            bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "#======================\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'LGPt0_'+revname+'.tif', lgpt0)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'LGPt5_'+revname+'.tif', lgpt5)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'LGPt10_'+revname+'.tif', lgpt10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~1 second run time for china\n",
    "start=timer()\n",
    "\n",
    "tsum0 = clim_reg.getTemperatureSum0()\n",
    "tsum5 = clim_reg.getTemperatureSum5()\n",
    "tsum10 = clim_reg.getTemperatureSum10()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "#======================\n",
    "# plt.figure(1, figsize=(20, 4),dpi=300)\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(tsum0, cmap='hot_r', vmin=0, vmax=11000,interpolation='none')\n",
    "plt.title('T-sumation 0')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(tsum5, cmap='hot_r', vmin=0, vmax=11000,interpolation='none')\n",
    "plt.title('T-sumation 5')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(tsum10, cmap='hot_r', vmin=0, vmax=11000,interpolation='none')\n",
    "plt.title('T-sumation 10')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.savefig(out_path+\"Tsum_\"+revname+\".png\",\n",
    "            bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "#======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_utilities.saveRaster(mask_path, out_path+'tsum0_'+revname+'.tif', tsum0)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'tsum5_'+revname+'.tif', tsum5)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'tsum10_'+revname+'.tif', tsum10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized+parallel: expect ~1 second run time for china\n",
    "# vectorized: expect ~6 seconds run time for china\n",
    "# non-vectorized: expect ~50 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "tprofile = clim_reg.getTemperatureProfile()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "tile_list = ['A1','A2','A3','A4','A5','A6','A7','A8','A9',\n",
    "            'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9']\n",
    "\n",
    "# fig = plt.figure(figsize=(12, 12))\n",
    "fig = plt.figure()\n",
    "for i1 in range(1, 19):\n",
    "    plt.subplot(6, 3, i1)\n",
    "    plt.imshow(tprofile[i1-1],interpolation='none')\n",
    "    plt.title(tile_list[i1-1])\n",
    "    plt.colorbar(shrink=0.8)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(out_path+\"Tprofiles_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1 in range(18):\n",
    "    obj_utilities.saveRaster(mask_path, out_path+'TProfile_' + tile_list[i1] +'_'+revname+'.tif', tprofile[i1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length of Growing Periods (LGPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def test_func1(x,y,z,X,Y,Z,mask):\n",
    "    x=x*2\n",
    "    y=y+3\n",
    "    z=z**2\n",
    "    X=np.where(mask,x,X)\n",
    "    Y=np.where(mask,y,Y)\n",
    "    Z=np.where(mask,z,Z)\n",
    "    return X,Y,Z\n",
    "\n",
    "def test_func2(out1,out2,out3):\n",
    "    out1=out1+10\n",
    "    out2=out2+20\n",
    "    out3=out3+30\n",
    "    return out1,out2,out3\n",
    "\n",
    "@dask.delayed\n",
    "def test_combine(x1,y1,z1,x2,y2,z2,mask1,mask2):\n",
    "    x=np.empty(x1.shape)\n",
    "    y=np.empty(x1.shape)\n",
    "    z=np.empty(x1.shape)\n",
    "    x=np.where(mask1,x1,x)\n",
    "    x=np.where(mask2,x2,x)\n",
    "    y=np.where(mask1,y1,y)\n",
    "    y=np.where(mask2,y2,y)\n",
    "    z=np.where(mask1,z1,z)\n",
    "    z=np.where(mask2,z2,z)        \n",
    "    return x,y,z\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ndays=5\n",
    "x_arr=np.ones((ndays,2,2),dtype='float32')\n",
    "y_arr=np.zeros((ndays,2,2),dtype='float32')\n",
    "z_arr=y_arr-1\n",
    "\n",
    "X=np.empty(x_arr.shape)\n",
    "Y=np.empty(y_arr.shape)\n",
    "Z=np.empty(z_arr.shape)\n",
    "X[:],Y[:],Z[:]=np.nan,np.nan,np.nan\n",
    "\n",
    "# [[1,1],[1,1]]\n",
    "mask1=np.array([[[1,0],[1,1]],[[1,0],[1,1]],[[1,0],[1,1]],[[1,0],[1,1]],[[1,0],[1,1]]])\n",
    "mask2=np.array([[[0,1],[0,0]],[[0,1],[0,0]],[[0,1],[0,0]],[[0,1],[0,0]],[[0,1],[0,0]]])\n",
    "\n",
    "mask1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncats=5\n",
    "for i,cat in enumerate(np.arange(ncats)+1):\n",
    "    print(i,cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list=[]\n",
    "for doy in range(ndays):\n",
    "    # task=test_func1(x_arr,y_arr,z_arr,X,Y,Z,mask1)\n",
    "    # task_list.append(task)\n",
    "    X,Y,Z=test_func1(x_arr,y_arr,z_arr,X,Y,Z,mask1)\n",
    "    # task=test_func1(x_arr,y_arr,z_arr,X,Y,Z,mask2)\n",
    "    # task_list.append(task)\n",
    "    # task=test_combine()\n",
    "    # print(task_list)\n",
    "    # output=dask.compute(*task_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output)\n",
    "output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list=[]\n",
    "for doy in range(ndays):\n",
    "    # out1,out2,out3=test_func1(x_arr,y_arr,z_arr)\n",
    "    task=test_func1(x_arr,y_arr,z_arr)\n",
    "    # task=test_func2(out1,out2,out3)\n",
    "    # task_list.append(task)\n",
    "    output=task.compute()\n",
    "    x_arr=output[0]\n",
    "    y_arr=output[1]\n",
    "    z_arr=output[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=dask.compute(*task_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized+parallel: expect ~66 seconds run time for china\n",
    "# vectorized: expect ~1.5 minutes run time for china\n",
    "# non-vectorized: expect ~6 minutes run time for china\n",
    "start=timer()\n",
    "\n",
    "lgp = clim_reg.getLGP(Sa=100., D=1.)\n",
    "lgp_class = clim_reg.getLGPClassified(lgp)\n",
    "lgp_equv = clim_reg.getLGPEquivalent()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "# fig = plt.figure(figsize=(20, 4))\n",
    "fig = plt.figure()\n",
    "# fig = plt.figure(figsize=(10, 8),dpi=600)\n",
    "plt.subplot(121)\n",
    "plt.imshow(lgp, cmap='viridis', vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGP [days]')\n",
    "plt.colorbar(shrink=0.8)\n",
    "# plt.savefig(out_path+\"LGP_\"+revname+\".png\", bbox_inches=\"tight\", dpi=600)\n",
    "# plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=(20, 8),dpi=600)\n",
    "plt.subplot(122)\n",
    "plt.imshow(lgp_equv, cmap='viridis', vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGP Equivalent [days]')\n",
    "plt.colorbar(shrink=0.8)\n",
    "# plt.savefig(out_path+\"LGP_Equv_\"+revname+\".png\",bbox_inches=\"tight\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(out_path+\"LGP_and_LGP_Equv_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'LGP_'+revname+'.tif', lgp)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'LGPEquivalent_'+revname+'.tif', lgp_equv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Cropping Zone\n",
    "Multiple cropping zones classification is an additional agro-climatic indicator, which relates to the possibility of cultivating multiple sequential crops under rain-fed and irrigated conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~1.5 minutes run time for china\n",
    "start=timer()\n",
    "\n",
    "multi_crop = clim_reg.getMultiCroppingZones(tclimate, lgp, lgpt5, lgpt10, tsum0, tsum10)\n",
    "multi_crop_rainfed = multi_crop[0]  # for rainfed conditions\n",
    "multi_crop_irr = multi_crop[1]  # for irrigated conditions\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(multi_crop_irr, cmap=plt.get_cmap('gist_ncar_r', 9), vmin=-0.2, vmax=8.4,interpolation='none')\n",
    "plt.title('Multi Cropping Zone - IRR')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"multicrop_irr_\"+revname+\".png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(multi_crop_rainfed,cmap=plt.get_cmap('gist_ncar_r', 9), vmin=-0.2, vmax=8.4,interpolation='none')\n",
    "plt.title('Multi Cropping Zone - RAINFED')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"multicrop_rain_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'multicrop_irr_'+revname+'.tif', multi_crop_irr)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'multicrop_rain_'+revname+'.tif', multi_crop_rainfed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Air Frost Index and Permafrost Evaluation\n",
    "Occurrence of continuous or discontinuous permafrost conditions are used in the suitability assessment. Permafrost areas are characterized by sub-soil at or below the freezing point for two or more years. In this section, PyAEZ utilizes the air frost index (FI) which is used to characterize climate-derived permafrost condition into 4 classes: \n",
    "1) Continuous permafrost\n",
    "2) Discontinuous permafrost \n",
    "3) Sporadic permafrost\n",
    "4) No permafrost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~2 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "permafrost_eval = clim_reg.AirFrostIndexandPermafrostEvaluation()\n",
    "frost_index = permafrost_eval[0]\n",
    "permafrost = permafrost_eval[1]\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(frost_index, cmap=plt.get_cmap('tab20b', 11), vmin=-0.05, vmax=1.05,interpolation='none')\n",
    "plt.title('Frost Index')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"frost_index_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(permafrost, cmap=plt.get_cmap('tab20b', 5), vmin=-0.5, vmax=4.3,interpolation='none')\n",
    "plt.title('Permafrost Evaluation')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"permafrost_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'frost_index_'+revname+'.tif', frost_index)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'permafrost_'+revname+'.tif', permafrost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fallow period requirement\n",
    "Fallow is an agricultural technique that consists of not sowing the arable land during one or more growing seasons. In AEZ framework, the fallow factors have been established by main crop groups and environmental conditions. The crop groups include cereals, legumes, roots and tubers, and a miscellaneous group consisting of long-term annuals/perennials. The fallow factors are expressed as percentage of time during the fallow-cropping cycle the land must be under fallow. PyAEZ determines the fallow requirements using Thermal Zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# expect ~15 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "tzone_fallow = clim_reg.TZoneFallowRequirement(tzone)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(tzone_fallow, cmap=plt.get_cmap('tab10', 7), vmin=-0.5, vmax=6.3,interpolation='none')\n",
    "plt.title('Fallow Requirement')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"fallow_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'fallow_'+revname+'.tif', tzone_fallow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dtypes of all outputs\n",
    "outputs=[tclimate,tzone,lgpt0,lgpt5,lgpt10,tsum0,tsum5,tsum10,tprofile,lgp,lgp_class,lgp_equv,multi_crop_rainfed,multi_crop_irr,frost_index,permafrost,tzone_fallow]\n",
    "dtypes=[]\n",
    "for var in outputs:\n",
    "    # for arrays\n",
    "    try:\n",
    "        dt=var.dtype\n",
    "        dtypes.append(dt)\n",
    "    # for lists of arrays\n",
    "    except:\n",
    "        for v in var:\n",
    "            dt=v.dtype\n",
    "            dtypes.append(dt)\n",
    "\n",
    "print(dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agro-ecological zones classification\n",
    "The agro-ecological zones (AEZ) methodology provides a framework for establishing a spatial inventory of land resources compiled from global/national environmental data sets and assembled to quantify multiple spatial characteristics required for the assessments of land productivity under location-specific agro-ecological conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't run until we have the global soil_terrain_lulc\n",
    "\n",
    "# expect ~ minutes run time for global\n",
    "start=timer()\n",
    "\n",
    "aez = clim_reg.AEZClassification(\n",
    "    tclimate, lgp, lgp_equv, lgpt5, soil_terrain_lulc, permafrost)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now visualizing result\n",
    "fig = plt.figure(dpi=600)\n",
    "plt.imshow(aez, cmap=plt.get_cmap('rainbow', 59), vmin=0, vmax=59,interpolation=None)\n",
    "plt.title('Agro-ecological Zonation')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"aez_\"+revname+\".png\",bbox_inches=\"tight\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'aez_'+revname+'.tif', aez)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### END OF MODULE 1: CLIMATE REGIME\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('pyaez_dask')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "65e72b0120c35d75cf65cfd3d4805280e35b271cd085ff832a3f7fa98db0a8ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
