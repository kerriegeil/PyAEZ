{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook I - Climate Regime\n",
    "<hr>\n",
    "This module performs climate data analysis and compiling general agro-climatic indicators. These general agro-climatic indicators summarize climatic profiles in the study area for each grid. The key input data for this module is the climatic data, and the geographical and terrain data.\n",
    "\n",
    "Prepared by Geoinformatics Center, AIT\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "# psutil.virtual_memory()\n",
    "\n",
    "psutil.virtual_memory().free/1E9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will import the specific Python packages we need for PyAEZ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import supporting libraries'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "import os\n",
    "try:\n",
    "    from osgeo import gdal\n",
    "except:\n",
    "    import gdal\n",
    "import sys\n",
    "\n",
    "from time import time as timer\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray as rio\n",
    "\n",
    "import dask.array as da\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# branch version tag\n",
    "revname='v21pv'\n",
    "\n",
    "# # HPC Orion\n",
    "# # Replace with path to your PyAEZ folder under your username\n",
    "# work_dir = '/work/hpc/users/kerrie/UN_FAO/repos/PyAEZ/pyaez2.1_vectorize/'\n",
    "# # Replace with whatever location you want to output data under your username\n",
    "# out_path = '/work/hpc/users/kerrie/UN_FAO/pyaez_results/china_8110/'+revname+'/' \n",
    "# # these are the same for everyone on HPC Orion\n",
    "# data_dir = '/work/hpc/datasets/un_fao/pyaez/china_8110/daily/npy/'\n",
    "# maskfile = '/work/hpc/datasets/un_fao/pyaez/china_static/netcdf/mask.nc'\n",
    "# elevfile = '/work/hpc/datasets/un_fao/pyaez/china_static/tif/elev.tif'\n",
    "\n",
    "\n",
    "# # Kerrie desktop\n",
    "work_dir = 'K:/projects/unfao/pyaez_gaez/repos/PyAEZ_kerrie/PyAEZ/pyaez2.1_parvec/' # path to your PyAEZ repo\n",
    "out_path = work_dir+'NB1outputs/' # path for saving output data\n",
    "data_dir = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_china_03272023/npy/' # path to your data\n",
    "maskfile = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_china_03272023/tif/mask.tif'# subset for no antarctica, 1800 lats\n",
    "elevfile = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_china_03272023/tif/elev.tif'\n",
    "\n",
    "# work_dir = 'K:/projects/unfao/pyaez_gaez/repos/PyAEZ_kerrie/PyAEZ/pyaez2.1_parvec/' # path to your PyAEZ repo\n",
    "# out_path = work_dir+'NB1outputs/' # path for saving output data\n",
    "# data_dir = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_global_NOTPRODUCTION/npy/' # path to your data\n",
    "# maskfile = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_global_NOTPRODUCTION/tif/mask_2268708_5m.tif'# subset for no antarctica, 1800 lats\n",
    "# elevfile = 'C://Users/kerrie.WIN/Documents/data/pyAEZ_data_inputs_global_NOTPRODUCTION/tif/Elevation_2268708_5m.tif'\n",
    "\n",
    "\n",
    "# # Kerrie laptop china\n",
    "# work_dir = 'C://Users/kerrie/Documents/01_LocalCode/repos/PyAEZ/pyaez2.1_parvec/' # path to your PyAEZ repo\n",
    "# out_path = work_dir+'NB1outputs/' # path for saving output data\n",
    "# # data_dir = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/china/npy/' # path to your data\n",
    "# # maskfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/china/tif/mask.tif'# subset for no antarctica, 1800 lats\n",
    "# # elevfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/china/tif/elev.tif'\n",
    "# data_dir = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/15GB/' # path to your data\n",
    "# maskfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/15GB/mask.tif'# subset for no antarctica, 1800 lats\n",
    "# elevfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/15GB/elev.tif'\n",
    "\n",
    "# Kerrie laptop global\n",
    "# work_dir = 'C://Users/kerrie/Documents/01_LocalCode/repos/PyAEZ/pyaez2.1_parvec/' # path to your PyAEZ repo\n",
    "# out_path = work_dir+'NB1outputs/' # path for saving output data\n",
    "# data_dir = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/global_NOTPRODUCTION/npy/' # path to your data\n",
    "# maskfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/global_NOTPRODUCTION/tif/mask_2268708_5m.tif'# subset for no antarctica, 1800 lats\n",
    "# elevfile = 'C://Users/kerrie/Documents/02_LocalData/pyAEZ_input_data/global_NOTPRODUCTION/tif/Elevation_2268708_5m.tif'\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(out_path)\n",
    "if not isExist:\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(out_path)\n",
    "   print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# Import Module 1 and initate Class intance\n",
    "# from pyaez import ClimateRegime\n",
    "# clim_reg = ClimateRegime.ClimateRegime()\n",
    "\n",
    "# # Importing UtilitiesCalc\n",
    "# from pyaez import UtilitiesCalc\n",
    "# obj_util = UtilitiesCalc.UtilitiesCalc()\n",
    "sys.path.append(work_dir)\n",
    "# import ClimateRegime_v21pv as ClimateRegime\n",
    "import ClimateRegime_test as ClimateRegime\n",
    "clim_reg = ClimateRegime.ClimateRegime()\n",
    "\n",
    "# import UtilitiesCalc_v21pv as UtilitiesCalc\n",
    "import UtilitiesCalc_test as UtilitiesCalc\n",
    "obj_utilities=UtilitiesCalc.UtilitiesCalc()\n",
    "\n",
    "\n",
    "# import UtilitiesCalc_v21pv as UtilitiesCalc\n",
    "import LGPCalc_test as LGPCalc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428, 741, 365) (428, 741)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kerrie.WIN\\.conda\\envs\\pyaez_dask\\Lib\\site-packages\\osgeo\\gdal.py:287: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.012753963470458984"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect 2 seconds run time for china\n",
    "# expect s run time for global\n",
    "\n",
    "start=timer()\n",
    "\n",
    "max_temp = da.from_npy_stack(data_dir+'Tmax-2m365/').astype('float32')  # maximum temperature\n",
    "min_temp = da.from_npy_stack(data_dir+'Tmin-2m365/').astype('float32')  # minimum temperature\n",
    "precipitation = da.from_npy_stack(data_dir+'Precip365/').astype('float32')  # precipitation\n",
    "rel_humidity = da.from_npy_stack(data_dir+'Rhum365/').astype('float32')  # relative humidity\n",
    "wind_speed = da.from_npy_stack(data_dir+'Wind-2m365/').astype('float32') # wind speed measured at two meters\n",
    "short_rad = da.from_npy_stack(data_dir+'Srad365/').astype('float32')  # shortwave radiation\n",
    "mask=da.from_array(gdal.Open(maskfile).ReadAsArray())\n",
    "elevation=da.from_array(gdal.Open(elevfile).ReadAsArray())\n",
    "\n",
    "print(min_temp.shape,mask.shape)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.780753664"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(max_temp.nbytes+min_temp.nbytes+precipitation.nbytes+rel_humidity.nbytes+wind_speed.nbytes+short_rad.nbytes+mask.nbytes+elevation.nbytes)/1E9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Area-Of-Interest's geographical extents\n",
    "\n",
    "# if lat_min/lat_max values defined below are located at pixel center --> set lat_centers to True \n",
    "# if they are located at the exterior pixel edge --> set lat_centers to False\n",
    "lat_centers=True \n",
    "\n",
    "# provide min and max latitudes (either set manually or read from a data file)\n",
    "# lat_min = 18.04167\n",
    "# lat_max = 53.625\n",
    "lats=rio.open_rasterio(maskfile)['y'].data   # get array of latitudes from maskfile\n",
    "lat_min = np.trunc(lats.min()*100000)/100000 # min lat value at pixel center, limit precision to 5 decimal places\n",
    "lat_max = np.trunc(lats.max()*100000)/100000 # max lat value at pixel center, limit precision 5 decimal places\n",
    "\n",
    "# mask information\n",
    "mask_value = 0  # pixel value in admin_mask to exclude from the analysis\n",
    "mask_path=maskfile\n",
    "\n",
    "# time resolution information\n",
    "daily = True #Type of climate data = True: daily, False: monthly\n",
    "parallel=True#False#True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the imported data into the Object Class ('*clim_reg*' Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002992391586303711"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect >1s run time for china\n",
    "start=timer()\n",
    "\n",
    "clim_reg.setParallel(max_temp,parallel)#,nchunks=288)#,nchunks=864)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect >1s run time for china\n",
    "start=timer()\n",
    "\n",
    "clim_reg.setStudyAreaMask(mask, mask_value)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060452938079833984"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expect >1s run time for china\n",
    "start=timer()\n",
    "\n",
    "clim_reg.setLocationTerrainData(lat_min, lat_max, lat_centers, elevation) #KLG\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, (-1, 93, -1), 58.11384)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clim_reg.nchunks, clim_reg.chunk3D, clim_reg.chunksize3D_MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in ClimateRegime, computing chunk_shapes in parallel\n",
      "in ClimateRegime, computing pet_daily in parallel\n",
      "in UtlitiesCalc, computing monthly aggregate in parallel\n",
      "in UtlitiesCalc, computing monthly aggregate in parallel\n",
      "in UtlitiesCalc, computing monthly aggregate in parallel\n",
      "in UtlitiesCalc, computing monthly aggregate in parallel\n",
      "in UtlitiesCalc, computing monthly aggregate in parallel\n",
      "in UtlitiesCalc, computing monthly aggregate in parallel\n",
      "in UtlitiesCalc, computing monthly aggregate in parallel\n",
      "in UtlitiesCalc, computing monthly aggregate in parallel\n",
      "in UtlitiesCalc, computing monthly aggregate in parallel\n",
      "in UtlitiesCalc, computing monthly aggregate in parallel\n",
      "in UtlitiesCalc, computing monthly aggregate in parallel\n",
      "in ClimateRegime, computing annual_Tmean in parallel\n",
      "in ClimateRegime, computing annual_accPrec in parallel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.087202072143555"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parallel=True; for global expect ~8.5min (laptop), ~11.5min (desktop) run time\n",
    "# parallel=True; for china expect x (laptop), ~24s (desktop) run time\n",
    "# parallel=False; for china\n",
    "# for parallel this is computing pet_daily and a few 2D monthly means and saving in memory as numpy arrays\n",
    "# everything else remains a dask array to be loaded and computed later when needed\n",
    "start=timer()\n",
    "\n",
    "clim_reg.setDailyClimateData(min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in ClimateRegime, computing lgpt5 in parallel\n"
     ]
    }
   ],
   "source": [
    "lgpt5 = clim_reg.getThermalLGP5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dask.array<blocks, shape=(428, 93), dtype=float32, chunksize=(428, 93), chunktype=numpy.ndarray>,\n",
       " dask.array<blocks, shape=(428, 93), dtype=float32, chunksize=(428, 93), chunktype=numpy.ndarray>,\n",
       " dask.array<blocks, shape=(428, 93), dtype=float32, chunksize=(428, 93), chunktype=numpy.ndarray>,\n",
       " dask.array<blocks, shape=(428, 93), dtype=float32, chunksize=(428, 93), chunktype=numpy.ndarray>,\n",
       " dask.array<blocks, shape=(428, 93), dtype=float32, chunksize=(428, 93), chunktype=numpy.ndarray>,\n",
       " dask.array<blocks, shape=(428, 93), dtype=float32, chunksize=(428, 93), chunktype=numpy.ndarray>,\n",
       " dask.array<blocks, shape=(428, 93), dtype=float32, chunksize=(428, 93), chunktype=numpy.ndarray>,\n",
       " dask.array<blocks, shape=(428, 90), dtype=float32, chunksize=(428, 90), chunktype=numpy.ndarray>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgpt5_delayed=da.from_array(clim_reg.lgpt5,chunks=clim_reg.chunk2D).blocks.ravel()\n",
    "lgpt5_delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in ClimateRegime, computing mask in parallel\n",
      "in ClimateRegime, computing ET components for day 1\n",
      "time spent on eta_class 0.9070041179656982\n",
      "time spent building task_list 0.000997304916381836\n",
      "time spent computing 0.7481331825256348\n",
      "time spent aggregating 0.008890151977539062\n",
      "in ClimateRegime, computing ET components for day 2\n",
      "time spent on eta_class 0.9409592151641846\n",
      "time spent building task_list 0.0\n",
      "time spent computing 0.7280142307281494\n",
      "time spent aggregating 0.010279417037963867\n",
      "in ClimateRegime, computing ET components for day 3\n",
      "time spent on eta_class 0.9995172023773193\n",
      "time spent building task_list 0.00025916099548339844\n",
      "time spent computing 0.753612756729126\n",
      "time spent aggregating 0.008975982666015625\n",
      "in ClimateRegime, computing ET components for day 4\n",
      "time spent on eta_class 1.0297105312347412\n",
      "time spent building task_list 0.0009965896606445312\n",
      "time spent computing 0.7928931713104248\n",
      "time spent aggregating 0.009203672409057617\n",
      "in ClimateRegime, computing ET components for day 5\n",
      "time spent on eta_class 1.0217692852020264\n",
      "time spent building task_list 0.0\n",
      "time spent computing 0.7921750545501709\n",
      "time spent aggregating 0.00897526741027832\n",
      "in ClimateRegime, computing ET components for day 6\n",
      "time spent on eta_class 1.0402402877807617\n",
      "time spent building task_list 0.000997304916381836\n",
      "time spent computing 0.7256903648376465\n",
      "time spent aggregating 0.008379220962524414\n",
      "in ClimateRegime, computing ET components for day 7\n",
      "time spent on eta_class 0.9585225582122803\n",
      "time spent building task_list 0.0\n",
      "time spent computing 0.7268040180206299\n",
      "time spent aggregating 0.008645772933959961\n",
      "in ClimateRegime, computing ET components for day 8\n",
      "time spent on eta_class 0.9959518909454346\n",
      "time spent building task_list 0.0009968280792236328\n",
      "time spent computing 0.7335779666900635\n",
      "time spent aggregating 0.009341001510620117\n",
      "in ClimateRegime, computing ET components for day 9\n",
      "time spent on eta_class 0.9875771999359131\n",
      "time spent building task_list 0.0009968280792236328\n",
      "time spent computing 0.8272340297698975\n",
      "time spent aggregating 0.009068012237548828\n",
      "in ClimateRegime, computing ET components for day 10\n",
      "time spent on eta_class 1.044060468673706\n",
      "time spent building task_list 0.0009963512420654297\n",
      "time spent computing 0.7437353134155273\n",
      "time spent aggregating 0.008976459503173828\n",
      "in ClimateRegime, computing ET components for day 11\n",
      "time spent on eta_class 0.9985642433166504\n",
      "time spent building task_list 0.0009970664978027344\n",
      "time spent computing 0.7745037078857422\n",
      "time spent aggregating 0.008976936340332031\n",
      "in ClimateRegime, computing ET components for day 12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m start\u001b[38;5;241m=\u001b[39mtimer()\n\u001b[1;32m----> 3\u001b[0m lgp \u001b[38;5;241m=\u001b[39m \u001b[43mclim_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetLGP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m task_time\u001b[38;5;241m=\u001b[39mtimer()\u001b[38;5;241m-\u001b[39mstart\n\u001b[0;32m      6\u001b[0m task_time\n",
      "File \u001b[1;32mk:\\projects\\unfao\\pyaez_gaez\\repos\\PyAEZ_kerrie\\PyAEZ\\pyaez2.1_parvec\\ClimateRegime_test.py:964\u001b[0m, in \u001b[0;36mClimateRegime.getLGP\u001b[1;34m(self, Sa, D)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39min ClimateRegime, computing ET components for day\u001b[39m\u001b[39m'\u001b[39m,idoy\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    960\u001b[0m \u001b[39m# for idoy in range(0,2):  #KLG\u001b[39;00m\n\u001b[0;32m    961\u001b[0m     \u001b[39m# istart=self.nchunks*idoy\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[39m# iend=istart+self.nchunks\u001b[39;00m\n\u001b[0;32m    963\u001b[0m     \u001b[39m# Eta_new, Etm_new, Wb_new, Wx_new, Sb_new, kc_new = LGPCalc.EtaCalc(\u001b[39;00m\n\u001b[1;32m--> 964\u001b[0m     Eta_new, Etm_new, Wb_new, Sb_new \u001b[39m=\u001b[39m LGPCalc\u001b[39m.\u001b[39;49mEtaCalc(\n\u001b[0;32m    965\u001b[0m                             mask_delayed,\n\u001b[0;32m    966\u001b[0m                             Tx365_timechunked[idoy], \n\u001b[0;32m    967\u001b[0m                             Ta365_timechunked[idoy],\n\u001b[0;32m    968\u001b[0m                             Pcp365_timechunked[idoy], \n\u001b[0;32m    969\u001b[0m                             Txsnm, \n\u001b[0;32m    970\u001b[0m                             Fsnm, \n\u001b[0;32m    971\u001b[0m                             pet_timechunked[idoy],\n\u001b[0;32m    972\u001b[0m                             Wb_old, \n\u001b[0;32m    973\u001b[0m                             Sb_old, \n\u001b[0;32m    974\u001b[0m                             idoy, \n\u001b[0;32m    975\u001b[0m                             istart0_delayed, \n\u001b[0;32m    976\u001b[0m                             istart1_delayed,\n\u001b[0;32m    977\u001b[0m                             Sa, \n\u001b[0;32m    978\u001b[0m                             D, \n\u001b[0;32m    979\u001b[0m                             p_delayed[idoy], \n\u001b[0;32m    980\u001b[0m                             kc_list, \n\u001b[0;32m    981\u001b[0m                             lgpt5_delayed)  \u001b[39m#KLG            \u001b[39;00m\n\u001b[0;32m    983\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mEta365[:,:,idoy]\u001b[39m=\u001b[39mEta_new  \u001b[39m#KLG\u001b[39;00m\n\u001b[0;32m    984\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mEtm365[:,:,idoy]\u001b[39m=\u001b[39mEtm_new  \u001b[39m#KLG\u001b[39;00m\n",
      "File \u001b[1;32mk:\\projects\\unfao\\pyaez_gaez\\repos\\PyAEZ_kerrie\\PyAEZ\\pyaez2.1_parvec\\LGPCalc_test.py:758\u001b[0m, in \u001b[0;36mEtaCalc\u001b[1;34m(im_mask_dlyd, Tx_da, Ta_da, Pr_da, Txsnm, Fsnm, Eto_da, wb_old, sb_old, idoy, istart0_dlyd, istart1_dlyd, Sa, D, p_dlyd, kc_list, lgpt5_dlyd)\u001b[0m\n\u001b[0;32m    756\u001b[0m start\u001b[39m=\u001b[39mtimer()\n\u001b[0;32m    757\u001b[0m task_list\u001b[39m=\u001b[39mdask\u001b[39m.\u001b[39mdelayed(Eta_class)(im_mask_dlyd,lgpt5_dlyd,Ta_da,Tx_da,Txsnm)\n\u001b[1;32m--> 758\u001b[0m eta_class\u001b[39m=\u001b[39mdask\u001b[39m.\u001b[39;49mcompute(task_list)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    759\u001b[0m eta_class_delay\u001b[39m=\u001b[39mdask\u001b[39m.\u001b[39mdelayed(eta_class)\n\u001b[0;32m    760\u001b[0m \u001b[39m# eta_class=Eta_class(im_mask,lgpt5,Ta,Tx,Txsnm)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kerrie.WIN\\.conda\\envs\\pyaez_dask\\Lib\\site-packages\\dask\\base.py:599\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    596\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[0;32m    597\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 599\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    600\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\kerrie.WIN\\.conda\\envs\\pyaez_dask\\Lib\\site-packages\\dask\\threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[0;32m     87\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 89\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[0;32m     90\u001b[0m     pool\u001b[39m.\u001b[39;49msubmit,\n\u001b[0;32m     91\u001b[0m     pool\u001b[39m.\u001b[39;49m_max_workers,\n\u001b[0;32m     92\u001b[0m     dsk,\n\u001b[0;32m     93\u001b[0m     keys,\n\u001b[0;32m     94\u001b[0m     cache\u001b[39m=\u001b[39;49mcache,\n\u001b[0;32m     95\u001b[0m     get_id\u001b[39m=\u001b[39;49m_thread_get_id,\n\u001b[0;32m     96\u001b[0m     pack_exception\u001b[39m=\u001b[39;49mpack_exception,\n\u001b[0;32m     97\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32mc:\\Users\\kerrie.WIN\\.conda\\envs\\pyaez_dask\\Lib\\site-packages\\dask\\local.py:500\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[39mwhile\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mwaiting\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mready\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mrunning\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    499\u001b[0m     fire_tasks(chunksize)\n\u001b[1;32m--> 500\u001b[0m     \u001b[39mfor\u001b[39;00m key, res_info, failed \u001b[39min\u001b[39;00m queue_get(queue)\u001b[39m.\u001b[39mresult():\n\u001b[0;32m    501\u001b[0m         \u001b[39mif\u001b[39;00m failed:\n\u001b[0;32m    502\u001b[0m             exc, tb \u001b[39m=\u001b[39m loads(res_info)\n",
      "File \u001b[1;32mc:\\Users\\kerrie.WIN\\.conda\\envs\\pyaez_dask\\Lib\\site-packages\\dask\\local.py:130\u001b[0m, in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m         \u001b[39mreturn\u001b[39;00m q\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, timeout\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m    131\u001b[0m     \u001b[39mexcept\u001b[39;00m Empty:\n\u001b[0;32m    132\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kerrie.WIN\\.conda\\envs\\pyaez_dask\\Lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[0;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\kerrie.WIN\\.conda\\envs\\pyaez_dask\\Lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start=timer()\n",
    "\n",
    "lgp = clim_reg.getLGP(Sa=100., D=1.)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(clim_reg.Eta365[:,:,1],interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(clim_reg.Etm365[:,:,1],interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgp#[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lgp[0],interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=timer()\n",
    "\n",
    "tclimate = clim_reg.getThermalClimate()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.__dict__.keys()\n",
    "# clim_reg.im_mask,clim_reg.elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(clim_reg.meanT_monthly_sealevel[:,:,2],interpolation='none')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.maxT_daily.transpose((2,0,1)).rechunk(chunks=(1,-1,-1)).blocks.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "psutil.virtual_memory().free/1E9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start=timer()\n",
    "\n",
    "# istart0,istart1 = clim_reg.getLGP(Sa=100., D=1.)\n",
    "\n",
    "# task_time=timer()-start\n",
    "# task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psh(ng, et0):\n",
    "    # psh0=np.where(ng==0,np.float32(0.5),np.float32(0.3+(ng-1)*.05))\n",
    "    # psh = psh0 + .04 * (5.-et0)\n",
    "    # psh=np.where(psh<0.1,np.float32(0.1),np.float32(psh))  \n",
    "    # psh=np.where(psh>0.8,np.float32(0.8),np.float32(psh))\n",
    "    psh0=np.where(ng==0,0.5,0.3+(ng-1)*.05)\n",
    "    psh = psh0 + .04 * (5.-et0)\n",
    "    psh=np.where(psh<0.1,0.1,psh)  \n",
    "    psh=np.where(psh>0.8,0.8,psh)  \n",
    "    return psh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rainPeak(meanT_daily, lgpt5):\n",
    "    day1=np.argmax(meanT_daily>=5.0,axis=2)   #KLG\n",
    "    day1=np.where(lgpt5==0,np.nan,day1)  #KLG\n",
    "    istart0=np.where((lgpt5<365),day1,0).astype('float32') # replaces if block  #KLG\n",
    "    dat1=np.where(istart0>365,istart0-365,istart0)  # replaces setdat function  #KLG\n",
    "    istart1=np.where((lgpt5<365),dat1+lgpt5-1,lgpt5-1).astype('float32') # replaces if block  #KLG\n",
    "    return istart0, istart1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start=timer()\n",
    "\n",
    "# p = psh(np.zeros(clim_reg.pet_daily[:,:,0].shape,dtype='float32'), clim_reg.pet_daily[:,:,0])   #KLG\n",
    "# # p = psh(np.zeros(clim_reg.pet_daily.shape,dtype='float32'), clim_reg.pet_daily)   #KLG\n",
    "\n",
    "# task_time=timer()-start\n",
    "# task_time\n",
    "\n",
    "# create delayed chunks\n",
    "lgpt5_delayed=da.from_array(lgpt5,chunks=clim_reg.chunk2D).to_delayed().ravel()\n",
    "meanT_delayed=clim_reg.meanT_daily.to_delayed().ravel()\n",
    "\n",
    "# create list of delayed compute tasks\n",
    "task_list=[dask.delayed(rainPeak)(meanT_chunk,lgp_chunk) for meanT_chunk,lgp_chunk in zip(meanT_delayed,lgpt5_delayed)]\n",
    "\n",
    "# compute\n",
    "results_list=dask.compute(*task_list)\n",
    "\n",
    "# separate results into lists of chunks\n",
    "istart0_chunks=[]\n",
    "istart1_chunks=[]\n",
    "for c in range(clim_reg.nchunks):\n",
    "    istart0_chunks.append(results_list[c][0])\n",
    "    istart1_chunks.append(results_list[c][1])\n",
    "\n",
    "# # concatenate to numpy array\n",
    "# istart0=np.concatenate(istart0_chunks,axis=1)\n",
    "# istart1=np.concatenate(istart1_chunks,axis=1)\n",
    "\n",
    "istart0_delayed=[]\n",
    "for arr in istart0_chunks:\n",
    "    istart0_delayed.append(dask.delayed(arr))\n",
    "\n",
    "istart0_delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=dask.delayed(clim_reg.meanT_daily)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=clim_reg.meanT_daily.to_delayed().ravel()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timechunks=(1,-1,clim_reg.chunk3D[1])\n",
    "Tx365 = clim_reg.maxT_daily.transpose((2,0,1)).rechunk(chunks=timechunks).blocks.ravel()\n",
    "len(Tx365),Tx365[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Tx365[0:clim_reg.nchunks])\n",
    "istart=clim_reg.nchunks*i\n",
    "iend=istart+clim_reg.nchunks\n",
    "# clim_reg.maxT_daily.transpose((2,0,1)).rechunk(chunks=timechunks).blocks.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=(3,5)\n",
    "\n",
    "arr1=np.array([[1,2,3,4,5],\n",
    "               [6,7,8,9,10],\n",
    "               [11,12,13,14,15]],dtype='int8')\n",
    "\n",
    "arr2=-np.array([[1,2,3,4,5],\n",
    "               [6,7,8,9,10],\n",
    "               [11,12,13,14,15]],dtype='int8')\n",
    "\n",
    "# np0=np.zeros(s,dtype='int8')\n",
    "# np1=np.ones(s,dtype='int8')\n",
    "\n",
    "# nptest=np.stack((np0,np1),axis=-1,dtype='int8')\n",
    "# nptest\n",
    "\n",
    "# nptest=np.stack((arr1,arr2),axis=-1,dtype='int8')\n",
    "# darr=da.from_array(nptest,chunks=(3,2,1))\n",
    "# nptest.shape,nptest\n",
    "nptest=np.stack((arr1,arr2),axis=0,dtype='int8')\n",
    "darr=da.from_array(nptest,chunks=(1,-1,2))\n",
    "darr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darr.blocks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darr.blocks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,block in enumerate(darr.blocks.ravel()[0:3]):\n",
    "    print('block',i)\n",
    "    print(block.compute())\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=dask.compute(*darr.blocks.ravel()[0:3])\n",
    "test2=np.concatenate(test,axis=2)\n",
    "test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nptest.shape,nptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack((arr1,arr2),axis=2,dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nptest.transpose((1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel=True; for global expect ~1min (laptop), ~1.5min (desktop) run time \n",
    "# parallel=True; for china expect x (laptop), ~1s (desktop) run time\n",
    "# parallel=False; for china expect x (laptop), ~xmin (desktop) run time\n",
    "\n",
    "start=timer()\n",
    "\n",
    "tclimate = clim_reg.getThermalClimate()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(tclimate, cmap=plt.get_cmap('gist_ncar_r', 12),vmin=-0.3,vmax=12.5,interpolation='none')\n",
    "plt.title('Thermal Climate')\n",
    "plt.colorbar(shrink=0.4)\n",
    "plt.savefig(out_path+\"ThermalClimate.png\",bbox_inches =\"tight\",dpi=300) #Save as PNG image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel=True; for global expect ~3s (laptop), ~4s (desktop) run time \n",
    "# parallel=True; for china expect x (laptop), <1s (desktop) run time\n",
    "# parallel=False; for china expect x (laptop), ~xmin (desktop) run time\n",
    "start=timer()\n",
    "\n",
    "tzone = clim_reg.getThermalZone()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(tzone, cmap=plt.get_cmap('gist_ncar_r', 12),vmin=-0.3,vmax=12.5,interpolation='none')\n",
    "plt.title('Thermal Zones')\n",
    "plt.colorbar(shrink=0.4)\n",
    "plt.savefig(out_path+\"ThermalZone\"+revname+\".png\",bbox_inches =\"tight\",dpi=300) #Save as PNG image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel=True; for global expect ~1min (laptop), ~1.25min (desktop) run time \n",
    "# parallel=True; for china expect x (laptop), ~1.5s (desktop) run time\n",
    "# parallel=False; for china expect x (laptop), ~xmin (desktop) run time\n",
    "start=timer()\n",
    "\n",
    "lgpt0 = clim_reg.getThermalLGP0()\n",
    "lgpt5 = clim_reg.getThermalLGP5()\n",
    "lgpt10 = clim_reg.getThermalLGP10()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "#======================\n",
    "# plt.figure(figsize=(20, 4),dpi=300)\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(lgpt0,vmin=0,vmax=366,interpolation='none')\n",
    "plt.title('LGPt 0')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(lgpt5, vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGPt 5')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(lgpt10, vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGPt 10')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.savefig(out_path+\"ThermalLGPs\"+revname+\".png\",\n",
    "            bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "#======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel=True; for global expect ~70s (laptop), ~75s (desktop) run time \n",
    "# parallel=True; for china expect x (laptop), ~1.5s (desktop) run time\n",
    "# parallel=False; for china expect x (laptop), ~xmin (desktop) run time\n",
    "start=timer()\n",
    "\n",
    "tsum0 = clim_reg.getTemperatureSum0()\n",
    "tsum5 = clim_reg.getTemperatureSum5()\n",
    "tsum10 = clim_reg.getTemperatureSum10()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "#======================\n",
    "# plt.figure(1, figsize=(20, 4),dpi=300)\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(tsum0, cmap='hot_r', vmin=0, vmax=11000,interpolation='none')\n",
    "plt.title('T-sumation 0')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(tsum5, cmap='hot_r', vmin=0, vmax=11000,interpolation='none')\n",
    "plt.title('T-sumation 5')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(tsum10, cmap='hot_r', vmin=0, vmax=11000,interpolation='none')\n",
    "plt.title('T-sumation 10')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.savefig(out_path+\"Tsum_\"+revname+\".png\",\n",
    "            bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "#======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "print('1:',psutil.virtual_memory().free/1E9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel=True; for global expect ~s (laptop), ~4.75min (desktop) run time \n",
    "# parallel=True; for china expect x (laptop), ~8s (desktop) run time\n",
    "# parallel=False; for china expect x (laptop), ~xmin (desktop) run time\n",
    "start=timer()\n",
    "\n",
    "tprofile = clim_reg.getTemperatureProfile()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "tile_list = ['A1','A2','A3','A4','A5','A6','A7','A8','A9',\n",
    "            'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9']\n",
    "\n",
    "# fig = plt.figure(figsize=(12, 12))\n",
    "fig = plt.figure()\n",
    "for i1 in range(1, 19):\n",
    "    plt.subplot(6, 3, i1)\n",
    "    plt.imshow(tprofile[i1-1],interpolation='none')\n",
    "    plt.title(tile_list[i1-1])\n",
    "    plt.colorbar(shrink=0.8)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(out_path+\"Tprofiles_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eta_class(mask,ta,tx,tmelt,lgpt5):    \n",
    "\n",
    "    eta_class=np.empty(mask.shape,dtype='float32')\n",
    "    eta_class[:]=np.nan\n",
    "\n",
    "    # assign categorical value to snow areas\n",
    "    eta_class=np.where((ta<=0) & (tx<=tmelt),np.float32(1),np.float32(eta_class))\n",
    "\n",
    "    # assign categorical value to snow melting areas\n",
    "    eta_class=np.where((ta<=0) & (tx>=0) & ~np.isfinite(eta_class),np.float32(2),np.float32(eta_class))\n",
    "\n",
    "    # assign categorical value to cold areas (pre-growing season)\n",
    "    eta_class=np.where((ta>0) & (ta<5) & ~np.isfinite(eta_class),np.float32(3),np.float32(eta_class))\n",
    "\n",
    "    # assign categorical value to warm areas (growing season)\n",
    "    eta_class=np.where((lgpt5<365) & (ta>=5) & ~np.isfinite(eta_class),np.float32(4),np.float32(eta_class))\n",
    "\n",
    "    # assign categorical value to warmest areas\n",
    "    eta_class=np.where((mask==1) & ~np.isfinite(eta_class),np.float32(5),np.float32(eta_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eta_class(mask,lgpt5,ta,tx,tmelt):    \n",
    "\n",
    "    eta_class=da.empty(mask.shape,dtype='float32')\n",
    "    eta_class[:]=np.nan\n",
    "\n",
    "    eta_class=da.where((ta<=0) & (tx<=tmelt),np.float32(1),np.float32(eta_class))\n",
    "    eta_class=da.where((ta<=0) & (tx>=0) & ~np.isfinite(eta_class),np.float32(2),np.float32(eta_class))\n",
    "    eta_class=da.where((ta>0) & (ta<5) & ~np.isfinite(eta_class),np.float32(3),np.float32(eta_class))\n",
    "    eta_class=da.where((lgpt5<365) & (ta>=5) & ~np.isfinite(eta_class),np.float32(4),np.float32(eta_class))\n",
    "    eta_class=da.where((mask==1) & ~np.isfinite(eta_class),np.float32(5),np.float32(eta_class))\n",
    "\n",
    "    return eta_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=timer()\n",
    "print('in ClimateRegime, computing Tx365 in parallel')\n",
    "Tx365=clim_reg.maxT_daily.compute()  # convert dask to numpy\n",
    "print('in ClimateRegime, computing Ta365 in parallel')\n",
    "Ta365=clim_reg.meanT_daily.compute()  # convert dask to numpy\n",
    "print('in ClimateRegime, computing Pcp355 in parallel')\n",
    "Pcp365=clim_reg.totalPrec_daily.compute()  # convert dask to numpy   \n",
    "print('computing mask in parallel')\n",
    "mask=clim_reg.im_mask.compute()\n",
    "\n",
    "eta_class=Eta_class(im_mask,lgpt5,Ta,Tx,Txsnm)\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=clim_reg.im_mask.to_delayed()\n",
    "chunk_shapes2D=dask.compute([chunk.shape for chunk in test.ravel()])\n",
    "# chunk_shapes2D[0][:]\n",
    "\n",
    "chunk_shapes3D=[]\n",
    "for item in chunk_shapes2D[0]:\n",
    "    chunk_shapes3D.append((item[0],item[1],365))\n",
    "# chunk_shapes3D[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=clim_reg.meanT_daily.rechunk(chunks=(-1,-1,1))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=clim_reg.maxT_daily.rechunk(chunks=(-1,-1,1))\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Txsnm = 0.\n",
    "eta_class=Eta_class(clim_reg.im_mask,da.from_array(lgpt5,chunks=clim_reg.chunk2D),clim_reg.meanT_daily[:,:,0],clim_reg.maxT_daily[:,:,0],Txsnm)\n",
    "eta_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel=True; for global expect ~s (laptop), ~x (desktop) run time \n",
    "# parallel=True; for china expect x (laptop), ~52s (desktop) run time\n",
    "# parallel=False; for china expect x (laptop), ~xmin (desktop) run time\n",
    "start=timer()\n",
    "\n",
    "lgp = clim_reg.getLGP(Sa=100., D=1.)\n",
    "lgp_class = clim_reg.getLGPClassified(lgp)\n",
    "lgp_equv = clim_reg.getLGPEquivalent()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "# fig = plt.figure(figsize=(20, 4))\n",
    "fig = plt.figure()\n",
    "# fig = plt.figure(figsize=(10, 8),dpi=600)\n",
    "plt.subplot(121)\n",
    "plt.imshow(lgp, cmap='viridis', vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGP [days]')\n",
    "plt.colorbar(shrink=0.8)\n",
    "# plt.savefig(out_path+\"LGP_\"+revname+\".png\", bbox_inches=\"tight\", dpi=600)\n",
    "# plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=(20, 8),dpi=600)\n",
    "plt.subplot(122)\n",
    "plt.imshow(lgp_equv, cmap='viridis', vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGP Equivalent [days]')\n",
    "plt.colorbar(shrink=0.8)\n",
    "# plt.savefig(out_path+\"LGP_Equv_\"+revname+\".png\",bbox_inches=\"tight\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(out_path+\"LGP_and_LGP_Equv_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel=True; for global expect ~s (laptop), ~x (desktop) run time \n",
    "# parallel=True; for china expect x (laptop), ~7s (desktop) run time\n",
    "# parallel=False; for china expect x (laptop), ~xmin (desktop) run time\n",
    "\n",
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~1.5 minutes run time for china\n",
    "start=timer()\n",
    "\n",
    "multi_crop = clim_reg.getMultiCroppingZones(tclimate, lgp, lgpt5, lgpt10, tsum0, tsum10)\n",
    "multi_crop_rainfed = multi_crop[0]  # for rainfed conditions\n",
    "multi_crop_irr = multi_crop[1]  # for irrigated conditions\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(multi_crop_irr, cmap=plt.get_cmap('gist_ncar_r', 9), vmin=-0.2, vmax=8.4,interpolation='none')\n",
    "plt.title('Multi Cropping Zone - IRR')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"multicrop_irr_\"+revname+\".png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(multi_crop_rainfed,cmap=plt.get_cmap('gist_ncar_r', 9), vmin=-0.2, vmax=8.4,interpolation='none')\n",
    "plt.title('Multi Cropping Zone - RAINFED')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"multicrop_rain_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel=True; for global expect ~s (laptop), ~x (desktop) run time \n",
    "# parallel=True; for china expect x (laptop), ~1s (desktop) run time\n",
    "# parallel=False; for china expect x (laptop), ~xmin (desktop) run time\n",
    "\n",
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~2 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "permafrost_eval = clim_reg.AirFrostIndexandPermafrostEvaluation()\n",
    "frost_index = permafrost_eval[0]\n",
    "permafrost = permafrost_eval[1]\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frost_index.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(frost_index, cmap=plt.get_cmap('tab20b', 11), vmin=-0.05, vmax=1.05,interpolation='none')\n",
    "plt.title('Frost Index')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"frost_index_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(permafrost, cmap=plt.get_cmap('tab20b', 5), vmin=-0.5, vmax=4.3,interpolation='none')\n",
    "plt.title('Permafrost Evaluation')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"permafrost_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parallel=True; for global expect ~s (laptop), ~x (desktop) run time \n",
    "# parallel=True; for china expect x (laptop), <1s (desktop) run time\n",
    "# parallel=False; for china expect x (laptop), ~xmin (desktop) run time\n",
    "\n",
    "# expect >1s run time for china\n",
    "# expect ~15 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "tzone_fallow = clim_reg.TZoneFallowRequirement(tzone)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(tzone_fallow, cmap=plt.get_cmap('tab10', 7), vmin=-0.5, vmax=6.3,interpolation='none')\n",
    "plt.title('Fallow Requirement')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"fallow_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'fallow_'+revname+'.tif', tzone_fallow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dtypes of all outputs\n",
    "outputs=[tclimate,tzone,lgpt0,lgpt5,lgpt10,tsum0,tsum5,tsum10,tprofile,lgp,lgp_class,lgp_equv,multi_crop_rainfed,multi_crop_irr,frost_index,permafrost,tzone_fallow]\n",
    "dtypes=[]\n",
    "for var in outputs:\n",
    "    # for arrays\n",
    "    try:\n",
    "        dt=var.dtype\n",
    "        dtypes.append(dt)\n",
    "    # for lists of arrays\n",
    "    except:\n",
    "        for v in var:\n",
    "            dt=v.dtype\n",
    "            dtypes.append(dt)\n",
    "\n",
    "print(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars=['meanT_daily','meanT_daily_sealevel','P_by_PET_daily','maxT_daily','totalPrec_daily']\n",
    "\n",
    "for v in vars:\n",
    "\n",
    "    start=timer()\n",
    "    test=clim_reg.__getattribute__(v).compute()\n",
    "    task_time=timer()-start\n",
    "    print(v, task_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETtest(dstart,dend,cdims,lat,alt,tmn,tmx,u2m,srad,rh):\n",
    "    # print('implementing data value limits')\n",
    "    nlats=cdims[0]\n",
    "    nlons=cdims[1]\n",
    "\n",
    "    # print('tavg,lam,dayoyr,ndays')\n",
    "    tavg = 0.5*(tmn + tmx)  # Averaged temperature  #KLG\n",
    "    lam = 2.501 - 0.002361 * tavg  # Latent heat of vaporization\n",
    "    dayoyr = np.arange(dstart, dend+1)  # Julien Days #KLG\n",
    "    ndays=len(dayoyr)  #KLG            \n",
    "\n",
    "    # print('es_tmin,es_tmax,es,ea')\n",
    "    es_tmin = 0.6108 * np.exp((17.27 * tmn) / (tmn + 237.3))\n",
    "    es_tmax = 0.6108 * np.exp((17.27 * tmx) / (tmx + 237.3))\n",
    "    es = 0.5*(es_tmin + es_tmax)\n",
    "    ea = rh * es  # Actual Vapor Pressure derived from relative humidity\n",
    "\n",
    "    # print('dlmx,dlmn,dl')\n",
    "    dlmx = 4098. * es_tmax / (tmx + 237.3)**2\n",
    "    dlmn = 4098. * es_tmin / (tmn + 237.3)**2\n",
    "    del es_tmin, es_tmax  #KLG\n",
    "    dl = 0.5* (dlmx + dlmn)\n",
    "    del dlmx,dlmn  #KLG\n",
    "\n",
    "    # print('ap and constants')\n",
    "    ap = 101.3*np.power(((293-(0.0065*alt))/293), 5.256)\n",
    "    ap = np.tile(ap[:,:,np.newaxis],(1,1,ndays))  \n",
    "    gam = 0.0016286 * ap/lam\n",
    "    hw = 200.\n",
    "    ht = 190.\n",
    "    hc = 12\n",
    "    Rl = 100  \n",
    "    RLAI = 24 * 0.12\n",
    "    rhoc = Rl/(0.5*RLAI)  \n",
    "    del ap\n",
    "\n",
    "    # print('rhoa,gamst')\n",
    "    rhoa = 208/u2m\n",
    "    gamst = gam * (1. + rhoc/rhoa)\n",
    "\n",
    "    # print('lat,sdcl')\n",
    "    latr = lat * np.pi/180.\n",
    "    latr3D = np.tile(latr[:,:,np.newaxis],(1,1,ndays))\n",
    "    del latr\n",
    "    sdcl = 0.4093 * np.sin(0.017214206 * dayoyr - 1.405)\n",
    "    sdcl3D = np.tile(sdcl[np.newaxis, np.newaxis,:], (nlats,nlons,1))\n",
    "    del sdcl\n",
    "\n",
    "    # print('xx,yy,zz')\n",
    "    xx = np.sin(sdcl3D) * np.sin(latr3D)\n",
    "    yy = np.cos(sdcl3D) * np.cos(latr3D)\n",
    "    zz = xx/yy\n",
    "\n",
    "    # print('omg,dayhr')\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        omg = np.tan(zz / (1. - zz*zz)**0.5) + 1.5708\n",
    "    dayhr = 24. * (omg/np.pi)\n",
    "\n",
    "    omg=np.where((np.abs(zz)>=0.9999)&(zz>0),np.pi,omg)\n",
    "    dayhr=np.where((np.abs(zz) >= 0.9999)&(zz > 0), 23.999,dayhr)\n",
    "    omg=np.where((np.abs(zz) >= 0.9999)&(zz <= 0),0,omg)\n",
    "    dayhr=np.where((np.abs(zz) >= 0.9999)&(zz <= 0), 0.001,dayhr)\n",
    "    del latr3D,sdcl3D,zz\n",
    "\n",
    "    # print('sdst,ra')\n",
    "    sdst = 1.0 + 0.033 * np.cos(0.017214206 * dayoyr)\n",
    "    sdst3D = np.tile(sdst[np.newaxis, np.newaxis,:], (nlats,nlons,1))\n",
    "    del sdst\n",
    "    ra = 37.586 * sdst3D * (omg*xx + np.sin(omg)*yy)\n",
    "    # ra = 37.586 * sdst3D * (omg_rev2*xx + np.sin(omg_rev2)*yy)\n",
    "    # del sdst3D, sdst, omg, omg_rev1, omg_rev2, dayhr, dayhr_rev1, dayhr_rev2, xx, yy       \n",
    "    del sdst3D, omg, dayhr, xx, yy       \n",
    "\n",
    "    # print('rs,rs0')\n",
    "    rs = srad  \n",
    "    alt3D=np.tile(alt[:,:,np.newaxis],(1,1,ndays)) \n",
    "    del alt\n",
    "    rs0 = (0.75 + 0.00002 * alt3D) * ra\n",
    "    del alt3D\n",
    "\n",
    "    # print('rns,rnl')\n",
    "    rns = 0.77 * rs\n",
    "    sub_cst = 0.000000004903\n",
    "    with np.errstate(invalid='ignore',divide='ignore'):\n",
    "        rs_div_ds0=rs/rs0\n",
    "    rnl = (((273.16+tmx)**4)+((273.16 + tmn)**4)) * \\\n",
    "        (0.34 - (0.14*(ea**0.5))) * \\\n",
    "        ((1.35*(rs_div_ds0))-0.35)*sub_cst/2\n",
    "    del rs0,rs,rs_div_ds0,tmx,tmn\n",
    "\n",
    "    # print('rn')\n",
    "    rn = rns - rnl\n",
    "    del rns,rnl\n",
    "\n",
    "    # print('ta_diff,G')\n",
    "    ta_diff=np.diff(tavg,n=1,axis=2,prepend=tavg[:,:,-1:])  #KLG\n",
    "    G = 0.14 * ta_diff  #KLG\n",
    "    del ta_diff\n",
    "\n",
    "    # print('et0ady')\n",
    "    et0ady = gam/(dl+gamst) * 900./(tavg+273.) * u2m * (es-ea)\n",
    "    del gam,tavg,es,ea\n",
    "\n",
    "    # print('et0rad')\n",
    "    et0rad = dl/(dl+gamst) * (rn-G) / lam\n",
    "    del dl,gamst,rn,G,lam\n",
    "\n",
    "    # print('et0')\n",
    "    et0 = et0ady + et0rad\n",
    "    del et0ady,et0rad\n",
    "\n",
    "    # print('et0_out')\n",
    "    et0_out=np.where(et0<0,0,et0)\n",
    "\n",
    "    return et0_out\n",
    "    # return doy_start,doy_end,chunkdims,latitude,alt,min_temp,max_temp,u2m,shortrad_daily_MJm2day,rel_humidity\n",
    "    # return alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDailyClimateData(self, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity):\n",
    "\n",
    "    self.doy_start=1  #KLG\n",
    "    self.doy_end=min_temp.shape[2]  #KLG \n",
    "    \n",
    "    print('rechunking and delaying inputs')\n",
    "    min_temp=min_temp.rechunk(chunks=self.chunk3D)\n",
    "    max_temp=max_temp.rechunk(chunks=self.chunk3D)\n",
    "    tmn_delay=min_temp.to_delayed()\n",
    "    tmx_delay=max_temp.to_delayed()\n",
    "\n",
    "    short_rad=short_rad.rechunk(chunks=self.chunk3D) # chunk\n",
    "    short_rad=da.where(short_rad < 0, 0, short_rad)  # elim negatives\n",
    "    short_rad = (short_rad*3600.*24.)/1000000.       # convert units\n",
    "    srad_delay=short_rad.to_delayed()\n",
    "    del short_rad\n",
    "\n",
    "    wind_speed=wind_speed.rechunk(chunks=self.chunk3D)     # chunk\n",
    "    # wind_speed=da.where(wind_speed < 0, 0, wind_speed)     # elim negative\n",
    "    wind_speed=da.where(wind_speed < 0.5, 0.5, wind_speed) # elim negative and small values\n",
    "    wind_delay=wind_speed.to_delayed()\n",
    "\n",
    "    rel_humidity=rel_humidity.rechunk(chunks=self.chunk3D)        # chunk\n",
    "    rel_humidity=da.where(rel_humidity > 0.99, 0.99,rel_humidity) # elim high values\n",
    "    rel_humidity=da.where(rel_humidity < 0.05, 0.05,rel_humidity) # elim low values\n",
    "    rh_delay=rel_humidity.to_delayed()\n",
    "    del rel_humidity\n",
    "\n",
    "    lat_delay=self.latitude.to_delayed()\n",
    "    elev_delay=self.elevation.to_delayed()        \n",
    "\n",
    "\n",
    "    print('getting chunk shapes')\n",
    "    chunk_shapes=dask.compute([chunk.shape for chunk in tmn_delay.ravel()])\n",
    "    print('zipping delayed inputs')\n",
    "    zipvars=zip(chunk_shapes[0][:],lat_delay.ravel(),elev_delay.ravel(),tmn_delay.ravel(),tmx_delay.ravel(),wind_delay.ravel(),srad_delay.ravel(),rh_delay.ravel())\n",
    "    print('creating task list')\n",
    "    task_list=[dask.delayed(ETtest)(self.doy_start,self.doy_end,cshape,lat,el,tmn,tmx,u,srad,rh) for cshape,lat,el,tmn,tmx,u,srad,rh in zipvars]\n",
    "\n",
    "    print('COMPUTING')\n",
    "    result_chunks=dask.compute(*task_list)\n",
    "    print('CONCATENATING')\n",
    "    self.pet_daily=np.concatenate(result_chunks,axis=1)\n",
    "    # return result_chunks\n",
    "\n",
    "\n",
    "    print('computing meanT, meanT_daily_sealevel, P_by_PET_daily')\n",
    "    self.meanT_daily = 0.5*(min_temp+max_temp)  #KLG\n",
    "\n",
    "    # sea level temperature\n",
    "    # P over PET ratio (to eliminate nan in the result, nan is replaced with zero)\n",
    "    if self.parallel:\n",
    "        self.meanT_daily_sealevel = self.meanT_daily + (da.tile(self.elevation[:,:,np.newaxis],(1,1,self.doy_end)).rechunk(chunks=self.chunk3D)/100*0.55)\n",
    "        precipitation=precipitation.rechunk(chunks=self.chunk3D)\n",
    "        with np.errstate(invalid='ignore',divide='ignore'):\n",
    "            self.P_by_PET_daily = da.nan_to_num(precipitation / self.pet_daily)\n",
    "    else:\n",
    "        self.meanT_daily_sealevel = self.meanT_daily + np.expand_dims(self.elevation/100*0.55,axis=2) # automatic broadcasting #KLG        \n",
    "        with np.errstate(invalid='ignore',divide='ignore'):\n",
    "            self.P_by_PET_daily = np.nan_to_num(precipitation / self.pet_daily)\n",
    "\n",
    "    self.set_monthly = False\n",
    "\n",
    "    print('computing interp_daily_temp')\n",
    "    # smoothed daily temperature\n",
    "    # create a mask of all 1's if the user doesn't provide a mask\n",
    "    if self.set_mask:\n",
    "        mask=self.im_mask\n",
    "    else:\n",
    "        mask=np.ones((self.im_height,self.im_width),dtype='int')\n",
    "\n",
    "    obj_utilities = UtilitiesCalc.UtilitiesCalc(self.chunk2D,self.chunk3D)  #KLG\n",
    "    self.interp_daily_temp=obj_utilities.smoothDailyTemp(self.doy_start,self.doy_end, mask, self.meanT_daily,self.chunk3D)\n",
    "\n",
    "    print('copying maxT_daily,minT_daily,totalPrec_daily')\n",
    "    self.maxT_daily = max_temp\n",
    "    # self.minT_daily = min_temp\n",
    "    self.totalPrec_daily = precipitation  #KLG   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.chunk3D, clim_reg.chunksize3D_MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setDailyClimateData(clim_reg, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clim_reg.pet_daily # numpy array\n",
    "# clim_reg.meanT_daily  # dask array\n",
    "# clim_reg.meanT_daily_sealevel  # dask_array\n",
    "# clim_reg.P_by_PET_daily  # dask array\n",
    "# clim_reg.maxT_daily  # dask array\n",
    "# clim_reg.totalPrec_daily  # dask array\n",
    "# clim_reg.interp_daily_temp  # numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prsum=clim_reg.totalPrec_daily.sum(axis=2).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.P_by_PET_daily.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this normal numpy calculation works just fine with 5GB inputs\n",
    "\n",
    "print('implementing data value limits')\n",
    "doy_start=1  #KLG\n",
    "doy_end=min_temp.shape[2]  #KLG\n",
    "nlats=min_temp.shape[0]\n",
    "nlons=min_temp.shape[1]\n",
    "\n",
    "rel_humidity=np.where(rel_humidity > 0.99, 0.99,rel_humidity)\n",
    "rel_humidity=np.where(rel_humidity < 0.05, 0.05,rel_humidity)\n",
    "short_rad=np.where(short_rad < 0, 0, short_rad)\n",
    "shortrad_daily_MJm2day = (short_rad*3600.*24.)/1000000.\n",
    "del short_rad\n",
    "# wind_speed=da.where(wind_speed < 0, 0, wind_speed)  \n",
    "u2m=np.where(wind_speed < 0.5, 0.5, wind_speed)\n",
    "\n",
    "print('tavg,lam,dayoyr,ndays')\n",
    "tavg = 0.5*(min_temp + max_temp)  # Averaged temperature  #KLG\n",
    "lam = 2.501 - 0.002361 * tavg  # Latent heat of vaporization\n",
    "\n",
    "dayoyr = np.arange(doy_start, doy_end+1)  # Julien Days #KLG\n",
    "ndays=len(dayoyr)  #KLG            \n",
    "# alt=np.tile(clim_reg.elevation[:,:,np.newaxis],(1,1,ndays))  # 3D altitude #KLG\n",
    "alt=elevation\n",
    "\n",
    "print('es_tmin,es_tmax,es,ea')\n",
    "es_tmin = 0.6108 * np.exp((17.27 * min_temp) / (min_temp + 237.3))\n",
    "es_tmax = 0.6108 * np.exp((17.27 * max_temp) / (max_temp + 237.3))\n",
    "es = 0.5*(es_tmin + es_tmax)\n",
    "ea = rel_humidity * es  # Actual Vapor Pressure derived from relative humidity\n",
    "\n",
    "print('dlmx,dlmn,dl')\n",
    "dlmx = 4098. * es_tmax / (max_temp + 237.3)**2\n",
    "dlmn = 4098. * es_tmin / (min_temp + 237.3)**2\n",
    "# del es_tmin, es_tmax  #KLG\n",
    "dl = 0.5* (dlmx + dlmn)\n",
    "# del dlmx,dlmn  #KLG\n",
    "\n",
    "print('ap and constants')\n",
    "ap = 101.3*np.power(((293-(0.0065*alt))/293), 5.256)\n",
    "ap = np.tile(ap[:,:,np.newaxis],(1,1,ndays))  \n",
    "gam = 0.0016286 * ap/lam\n",
    "hw = 200.\n",
    "ht = 190.\n",
    "hc = 12\n",
    "Rl = 100  \n",
    "RLAI = 24 * 0.12\n",
    "rhoc = Rl/(0.5*RLAI)  \n",
    "# del ap\n",
    "\n",
    "print('rhoa,gamst')\n",
    "rhoa = 208/u2m\n",
    "gamst = gam * (1. + rhoc/rhoa)\n",
    "\n",
    "print('lat,sdcl')\n",
    "latr = clim_reg.latitude * np.pi/180.\n",
    "latr3D = np.tile(latr[:,:,np.newaxis],(1,1,ndays))\n",
    "sdcl = 0.4093 * np.sin(0.017214206 * dayoyr - 1.405)\n",
    "sdcl3D = np.tile(sdcl[np.newaxis, np.newaxis,:], (nlats,nlons,1))\n",
    "\n",
    "print('xx,yy,zz')\n",
    "xx = np.sin(sdcl3D) * np.sin(latr3D)\n",
    "yy = np.cos(sdcl3D) * np.cos(latr3D)\n",
    "zz = xx/yy\n",
    "\n",
    "print('omg,dayhr')\n",
    "omg = np.tan(zz / (1. - zz*zz)**0.5) + 1.5708\n",
    "dayhr = 24. * (omg/np.pi)\n",
    "omg_rev1=np.where((np.abs(zz)>=0.9999)&(zz>0),np.pi,omg)\n",
    "dayhr_rev1=np.where((np.abs(zz) >= 0.9999)&(zz > 0), 23.999,dayhr)\n",
    "omg_rev2=np.where((np.abs(zz) >= 0.9999)&(zz <= 0),0,omg_rev1)\n",
    "dayhr_rev2=np.where((np.abs(zz) >= 0.9999)&(zz <= 0), 0.001,dayhr_rev1)\n",
    "del latr3D,sdcl3D,latr,sdcl,zz\n",
    "\n",
    "print('sdst,ra')\n",
    "sdst = 1.0 + 0.033 * np.cos(0.017214206 * dayoyr)\n",
    "sdst3D = np.tile(sdst[np.newaxis, np.newaxis,:], (nlats,nlons,1))\n",
    "ra = 37.586 * sdst3D * (omg_rev2*xx + np.sin(omg_rev2)*yy)\n",
    "del sdst3D, sdst, omg, omg_rev1, omg_rev2, dayhr, dayhr_rev1, dayhr_rev2, xx, yy       \n",
    "\n",
    "print('rs,rs0')\n",
    "rs = shortrad_daily_MJm2day  \n",
    "alt3D=np.tile(alt[:,:,np.newaxis],(1,1,ndays)) \n",
    "rs0 = (0.75 + 0.00002 * alt3D) * ra\n",
    "del alt3D,alt\n",
    "\n",
    "print('rns,rnl')\n",
    "rns = 0.77 * rs\n",
    "sub_cst = 0.000000004903\n",
    "rs_div_ds0=rs/rs0\n",
    "rnl = (((273.16+max_temp)**4)+((273.16 + min_temp)**4)) * \\\n",
    "    (0.34 - (0.14*(ea**0.5))) * \\\n",
    "    ((1.35*(rs_div_ds0))-0.35)*sub_cst/2\n",
    "del rs0,rs,rs_div_ds0\n",
    "\n",
    "print('rn')\n",
    "rn = rns - rnl\n",
    "del rns,rnl\n",
    "\n",
    "print('ta_diff,G')\n",
    "ta_diff=np.diff(tavg,n=1,axis=2,prepend=tavg[:,:,-1:])  #KLG\n",
    "G = 0.14 * ta_diff  #KLG\n",
    "del ta_diff\n",
    "\n",
    "print('et0ady')\n",
    "et0ady = gam/(dl+gamst) * 900./(tavg+273.) * u2m * (es-ea)\n",
    "del gam,tavg,es,ea\n",
    "\n",
    "print('et0rad')\n",
    "et0rad = dl/(dl+gamst) * (rn-G) / lam\n",
    "del dl,gamst,rn,G,lam\n",
    "\n",
    "print('et0')\n",
    "et0 = et0ady + et0rad\n",
    "del et0ady,et0rad\n",
    "\n",
    "print('et0_out')\n",
    "et0_out=np.where(et0<0,0,et0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam.shape, rhoa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nchunks=238\n",
    "# nlons=min_temp.shape[1]\n",
    "# chunk_nlons=int(da.ceil(nlons/nchunks))\n",
    "# chunks3D=(-1,chunk_nlons,-1)\n",
    "# chunks2D=(-1,chunk_nlons)\n",
    "\n",
    "# lat_vals=da.linspace(lat_min, lat_max, min_temp.shape[0]).astype('float32')  #KLG\n",
    "# lat_map=da.tile(lat_vals[:,np.newaxis],(1,min_temp.shape[1])).rechunk(chunks=chunks2D)  #KLG   \n",
    "# # lat_map=da.broadcast_to(lat_vals,(min_temp.shape[0],min_temp.shape[1]),chunks=chunks2D)\n",
    "# lat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETOCalc(object):\n",
    " \n",
    "    def __init__(self, cycle_begin, cycle_end, latitude, altitude,chunk3D):\n",
    "        \"\"\"Initiate a ETOCalc Class instance\n",
    "\n",
    "        Args:\n",
    "            cycle_begin (int): Julian day for the beginning of crop cycle\n",
    "            cycle_end (int): Julian day for the ending of crop cycle\n",
    "            latitude (float): a latitude value\n",
    "            altitude (float): an altitude value\n",
    "        \"\"\"        \n",
    "        self.cycle_begin = cycle_begin\n",
    "        self.cycle_end = cycle_end\n",
    "        self.latitude = latitude\n",
    "        self.alt = altitude\n",
    "        \n",
    "        self.chunk3D=chunk3D\n",
    "        if self.chunk3D: self.parallel=True\n",
    "        else: self.parallel=False\n",
    "        print('parallel ETO = ',self.parallel)\n",
    "\n",
    "    def setClimateData(self, min_temp, max_temp, wind_speed, short_rad, rel_humidity):\n",
    "        \"\"\"Load the climatic (point) data into the Class\n",
    "\n",
    "        Args:\n",
    "            min_temp (float): Minimum temperature [Celcius]\n",
    "            max_temp (float): Maximum temperature [Celcius]\n",
    "            wind_speed (float): Windspeed at 2m altitude [m/s]\n",
    "            short_rad (float): Radiation [MJ/m2.day]\n",
    "            rel_humidity (float): Relative humidity [decimal percentage]\n",
    "        \"\"\"        \n",
    "\n",
    "        self.minT_daily = min_temp # Celcius\n",
    "        self.maxT_daily = max_temp # Celcius\n",
    "        self.u2m = wind_speed # m/s at 2m\n",
    "        self.shortRad_daily = short_rad # MJ/m2.day\n",
    "        self.rel_humidity = rel_humidity # Fraction\n",
    "\n",
    "    def calculateETO(self):  #KLG\n",
    "        # numba doesn't speed this up in time tests  #KLG\n",
    "        # removing in favor of vectorization which will allow chunking with dask for speed  #KLG\n",
    "\n",
    "        \"\"\"Calculate the reference evapotranspiration with Penmann-Monteith Equation\n",
    "\n",
    "        Returns:\n",
    "            ## float: ETo of a single pixel (function is called pixel-wise)\n",
    "            float: ETo of each pixel  #KLG\n",
    "        \"\"\"        \n",
    "        # if self.parallel:\n",
    "        #     self.minT_daily=self.minT_daily.persist()\n",
    "        #     self.maxT_daily=self.maxT_daily.persist()\n",
    "            # self.windspeed_daily=self.windspeed_daily.persist()\n",
    "            # self.alt=self.alt.persist()\n",
    "            # self.latitude=self.latitude.persist()\n",
    "\n",
    "        # nchunks=238\n",
    "        # nlons=self.alt.shape[1]\n",
    "        # chunk_nlons=int(da.ceil(nlons/nchunks))\n",
    "        # chunks3D=(-1,chunk_nlons,-1)\n",
    "        # chunks2D=(-1,chunk_nlons)\n",
    "\n",
    "        print('tavg,lam,alt')\n",
    "        # constants\n",
    "        # tavg = 0.5*(maxT_daily+minT_daily)  # Averaged temperature\n",
    "        tavg = 0.5*(self.minT_daily + self.maxT_daily)  # Averaged temperature  #KLG\n",
    "        print('tavg.shape=',tavg.shape)\n",
    "        lam = 2.501 - 0.002361 * tavg  # Latent heat of vaporization\n",
    "        # if self.parallel:\n",
    "        #     dayoyr = da.arange(self.cycle_begin, self.cycle_end+1,chunks=-1)  # Julien Days #KLG\n",
    "        #     ndays=len(dayoyr)  #KLG\n",
    "        #     alt=da.tile(self.alt[:,:,np.newaxis],(1,1,ndays)).rechunk(chunks=self.chunk3D)\n",
    "        # else:\n",
    "            # dayoyr = np.arange(self.cycle_begin, self.cycle_end+1)  # Julien Days #KLG\n",
    "            # ndays=len(dayoyr)  #KLG            \n",
    "            # alt=np.tile(self.alt[:,:,np.newaxis],(1,1,ndays))  # 3D altitude #KLG\n",
    "        dayoyr = np.arange(self.cycle_begin, self.cycle_end+1)  # Julien Days #KLG\n",
    "        ndays=len(dayoyr)  #KLG            \n",
    "        alt=np.tile(self.alt[:,:,np.newaxis],(1,1,ndays))  # 3D altitude #KLG\n",
    "\n",
    "        # print('u2m')\n",
    "        # Wind speed\n",
    "        # u2m = windspeed_daily.copy()\n",
    "        # u2m = self.windspeed_daily.copy()  #KLG\n",
    "        # limit to no less than 0.5 m/s; FAO 56, p.63\n",
    "        # u2m[windspeed_daily < 0.5] = 0.5\n",
    "        # print('u2m.where')\n",
    "        # if self.parallel:\n",
    "        #     u2m=da.where(u2m < 0.5, 0.5, u2m)\n",
    "        # else:\n",
    "        #     u2m=np.where(u2m < 0.5, 0.5, u2m)\n",
    "        # u2m=np.where(u2m < 0.5, 0.5, u2m)\n",
    "\n",
    "        print('es_tmin,es_tmax')\n",
    "        # Mean Saturation Vapor Pressure derived from air temperature\n",
    "        # if self.parallel:\n",
    "        #     es_tmin = 0.6108 * da.exp((17.27 * self.minT_daily) / (self.minT_daily + 237.3))  #KLG\n",
    "        #     es_tmax = 0.6108 * da.exp((17.27 * self.maxT_daily) / (self.maxT_daily + 237.3))  #KLG\n",
    "        # else:            \n",
    "        #     es_tmin = 0.6108 * np.exp((17.27 * self.minT_daily) / (self.minT_daily + 237.3))\n",
    "        #     es_tmax = 0.6108 * np.exp((17.27 * self.maxT_daily) / (self.maxT_daily + 237.3))\n",
    "        es_tmin = 0.6108 * np.exp((17.27 * self.minT_daily) / (self.minT_daily + 237.3))\n",
    "        es_tmax = 0.6108 * np.exp((17.27 * self.maxT_daily) / (self.maxT_daily + 237.3))\n",
    "\n",
    "        print('es,ea')\n",
    "        es = 0.5*(es_tmin + es_tmax)\n",
    "        # ea = rel_humidity * es  # Actual Vapor Pressure derived from relative humidity\n",
    "        ea = self.rel_humidity * es  # Actual Vapor Pressure derived from relative humidity  #KLG\n",
    "\n",
    "        print('dlmx,dlmn,dl')\n",
    "        # slope vapour pressure curve\n",
    "        # dlmx = 4098. * es_tmax / (maxT_daily + 237.3)**2\n",
    "        # dlmn = 4098. * es_tmin / (minT_daily + 237.3)**2\n",
    "        dlmx = 4098. * es_tmax / (self.maxT_daily + 237.3)**2  #KLG\n",
    "        dlmn = 4098. * es_tmin / (self.minT_daily + 237.3)**2  #KLG\n",
    "        del es_tmin, es_tmax  #KLG\n",
    "        dl = 0.5* (dlmx + dlmn)\n",
    "        del dlmx,dlmn  #KLG\n",
    "\n",
    "        print('ap,gam')\n",
    "        # Atmospheric pressure\n",
    "        # if self.parallel:\n",
    "        #     ap = 101.3*da.power(((293-(0.0065*alt))/293), 5.256)\n",
    "        # else:\n",
    "        #     ap = 101.3*np.power(((293-(0.0065*alt))/293), 5.256)\n",
    "        ap = 101.3*np.power(((293-(0.0065*alt))/293), 5.256)\n",
    "\n",
    "            \n",
    "        # Psychrometric constant\n",
    "        gam = 0.0016286 * ap/lam\n",
    "        del ap\n",
    "\n",
    "        hw = 200.\n",
    "        ht = 190.\n",
    "        hc = 12.\n",
    "\n",
    "        print('rhoa,Rl,RLAI,rhic,gamst')\n",
    "        # aerodynamic resistance\n",
    "        rhoa = 208/self.u2m\n",
    "\n",
    "        # crop canopy resistance\n",
    "        Rl = 100  # daily stomata resistance of a single leaf (s/m)\n",
    "        # Standard is xLAO = 24\n",
    "        RLAI = 24 * 0.12\n",
    "        rhoc = Rl/(0.5*RLAI)  # crop canopy resistance\n",
    "\n",
    "        gamst = gam * (1. + rhoc/rhoa)\n",
    "\n",
    "        print('latr')\n",
    "        # latr = latitude * np.pi/180.\n",
    "        latr = self.latitude * np.pi/180.\n",
    "        # if self.parallel:\n",
    "        #     latr=da.tile(latr[:,:,np.newaxis],(1,1,ndays)).rechunk(chunks=self.chunk3D)\n",
    "        # else:\n",
    "        #     latr = np.tile(latr[:,:,np.newaxis],(1,1,ndays))\n",
    "        # latr = np.tile(latr[:,:,np.newaxis],(1,1,ndays))\n",
    "\n",
    "        print('sdcl')\n",
    "        # (a) calculate extraterrestrial radiation\n",
    "        # solar declination (rad)\n",
    "        # if self.parallel:\n",
    "        #     sdcl = 0.4093 * da.sin(0.017214206 * dayoyr - 1.405)\n",
    "        #     sdcl=da.broadcast_to(sdcl,(tavg.shape[0],tavg.shape[1],tavg.shape[2]),chunks=self.chunk3D)\n",
    "        # else:\n",
    "        #     sdcl = 0.4093 * np.sin(0.017214206 * dayoyr - 1.405)\n",
    "        #     sdcl = np.tile(sdcl[np.newaxis, np.newaxis,:], (tavg.shape[0],tavg.shape[1],1))\n",
    "        sdcl = 0.4093 * np.sin(0.017214206 * dayoyr - 1.405)\n",
    "        # sdcl = np.tile(sdcl[np.newaxis, np.newaxis,:], (tavg.shape[0],tavg.shape[1],1))\n",
    "        \n",
    "        print('sdst')\n",
    "        # relative distance earth to sun\n",
    "        # if self.parallel:\n",
    "        #     sdst = 1.0 + 0.033 * da.cos(0.017214206 * dayoyr)\n",
    "        #     sdst=da.broadcast_to(sdst,(tavg.shape[0],tavg.shape[1],tavg.shape[2]),chunks=self.chunk3D)\n",
    "        # else:\n",
    "        #     sdst = 1.0 + 0.033 * np.cos(0.017214206 * dayoyr)\n",
    "        #     sdst=np.tile(sdst[np.newaxis, np.newaxis,:], (tavg.shape[0],tavg.shape[1],1))\n",
    "        sdst = 1.0 + 0.033 * np.cos(0.017214206 * dayoyr)\n",
    "        # sdst=np.tile(sdst[np.newaxis, np.newaxis,:], (tavg.shape[0],tavg.shape[1],1))\n",
    "        del dayoyr\n",
    "\n",
    "        print('xx,yy,zz')\n",
    "        # if self.parallel:\n",
    "        #     xx = da.sin(sdcl) * da.sin(latr)\n",
    "        #     yy = da.cos(sdcl) * da.cos(latr)            \n",
    "        # else:\n",
    "        #     xx = np.sin(sdcl) * np.sin(latr)\n",
    "        #     yy = np.cos(sdcl) * np.cos(latr)\n",
    "        xx = np.sin(sdcl) * np.sin(latr)\n",
    "        yy = np.cos(sdcl) * np.cos(latr)\n",
    "        zz = xx/yy\n",
    "\n",
    "        print('omg,dayhr')\n",
    "        # if self.parallel:\n",
    "        #     omg = da.tan(zz / (1. - zz*zz)**0.5) + 1.5708\n",
    "        # else:\n",
    "        #     omg = np.tan(zz / (1. - zz*zz)**0.5) + 1.5708\n",
    "        omg = np.tan(zz / (1. - zz*zz)**0.5) + 1.5708\n",
    "        dayhr = 24. * (omg/np.pi)\n",
    "\n",
    "        # if self.parallel:\n",
    "        #     print('omg.where,dayhr.where,ra')\n",
    "        #     omg=da.where((da.abs(zz)>=0.9999)&(zz>0),np.pi,omg)\n",
    "        #     dayhr=da.where((da.abs(zz) >= 0.9999)&(zz > 0), 23.999,dayhr)\n",
    "\n",
    "        #     omg=da.where((da.abs(zz) >= 0.9999)&(zz <= 0),0,omg)\n",
    "        #     dayhr=da.where((da.abs(zz) >= 0.9999)&(zz <= 0), 0.001,dayhr)\n",
    "\n",
    "        #     print('ra')\n",
    "        #     ra = 37.586 * sdst * (omg*xx + da.sin(omg)*yy)\n",
    "        # else:\n",
    "        #     print('omg.where,dayhr.where,ra')\n",
    "        #     omg=np.where((np.abs(zz)>=0.9999)&(zz>0),np.pi,omg)\n",
    "        #     dayhr=np.where((np.abs(zz) >= 0.9999)&(zz > 0), 23.999,dayhr)\n",
    "\n",
    "        #     omg=np.where((np.abs(zz) >= 0.9999)&(zz <= 0),0,omg)\n",
    "        #     dayhr=np.where((np.abs(zz) >= 0.9999)&(zz <= 0), 0.001,dayhr) \n",
    "            \n",
    "        #     print('ra')\n",
    "        #     ra = 37.586 * sdst * (omg*xx + np.sin(omg)*yy)\n",
    "        print('omg.where,dayhr.where,ra')\n",
    "        omg_rev1=np.where((np.abs(zz)>=0.9999)&(zz>0),np.pi,omg)\n",
    "        dayhr_rev1=np.where((np.abs(zz) >= 0.9999)&(zz > 0), 23.999,dayhr)\n",
    "\n",
    "        omg_rev2=np.where((np.abs(zz) >= 0.9999)&(zz <= 0),0,omg_rev1)\n",
    "        dayhr_rev2=np.where((np.abs(zz) >= 0.9999)&(zz <= 0), 0.001,dayhr_rev1) \n",
    "        \n",
    "        print('ra')\n",
    "        ra = 37.586 * sdst * (omg_rev2*xx + np.sin(omg_rev2)*yy)\n",
    "        del sdcl, latr, sdst, omg, omg_rev1, omg_rev2, dayhr, dayhr_rev1, dayhr_rev2, xx, yy, zz        \n",
    "\n",
    "        print('rs,rs0')\n",
    "        # (b) solar radiation Rs (0.25, 0.50 Angstrom coefficients)\n",
    "        # rs = (0.25 + (0.50 * (sd/dayhr))) * ra\n",
    "        # rs = shortRad_daily\n",
    "        rs = self.shortRad_daily  #KLG\n",
    "        # rs0 = (0.75 + 0.00002 * alt) * ra\n",
    "        rs0 = (0.75 + 0.00002 * self.alt) * ra\n",
    "        \n",
    "        del alt\n",
    "\n",
    "        print('rns,rnl')\n",
    "        # (c) net shortwave radiation Rns = (1 - alpha) * Rs\n",
    "        # (alpha for grass = 0.23)\n",
    "        rns = 0.77 * rs\n",
    "\n",
    "        # (d) net longwave radiation Rnl\n",
    "        # Stefan-Boltzmann constant [MJ K-4 m-2 day-1]\n",
    "        sub_cst = 0.000000004903\n",
    "        rs_div_ds0=rs/rs0\n",
    "        rnl = (((273.16+self.maxT_daily)**4)+((273.16 + self.minT_daily)**4)) * \\\n",
    "            (0.34 - (0.14*(ea**0.5))) * \\\n",
    "            ((1.35*(rs_div_ds0))-0.35)*sub_cst/2\n",
    "        del rs0,rs\n",
    "\n",
    "        print('rn')\n",
    "        # (e) net radiation Rn = Rns - Rnl\n",
    "        rn = rns - rnl\n",
    "        del rns,rnl\n",
    "\n",
    "        print('ta_diff,G')\n",
    "        # (f) soil heat flux [MJ/m2/day]\n",
    "        # if self.parallel:\n",
    "        #     ta_diff=da.diff(tavg,n=1,axis=2,prepend=tavg[:,:,-1:])  #KLG\n",
    "        # else:\n",
    "        #     ta_diff=np.diff(tavg,n=1,axis=2,prepend=tavg[:,:,-1:])  #KLG\n",
    "        ta_diff=np.diff(tavg,n=1,axis=2,prepend=tavg[:,:,-1:])  #KLG\n",
    "        G = 0.14 * ta_diff  #KLG\n",
    "        del ta_diff\n",
    "\n",
    "        print('et0ady')\n",
    "        # (g) calculate aerodynamic and radiation terms of ET0\n",
    "        et0ady = gam/(dl+gamst) * 900./(tavg+273.) * self.u2m * (es-ea)\n",
    "        del gam,tavg,es,ea\n",
    "\n",
    "        print('et0rad')\n",
    "        et0rad = dl/(dl+gamst) * (rn-G) / lam\n",
    "        del dl,gamst,rn,G,lam\n",
    "\n",
    "        print('et0')\n",
    "        et0 = et0ady + et0rad\n",
    "        del et0ady,et0rad\n",
    "\n",
    "        print('et0.where')\n",
    "        # et0[et0 < 0] = 0\n",
    "        # if self.parallel:\n",
    "        #     et0=da.where(et0<0,0,et0)\n",
    "        # else:\n",
    "        #     et0=np.where(et0<0,0,et0)\n",
    "        et0=np.where(et0<0,0,et0)\n",
    "\n",
    "        return et0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pet(doy_start, doy_end, chunk3D, latitude, elevation, min_temp, max_temp, wind_speed, short_rad, rel_humidity):\n",
    "    print('initializing obj_eto')\n",
    "    obj_eto = ETOCalc(doy_start, doy_end, latitude, elevation, chunk3D)  #KLG\n",
    "    \n",
    "    print('adjusting short_rad units')\n",
    "    shortrad_daily_MJm2day = (short_rad*3600.*24.)/1000000. # convert w/m2 to MJ/m2/day  #KLG    \n",
    "\n",
    "    print('obj_eto.setClimateData')\n",
    "    obj_eto.setClimateData(min_temp, max_temp, wind_speed, shortrad_daily_MJm2day, rel_humidity)  #KLG\n",
    "\n",
    "    pet_daily= obj_eto.calculateETO()\n",
    "    return pet_daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDailyClimateData(self, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity):\n",
    "\n",
    "    if self.parallel:\n",
    "        print('rechunking')\n",
    "        min_temp=min_temp.rechunk(chunks=self.chunk3D).to_delayed()\n",
    "        max_temp=max_temp.rechunk(chunks=self.chunk3D).to_delayed()\n",
    "        # precipitation=precipitation.rechunk(chunks=self.chunk3D)\n",
    "        short_rad=short_rad.rechunk(chunks=self.chunk3D)\n",
    "        wind_speed=wind_speed.rechunk(chunks=self.chunk3D)\n",
    "        rel_humidity=rel_humidity.rechunk(chunks=self.chunk3D)\n",
    "        # latitude and elevation are already chunked correctly    \n",
    "\n",
    "        print('removing negative data values')\n",
    "        rel_humidity=da.where(rel_humidity > 0.99, 0.99,rel_humidity)\n",
    "        rel_humidity=da.where(rel_humidity < 0.05, 0.05,rel_humidity)\n",
    "        short_rad=da.where(short_rad < 0, 0, short_rad)\n",
    "        # wind_speed=da.where(wind_speed < 0, 0, wind_speed)  \n",
    "        wind_speed=da.where(wind_speed < 0.5, 0.5, wind_speed)\n",
    "\n",
    "        rel_humidity=rel_humidity.to_delayed()\n",
    "        short_rad=short_rad.to_delayed()\n",
    "        wind_speed=wind_speed.to_delayed()\n",
    "\n",
    "        latitude=self.latitude.to_delayed()\n",
    "        elevation=self.elevation.to_delayed()        \n",
    "\n",
    "    self.doy_start=1  #KLG\n",
    "    self.doy_end=min_temp.shape[2]  #KLG\n",
    "\n",
    "    task_list=[dask.delayed(compute_pet)(self.doy_start,self.doy_end,self.chunk3D, lat_chunk, elev_chunk, minT_chunk, maxT_chunk, wind_chunk, rad_chunk, rhum_chunk) for lat_chunk, elev_chunk, minT_chunk, maxT_chunk, wind_chunk, rad_chunk, rhum_chunk in zip(latitude[0,:], elevation[0,:], min_temp[0,:], max_temp[0,:], wind_speed[0,:], short_rad[0,:], rel_humidity[0,:])]\n",
    "\n",
    "    result_chunks=dask.compute(*task_list)\n",
    "    self.pet_daily=np.concat(result_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setDailyClimateData(clim_reg, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setDailyClimateData(self, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity):\n",
    "    # print('converting inputs to dask arrays')\n",
    "    # nchunks=238\n",
    "    # nlons=min_temp.shape[1]\n",
    "    # chunk_nlons=int(np.ceil(nlons/nchunks))\n",
    "    # chunks3D=(-1,chunk_nlons,-1)\n",
    "    # chunks2D=(-1,chunk_nlons)\n",
    "    # print(nchunks,nlons,chunk_nlons,chunks3D)\n",
    "\n",
    "    # min_temp=da.from_array(min_temp,chunks=chunks3D)\n",
    "    # max_temp=da.from_array(max_temp,chunks=chunks3D)\n",
    "    # precipitation=da.from_array(precipitation,chunks=chunks3D)\n",
    "    # short_rad=da.from_array(short_rad,chunks=chunks3D)\n",
    "    # wind_speed=da.from_array(wind_speed,chunks=chunks3D)\n",
    "    # rel_humidity=da.from_array(rel_humidity,chunks=chunks3D)\n",
    "    # latitude=da.from_array(self.latitude,chunks=chunks2D)\n",
    "    # elevation=da.from_array(self.elevation,chunks=chunks2D)\n",
    "    if self.parallel:\n",
    "        print('rechunking')\n",
    "        min_temp=min_temp.rechunk(chunks=self.chunk3D)\n",
    "        max_temp=max_temp.rechunk(chunks=self.chunk3D)\n",
    "        precipitation=precipitation.rechunk(chunks=self.chunk3D)\n",
    "        short_rad=short_rad.rechunk(chunks=self.chunk3D)\n",
    "        wind_speed=wind_speed.rechunk(chunks=self.chunk3D)\n",
    "        rel_humidity=rel_humidity.rechunk(chunks=self.chunk3D)\n",
    "        # latitude and elevation are already chunked correctly\n",
    "\n",
    "        # min_temp=min_temp.persist()\n",
    "        # max_temp=max_temp.persist()\n",
    "        # precipitation=precipitation.persist()\n",
    "        # short_rad=short_rad.persist()\n",
    "        # wind_speed=wind_speed.persist()\n",
    "        # rel_humidity=rel_humidity.persist()        \n",
    "\n",
    "        print('removing negative data values')\n",
    "        rel_humidity=da.where(rel_humidity > 0.99, 0.99,rel_humidity)\n",
    "        rel_humidity=da.where(rel_humidity < 0.05, 0.05,rel_humidity)\n",
    "        short_rad=da.where(short_rad < 0, 0, short_rad)\n",
    "        wind_speed=da.where(wind_speed < 0, 0, wind_speed)  \n",
    "\n",
    "\n",
    "    else:\n",
    "        print('removing negative data values')\n",
    "        rel_humidity[rel_humidity > 0.99] = 0.99\n",
    "        rel_humidity[rel_humidity < 0.05] = 0.05\n",
    "        short_rad[short_rad < 0] = 0\n",
    "        wind_speed[wind_speed < 0] = 0\n",
    "\n",
    "    self.doy_start=1  #KLG\n",
    "    self.doy_end=min_temp.shape[2]  #KLG\n",
    "\n",
    "\n",
    "\n",
    "    # calculation of reference evapotranspiration (ETo)  #KLG\n",
    "    print('initializing obj_eto')\n",
    "    obj_eto = ETOCalc(self.doy_start, self.doy_end, self.latitude, self.elevation,self.chunk3D)  #KLG\n",
    "\n",
    "    print('adjusting short_rad units')\n",
    "    shortrad_daily_MJm2day = (short_rad*3600.*24.)/1000000. # convert w/m2 to MJ/m2/day  #KLG\n",
    "    # shortrad_daily_MJm2day=shortrad_daily_MJm2day.persist()\n",
    "    print('obj_eto.setClimateData')\n",
    "    obj_eto.setClimateData(min_temp, max_temp, wind_speed, shortrad_daily_MJm2day, rel_humidity)  #KLG\n",
    "    del rel_humidity,short_rad,wind_speed,shortrad_daily_MJm2day  #KLG\n",
    "    # print('pet equations')\n",
    "    # pet_daily= obj_eto.calculateETO()   #KLG\n",
    "    # print(pet_daily)\n",
    "    print('computing pet')\n",
    "    if self.parallel:\n",
    "        # self.pet_daily=pet_daily.compute()\n",
    "        self.pet_daily= obj_eto.calculateETO().compute()   #KLG\n",
    "        # self.pet_daily= obj_eto.calculateETO()\n",
    "\n",
    "    else:\n",
    "        self.pet_daily= obj_eto.calculateETO()\n",
    "    del obj_eto\n",
    "\n",
    "    # print('computing meanT, meanT_daily_sealevel, P_by_PET_daily')\n",
    "    # self.meanT_daily = 0.5*(min_temp+max_temp)  #KLG\n",
    "\n",
    "    # # sea level temperature\n",
    "    # # P over PET ratio (to eliminate nan in the result, nan is replaced with zero)\n",
    "    # if self.parallel:\n",
    "    #     self.meanT_daily_sealevel = self.meanT_daily + (da.tile(self.elevation[:,:,np.newaxis],(1,1,self.doy_end)).rechunk(chunks=self.chunk3D)/100*0.55)\n",
    "    #     self.P_by_PET_daily = da.nan_to_num(precipitation / self.pet_daily)\n",
    "    # else:\n",
    "    #     self.meanT_daily_sealevel = self.meanT_daily + np.expand_dims(self.elevation/100*0.55,axis=2) # automatic broadcasting #KLG        \n",
    "    #     self.P_by_PET_daily = np.nan_to_num(precipitation / self.pet_daily)\n",
    "\n",
    "    # self.set_monthly = False\n",
    "\n",
    "    # print('computing interp_daily_temp')\n",
    "    # # smoothed daily temperature\n",
    "    # # create a mask of all 1's if the user doesn't provide a mask\n",
    "    # if self.set_mask:\n",
    "    #     mask=self.im_mask\n",
    "    # else:\n",
    "    #     mask=np.ones((self.im_height,self.im_width),dtype='int')\n",
    "\n",
    "    # obj_utilities = UtilitiesCalc.UtilitiesCalc(self.chunk2D,self.chunk3D)  #KLG\n",
    "\n",
    "    # # if self.parallel:\n",
    "    # self.interp_daily_temp=obj_utilities.smoothDailyTemp(self.doy_start,self.doy_end, mask, self.meanT_daily,self.chunk3D)\n",
    "    # # else:\n",
    "    #     # self.interp_daily_temp=obj_utilities.smoothDailyTemp(self.doy_start,self.doy_end, mask, self.meanT_daily)  \n",
    "\n",
    "    # print('copying maxT_daily,minT_daily,totalPrec_daily')\n",
    "    # self.maxT_daily = max_temp\n",
    "    # # self.minT_daily = min_temp\n",
    "    # self.totalPrec_daily = precipitation  #KLG    \n",
    "    \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setDailyClimateData(clim_reg, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.pet_daily.shape,clim_reg.nchunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels=clim_reg.__dict__.keys()\n",
    "data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clim_reg.set_mask:\n",
    "    mask=clim_reg.im_mask\n",
    "else:\n",
    "    mask=np.ones((clim_reg.im_height,clim_reg.im_width),dtype='int')\n",
    "\n",
    "# this takes 100s\n",
    "# days = np.arange(clim_reg.doy_start,clim_reg.doy_end+1) # x values  #KLG\n",
    "# mask3D = np.tile(mask[:,:,np.newaxis], (1,1,days.shape[0]))  #KLG\n",
    "# data=np.where(mask3D==0,0,clim_reg.meanT_daily)   #KLG\n",
    "# data2D=data.transpose(2,0,1).reshape(days.shape[0],-1) # every column is a set of y values  #KLG\n",
    "# del data  #KLG\n",
    "# quad_spl=np.polynomial.polynomial.polyfit(days,data2D,deg=5)  #KLG\n",
    "# interp_daily_temp=np.polynomial.polynomial.polyval(days,quad_spl)  #KLG\n",
    "# interp_daily_temp=interp_daily_temp.reshape(mask3D.shape[0],mask3D.shape[1],-1)  #KLG\n",
    "# interp_daily_temp=np.where(mask3D==0,np.nan,interp_daily_temp)        \n",
    "# interp_daily_temp.shape\n",
    "\n",
    "# this takes 33s\n",
    "# days = np.arange(clim_reg.doy_start,clim_reg.doy_end+1) # x values  #KLG\n",
    "# mask3D = da.tile(mask[:,:,np.newaxis], (1,1,days.shape[0])).rechunk(chunks=clim_reg.chunk3D)  #KLG\n",
    "# data=da.where(mask3D==0,0,clim_reg.meanT_daily)   #KLG\n",
    "# nlats=data.shape[0]\n",
    "# data2D=data.transpose(2,0,1).reshape(days.shape[0],-1).rechunk(chunks=(clim_reg.chunk3D[0],clim_reg.chunk3D[1]*nlats)) # every column is a set of y values  #KLG\n",
    "# coefs=np.polynomial.polynomial.polyfit(days,data2D,deg=5)  #KLG\n",
    "# interp_daily_temp=np.polynomial.polynomial.polyval(days,coefs)  #KLG\n",
    "# interp_daily_temp.shape\n",
    "\n",
    "\n",
    "# # this takes 33s\n",
    "# days = np.arange(clim_reg.doy_start,clim_reg.doy_end+1) # x values  #KLG\n",
    "# mask3D = da.tile(mask[:,:,np.newaxis], (1,1,days.shape[0])).rechunk(chunks=clim_reg.chunk3D)  #KLG\n",
    "# data=da.where(mask3D==0,0,clim_reg.meanT_daily)   #KLG\n",
    "# nlats=data.shape[0]\n",
    "# data2D=data.transpose(2,0,1).reshape(days.shape[0],-1).rechunk(chunks=(clim_reg.chunk3D[0],clim_reg.chunk3D[1]*nlats))#(-1,-1)) # every column is a set of y values  #KLG\n",
    "# def polyfit(x,y,deg):\n",
    "#     coefs=np.polynomial.polynomial.polyfit(x,y,deg=deg)\n",
    "#     return coefs\n",
    "# deg=5\n",
    "# coefs=da.apply_gufunc(polyfit,\"(t),(t,s),()->(d,s)\",days,data2D,deg,output_dtypes='float32',output_sizes={'t':data2D.shape[0],'s':data2D.shape[1],'d':deg+1},vectorize=True)#.compute()\n",
    "# def polyval(x,coefs):\n",
    "#     spline=np.polynomial.polynomial.polyval(x,coefs)    \n",
    "#     return spline\n",
    "# interp_daily_temp=da.apply_gufunc(polyval,\"(t),(d,s)->(s,t)\",days,coefs,output_dtypes='float32',output_sizes={'t':data2D.shape[0],'s':data2D.shape[1],'d':deg+1},vectorize=True).compute()\n",
    "# interp_daily_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clim_reg.set_mask:\n",
    "    mask=clim_reg.im_mask\n",
    "else:\n",
    "    mask=np.ones((clim_reg.im_height,clim_reg.im_width),dtype='int')\n",
    "\n",
    "days1D = np.arange(clim_reg.doy_start,clim_reg.doy_end+1) # x values  #KLG\n",
    "mask3D = da.tile(mask[:,:,np.newaxis], (1,1,days1D.shape[0])).rechunk(chunks=clim_reg.chunk3D)  #KLG\n",
    "data=da.where(mask3D==0,0,clim_reg.meanT_daily)   #KLG\n",
    "nlats=data.shape[0]\n",
    "data2D=data.transpose(2,0,1).reshape(days1D.shape[0],-1).rechunk({0:-1,1:'auto'})\n",
    "\n",
    "days1D=dask.delayed(days1D)\n",
    "partitions=data2D.to_delayed()\n",
    "\n",
    "def polyfit_polyval(x,y,deg):\n",
    "    coefs=np.polynomial.polynomial.polyfit(x,y,deg=deg)         \n",
    "    spline=np.polynomial.polynomial.polyval(x,coefs) \n",
    "    return spline   \n",
    "\n",
    "deg=5\n",
    "delayed_values = [dask.delayed(polyfit_polyval)(days1D,part,deg) for part in partitions[0,:]]\n",
    "results=dask.compute(*delayed_values)\n",
    "\n",
    "interp_daily_temp=np.concatenate(results).reshape(mask3D.shape[0],mask3D.shape[1],-1)  #KLG\n",
    "# interp_daily_temp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[0].shape\n",
    "test=np.concatenate(results)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clim_reg.set_mask:\n",
    "    mask=clim_reg.im_mask\n",
    "else:\n",
    "    mask=np.ones((clim_reg.im_height,clim_reg.im_width),dtype='int')\n",
    "\n",
    "days1D = np.arange(clim_reg.doy_start,clim_reg.doy_end+1) # x values  #KLG\n",
    "# days1D = da.arange(clim_reg.doy_start,clim_reg.doy_end+1,chunks=-1) # x values  #KLG\n",
    "mask3D = np.tile(mask[:,:,np.newaxis], (1,1,days1D.shape[0])) #KLG\n",
    "data=np.where(mask3D==0,0,clim_reg.meanT_daily)   #KLG\n",
    "data2D=data.transpose(2,0,1).reshape(days1D.shape[0],-1)#.rechunk(chunks=-1)#(clim_reg.chunk3D[0],clim_reg.chunk3D[1]*nlats))#(-1,-1)) # every column is a set of y values  #KLG\n",
    "ngrids=data2D.shape[1]\n",
    "# days2D = da.from_array(np.tile(days1D[:,np.newaxis],(1,data2D.shape[1])),chunks=(clim_reg.chunk3D[0],clim_reg.chunk3D[1]*nlats)) # x values  #KLG\n",
    "\n",
    "# @dask.delayed\n",
    "# def polyfit(x,y,deg):\n",
    "#     coefs=np.polynomial.polynomial.polyfit(x,y,deg=deg)\n",
    "#     return coefs\n",
    "\n",
    "# def polyval(x,coefs):\n",
    "#     spline=np.polynomial.polynomial.polyval(x,coefs)    \n",
    "#     return spline   \n",
    "# days1D=dask.persist(days1D)\n",
    "# data2D=dask.persist(data2D)\n",
    "days1D=dask.delayed(days1D)\n",
    "data2D=dask.delayed(data2D)\n",
    "\n",
    "@dask.delayed\n",
    "def polyfit_polyval(x,y,deg):\n",
    "    coefs=np.polynomial.polynomial.polyfit(x,y,deg=deg)         \n",
    "    spline=np.polynomial.polynomial.polyval(x,coefs) \n",
    "    return spline   \n",
    "\n",
    "deg=5\n",
    "nlats_block=int(np.ceil(ngrids/clim_reg.nchunks))\n",
    "# ngrids,clim_reg.nchunks,nlats_block\n",
    "\n",
    "# interp_T=np.empty((data2D.shape[1],data2D.shape[0]),dtype='float32')\n",
    "\n",
    "task_list=[]\n",
    "for ichunk in range(clim_reg.nchunks)[0:3]:\n",
    "    istart=ichunk*nlats_block\n",
    "    if ichunk < clim_reg.nchunks-1:\n",
    "        iend=istart+nlats_block\n",
    "    else:\n",
    "        iend=ngrids\n",
    "    print(istart,iend)\n",
    "    interp_task=polyfit_polyval(days1D,data2D[:,istart:iend],deg)\n",
    "    task_list.append(interp_task)\n",
    "print('computing')\n",
    "interp_list=dask.compute(*task_list)\n",
    "\n",
    "interp_list[0].shape\n",
    "# interp_temp_daily=np.concat(interp_list,axis=1)\n",
    "\n",
    "# task_list=[]\n",
    "# for ichunk in range(clim_reg.nchunks)[0:3]:\n",
    "#     istart=ichunk*nlats_block\n",
    "#     if ichunk < clim_reg.nchunks-1:\n",
    "#         iend=istart+nlats_block\n",
    "#     else:\n",
    "#         iend=ngrids\n",
    "\n",
    "#     interp_task=polyval(days1D,coefs_list[ichunk])\n",
    "#     task_list.append(coefs_task)\n",
    "# coefs_list=dask.compute(*task_list)\n",
    "\n",
    "#     print(coefs.T)\n",
    "\n",
    "        # T=polyval(days1D,coefs)\n",
    "\n",
    "    # print(istart,iend)\n",
    "# days1D.shape,data2D.shape\n",
    "\n",
    "# for block in data2D.blocks:\n",
    "#     coef_block=polyfit(days1D,block)\n",
    "\n",
    "# data2D.blocks[0,1]\n",
    "\n",
    "# coefs=da.apply_gufunc(polyfit,\"(t),(t,s),()->(d,s)\",days,data2D,deg,output_dtypes='float32',output_sizes={'t':data2D.shape[0],'s':data2D.shape[1],'d':deg+1},vectorize=True)#.compute()\n",
    "# coefs=da.map_blocks(polyfit,days2D,data2D,dtype='float32',chunks=(deg+1,clim_reg.chunk3D[1]*nlats),drop_axis=0,new_axis=0,meta=np.empty((6,data2D.shape[1]),dtype='float32'))#.compute()\n",
    "# coefs.shape\n",
    "# def polyval(x,coefs):\n",
    "#     spline=np.polynomial.polynomial.polyval(x,coefs)    \n",
    "#     return spline\n",
    "# # interp_daily_temp=da.apply_gufunc(polyval,\"(t),(d,s)->(s,t)\",days,coefs,output_dtypes='float32',output_sizes={'t':data2D.shape[0],'s':data2D.shape[1],'d':deg+1},vectorize=True).compute()\n",
    "# interp_daily_temp=da.apply_gufunc(polyval,\"(t),(d,s)->(s,t)\",days1D,coefs,output_dtypes='float32',output_sizes={'t':data2D.shape[0],'s':data2D.shape[1],'d':deg+1},vectorize=True,allow_rechunk=True).compute()\n",
    "# interp_daily_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2D=min_temp.transpose(2,0,1).reshape(365,-1).rechunk(chunks=(-1,7200)) # every column is a set of y values  #KLG\n",
    "data2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_reg.pet_daily.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def setDailyClimateData(self, min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity):\n",
    "        \"\"\"Load DAILY climate data into the Class and calculate the Reference Evapotranspiration (ETo)\n",
    "\n",
    "        Args:\n",
    "            min_temp (3D NumPy): Daily minimum temperature [Celcius]\n",
    "            max_temp (3D NumPy): Daily maximum temperature [Celcius]\n",
    "            precipitation (3D NumPy): Daily total precipitation [mm/day]\n",
    "            short_rad (3D NumPy): Daily solar radiation [W/m2]\n",
    "            wind_speed (3D NumPy): Daily windspeed at 2m altitude [m/s]\n",
    "            rel_humidity (3D NumPy): Daily relative humidity [percentage decimal, 0-1]\n",
    "        \"\"\"\n",
    "        self.doy_start=1  #KLG\n",
    "        self.doy_end=min_temp.shape[2]  #KLG\n",
    "\n",
    "        rel_humidity[rel_humidity > 0.99] = 0.99\n",
    "        rel_humidity[rel_humidity < 0.05] = 0.05\n",
    "        short_rad[short_rad < 0] = 0\n",
    "        wind_speed[wind_speed < 0] = 0\n",
    "                \n",
    "        # self.meanT_daily = np.zeros((self.im_height, self.im_width, 365)) \n",
    "        # self.totalPrec_daily = np.zeros((self.im_height, self.im_width, 365)) \n",
    "        # self.pet_daily = np.zeros((self.im_height, self.im_width, 365))  \n",
    "        self.maxT_daily = max_temp\n",
    "        self.minT_daily = min_temp\n",
    "        self.totalPrec_daily = precipitation  #KLG\n",
    "        del max_temp, min_temp, precipitation  #KLG\n",
    "\n",
    "\n",
    "        # calculation of reference evapotranspiration (ETo)  #KLG\n",
    "        obj_eto = ETOCalc.ETOCalc(self.doy_start, self.doy_end, self.latitude, self.elevation)  #KLG\n",
    "        shortrad_daily_MJm2day = (short_rad*3600.*24.)/1000000. # convert w/m2 to MJ/m2/day  #KLG\n",
    "        obj_eto.setClimateData(self.minT_daily, self.maxT_daily, wind_speed, shortrad_daily_MJm2day, rel_humidity)  #KLG\n",
    "        del rel_humidity,short_rad,wind_speed,shortrad_daily_MJm2day  #KLG\n",
    "        self.pet_daily= obj_eto.calculateETO()   #KLG\n",
    "        del obj_eto\n",
    "\n",
    "        # sea level temperature\n",
    "        # self.meanT_daily_sealevel = self.meanT_daily + np.tile(np.reshape(self.elevation/100*0.55, (self.im_height,self.im_width,1)), (1,1,365))\n",
    "        self.meanT_daily = 0.5*(self.minT_daily+self.maxT_daily)  #KLG\n",
    "        self.meanT_daily_sealevel = self.meanT_daily + np.expand_dims(self.elevation/100*0.55,axis=2) # automatic broadcasting #KLG        \n",
    "\n",
    "        # P over PET ratio (to eliminate nan in the result, nan is replaced with zero)\n",
    "        self.P_by_PET_daily = np.nan_to_num(self.totalPrec_daily / self.pet_daily)\n",
    "        self.set_monthly = False\n",
    "\n",
    "        # smoothed daily temperature\n",
    "        obj_utilities = UtilitiesCalc.UtilitiesCalc()  #KLG\n",
    "\n",
    "        if self.set_mask:\n",
    "            mask=self.im_mask\n",
    "        else:\n",
    "            mask=np.ones((self.im_height,self.im_width),dtype='int')\n",
    "\n",
    "        if self.parallel:\n",
    "            self.interp_daily_temp=obj_utilities.smoothDailyTemp(self.doy_start,self.doy_end, mask, self.meanT_daily,self.chunk3D)\n",
    "        else:\n",
    "            self.interp_daily_temp=obj_utilities.smoothDailyTemp(self.doy_start,self.doy_end, mask, self.meanT_daily)\n",
    "\n",
    "\n",
    "        self.chunk3D=(-1,94,-1)\n",
    "        self.chunk2D=(-1,94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expect ~30 seconds run time for china\n",
    "\n",
    "# start=timer()\n",
    "\n",
    "# if daily:\n",
    "#     clim_reg.setDailyClimateData(\n",
    "#         min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)\n",
    "# else:\n",
    "#     clim_reg.setMonthlyClimateData(\n",
    "#         min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)\n",
    "    \n",
    "# task_time=timer()-start\n",
    "# task_time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Releasing the memory of input climate data -- free up some RAM space'\n",
    "# del(min_temp, max_temp, precipitation, short_rad, wind_speed, rel_humidity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all the data in the class instance clim_reg\n",
    "\n",
    "data_labels=clim_reg.__dict__.keys()\n",
    "data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity check\n",
    "# # plot 2D & 3D data, print value of scalars \n",
    "\n",
    "# for key in data_labels:\n",
    "#     print(key)    \n",
    "#     try:\n",
    "#         ndims=len(clim_reg.__getattribute__(key).shape)\n",
    "#         # dims=clim_reg.__getattribute__(key).shape\n",
    "#     except:\n",
    "#         ndims=1\n",
    "#     if ndims==1:\n",
    "#         print(key,'=',clim_reg.__getattribute__(key))\n",
    "#     if ndims==2:\n",
    "#         plt.imshow(clim_reg.__getattribute__(key),interpolation='none')\n",
    "#         plt.colorbar(shrink=0.5)\n",
    "#         plt.title(key)\n",
    "#         plt.show()\n",
    "#     if ndims==3:\n",
    "#         plt.imshow(clim_reg.__getattribute__(key)[:,:,0],interpolation='none')\n",
    "#         plt.colorbar(shrink=0.5)\n",
    "#         plt.title(key)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list=[]\n",
    "# for key in data_labels:\n",
    "#     data_list.append(clim_reg.__getattribute__(key))\n",
    "\n",
    "# data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fut_climreg=dask.persist(*data_list)\n",
    "\n",
    "# fut_climreg.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da_vars=clim_reg.meanT_daily\n",
    "# da_vars.store(clim_reg.meanT_daily,return_stored=True)\n",
    "# da_vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fut_climreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: After loading the data into the *clim_reg* Class, all the parameters will be converted to DAILY DATA and calculated as other parameters. \n",
    "These new parameters are available and can be called into use as:\n",
    "- *clim_reg.minT_daily* (minimum temperature)\n",
    "- *clim_reg.maxT_daily* (maximum temperature)\n",
    "- *clim_reg.meanT_daily* (mean temperature)\n",
    "- *clim_reg.meanT_daily_sealevel* (mean temperature, corrected to sea-level)\n",
    "- *clim_reg.totalPrec_daily* (total precipitation)\n",
    "- *clim_reg.pet_daily* (reference evapotranspiration, ETo)\n",
    "- *clim_reg.P_by_PET_daily* (ratio of precipitation over ETo)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thermal Climate\n",
    "The Thermal Climate function calculates and classifies latitudinal thermal climate, which will be used later in Module 2 for the assessment of potential crops and land utilization types (LUT) presence in each grid cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~50 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "tclimate = clim_reg.getThermalClimate()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(tclimate, cmap=plt.get_cmap('gist_ncar_r', 12),vmin=-0.3,vmax=12.5,interpolation='none')\n",
    "plt.title('Thermal Climate')\n",
    "plt.colorbar(shrink=0.4)\n",
    "plt.savefig(out_path+\"ThermalClimate.png\",bbox_inches =\"tight\",dpi=300) #Save as PNG image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_utilities.saveRaster(mask_path, out_path+'ThermalClimate_'+revname+'.tif',tclimate) #Save as GeoTIFF raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thermal Zone\n",
    "The thermal zone is classified based on actual temperature which reflects on the temperature regimes of major thermal climates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~35 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "tzone = clim_reg.getThermalZone()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(tzone, cmap=plt.get_cmap('gist_ncar_r', 12),vmin=-0.3,vmax=12.5,interpolation='none')\n",
    "plt.title('Thermal Zones')\n",
    "plt.colorbar(shrink=0.4)\n",
    "plt.savefig(out_path+\"ThermalZone\"+revname+\".png\",bbox_inches =\"tight\",dpi=300) #Save as PNG image\n",
    "plt.show()\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'ThermalZone'+revname+'.tif',tzone) #Save as GeoTIFF raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thermal Length of Growing Period (LGP)\n",
    "The thermal length of growing period (LGPt) is defined as the number of days in a year during which the daily mean temperature (Ta) is conductive to crop growth and development. PyAEZ utilizes the AEZ three standard temperature thresholds for LGPt:\n",
    "- Periods with Ta>0°C (LGPt0)\n",
    "- Periods with Ta>5°C (LGPt5) – the period conductive to plant growth and development\n",
    "- Periods, and Ta>10°C (LGPt10) – a proxy for the period of low risks for late and early frost occurrences and termed ‘frost-free period’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~1 second run time for china\n",
    "start=timer()\n",
    "\n",
    "lgpt0 = clim_reg.getThermalLGP0()\n",
    "lgpt5 = clim_reg.getThermalLGP5()\n",
    "lgpt10 = clim_reg.getThermalLGP10()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "#======================\n",
    "# plt.figure(figsize=(20, 4),dpi=300)\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(lgpt0,vmin=0,vmax=366,interpolation='none')\n",
    "plt.title('LGPt 0')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(lgpt5, vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGPt 5')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(lgpt10, vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGPt 10')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.savefig(out_path+\"ThermalLGPs\"+revname+\".png\",\n",
    "            bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "#======================\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'LGPt0_'+revname+'.tif', lgpt0)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'LGPt5_'+revname+'.tif', lgpt5)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'LGPt10_'+revname+'.tif', lgpt10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~1 second run time for china\n",
    "start=timer()\n",
    "\n",
    "tsum0 = clim_reg.getTemperatureSum0()\n",
    "tsum5 = clim_reg.getTemperatureSum5()\n",
    "tsum10 = clim_reg.getTemperatureSum10()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "#======================\n",
    "# plt.figure(1, figsize=(20, 4),dpi=300)\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(tsum0, cmap='hot_r', vmin=0, vmax=11000,interpolation='none')\n",
    "plt.title('T-sumation 0')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(tsum5, cmap='hot_r', vmin=0, vmax=11000,interpolation='none')\n",
    "plt.title('T-sumation 5')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(tsum10, cmap='hot_r', vmin=0, vmax=11000,interpolation='none')\n",
    "plt.title('T-sumation 10')\n",
    "plt.colorbar(shrink=0.8)\n",
    "#----------------------\n",
    "plt.savefig(out_path+\"Tsum_\"+revname+\".png\",\n",
    "            bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "#======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_utilities.saveRaster(mask_path, out_path+'tsum0_'+revname+'.tif', tsum0)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'tsum5_'+revname+'.tif', tsum5)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'tsum10_'+revname+'.tif', tsum10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized+parallel: expect ~1 second run time for china\n",
    "# vectorized: expect ~6 seconds run time for china\n",
    "# non-vectorized: expect ~50 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "tprofile = clim_reg.getTemperatureProfile()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "tile_list = ['A1','A2','A3','A4','A5','A6','A7','A8','A9',\n",
    "            'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9']\n",
    "\n",
    "# fig = plt.figure(figsize=(12, 12))\n",
    "fig = plt.figure()\n",
    "for i1 in range(1, 19):\n",
    "    plt.subplot(6, 3, i1)\n",
    "    plt.imshow(tprofile[i1-1],interpolation='none')\n",
    "    plt.title(tile_list[i1-1])\n",
    "    plt.colorbar(shrink=0.8)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(out_path+\"Tprofiles_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1 in range(18):\n",
    "    obj_utilities.saveRaster(mask_path, out_path+'TProfile_' + tile_list[i1] +'_'+revname+'.tif', tprofile[i1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length of Growing Periods (LGPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def test_func1(x,y,z,X,Y,Z,mask):\n",
    "    x=x*2\n",
    "    y=y+3\n",
    "    z=z**2\n",
    "    X=np.where(mask,x,X)\n",
    "    Y=np.where(mask,y,Y)\n",
    "    Z=np.where(mask,z,Z)\n",
    "    return X,Y,Z\n",
    "\n",
    "def test_func2(out1,out2,out3):\n",
    "    out1=out1+10\n",
    "    out2=out2+20\n",
    "    out3=out3+30\n",
    "    return out1,out2,out3\n",
    "\n",
    "@dask.delayed\n",
    "def test_combine(x1,y1,z1,x2,y2,z2,mask1,mask2):\n",
    "    x=np.empty(x1.shape)\n",
    "    y=np.empty(x1.shape)\n",
    "    z=np.empty(x1.shape)\n",
    "    x=np.where(mask1,x1,x)\n",
    "    x=np.where(mask2,x2,x)\n",
    "    y=np.where(mask1,y1,y)\n",
    "    y=np.where(mask2,y2,y)\n",
    "    z=np.where(mask1,z1,z)\n",
    "    z=np.where(mask2,z2,z)        \n",
    "    return x,y,z\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ndays=5\n",
    "x_arr=np.ones((ndays,2,2),dtype='float32')\n",
    "y_arr=np.zeros((ndays,2,2),dtype='float32')\n",
    "z_arr=y_arr-1\n",
    "\n",
    "X=np.empty(x_arr.shape)\n",
    "Y=np.empty(y_arr.shape)\n",
    "Z=np.empty(z_arr.shape)\n",
    "X[:],Y[:],Z[:]=np.nan,np.nan,np.nan\n",
    "\n",
    "# [[1,1],[1,1]]\n",
    "mask1=np.array([[[1,0],[1,1]],[[1,0],[1,1]],[[1,0],[1,1]],[[1,0],[1,1]],[[1,0],[1,1]]])\n",
    "mask2=np.array([[[0,1],[0,0]],[[0,1],[0,0]],[[0,1],[0,0]],[[0,1],[0,0]],[[0,1],[0,0]]])\n",
    "\n",
    "mask1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncats=5\n",
    "for i,cat in enumerate(np.arange(ncats)+1):\n",
    "    print(i,cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list=[]\n",
    "for doy in range(ndays):\n",
    "    # task=test_func1(x_arr,y_arr,z_arr,X,Y,Z,mask1)\n",
    "    # task_list.append(task)\n",
    "    X,Y,Z=test_func1(x_arr,y_arr,z_arr,X,Y,Z,mask1)\n",
    "    # task=test_func1(x_arr,y_arr,z_arr,X,Y,Z,mask2)\n",
    "    # task_list.append(task)\n",
    "    # task=test_combine()\n",
    "    # print(task_list)\n",
    "    # output=dask.compute(*task_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output)\n",
    "output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list=[]\n",
    "for doy in range(ndays):\n",
    "    # out1,out2,out3=test_func1(x_arr,y_arr,z_arr)\n",
    "    task=test_func1(x_arr,y_arr,z_arr)\n",
    "    # task=test_func2(out1,out2,out3)\n",
    "    # task_list.append(task)\n",
    "    output=task.compute()\n",
    "    x_arr=output[0]\n",
    "    y_arr=output[1]\n",
    "    z_arr=output[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=dask.compute(*task_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized+parallel: expect ~66 seconds run time for china\n",
    "# vectorized: expect ~1.5 minutes run time for china\n",
    "# non-vectorized: expect ~6 minutes run time for china\n",
    "start=timer()\n",
    "\n",
    "lgp = clim_reg.getLGP(Sa=100., D=1.)\n",
    "lgp_class = clim_reg.getLGPClassified(lgp)\n",
    "lgp_equv = clim_reg.getLGPEquivalent()\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "# fig = plt.figure(figsize=(20, 4))\n",
    "fig = plt.figure()\n",
    "# fig = plt.figure(figsize=(10, 8),dpi=600)\n",
    "plt.subplot(121)\n",
    "plt.imshow(lgp, cmap='viridis', vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGP [days]')\n",
    "plt.colorbar(shrink=0.8)\n",
    "# plt.savefig(out_path+\"LGP_\"+revname+\".png\", bbox_inches=\"tight\", dpi=600)\n",
    "# plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=(20, 8),dpi=600)\n",
    "plt.subplot(122)\n",
    "plt.imshow(lgp_equv, cmap='viridis', vmin=0, vmax=366,interpolation='none')\n",
    "plt.title('LGP Equivalent [days]')\n",
    "plt.colorbar(shrink=0.8)\n",
    "# plt.savefig(out_path+\"LGP_Equv_\"+revname+\".png\",bbox_inches=\"tight\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(out_path+\"LGP_and_LGP_Equv_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'LGP_'+revname+'.tif', lgp)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'LGPEquivalent_'+revname+'.tif', lgp_equv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Cropping Zone\n",
    "Multiple cropping zones classification is an additional agro-climatic indicator, which relates to the possibility of cultivating multiple sequential crops under rain-fed and irrigated conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~1.5 minutes run time for china\n",
    "start=timer()\n",
    "\n",
    "multi_crop = clim_reg.getMultiCroppingZones(tclimate, lgp, lgpt5, lgpt10, tsum0, tsum10)\n",
    "multi_crop_rainfed = multi_crop[0]  # for rainfed conditions\n",
    "multi_crop_irr = multi_crop[1]  # for irrigated conditions\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(multi_crop_irr, cmap=plt.get_cmap('gist_ncar_r', 9), vmin=-0.2, vmax=8.4,interpolation='none')\n",
    "plt.title('Multi Cropping Zone - IRR')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"multicrop_irr_\"+revname+\".png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(multi_crop_rainfed,cmap=plt.get_cmap('gist_ncar_r', 9), vmin=-0.2, vmax=8.4,interpolation='none')\n",
    "plt.title('Multi Cropping Zone - RAINFED')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"multicrop_rain_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'multicrop_irr_'+revname+'.tif', multi_crop_irr)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'multicrop_rain_'+revname+'.tif', multi_crop_rainfed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Air Frost Index and Permafrost Evaluation\n",
    "Occurrence of continuous or discontinuous permafrost conditions are used in the suitability assessment. Permafrost areas are characterized by sub-soil at or below the freezing point for two or more years. In this section, PyAEZ utilizes the air frost index (FI) which is used to characterize climate-derived permafrost condition into 4 classes: \n",
    "1) Continuous permafrost\n",
    "2) Discontinuous permafrost \n",
    "3) Sporadic permafrost\n",
    "4) No permafrost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# non-vectorized: expect ~2 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "permafrost_eval = clim_reg.AirFrostIndexandPermafrostEvaluation()\n",
    "frost_index = permafrost_eval[0]\n",
    "permafrost = permafrost_eval[1]\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(frost_index, cmap=plt.get_cmap('tab20b', 11), vmin=-0.05, vmax=1.05,interpolation='none')\n",
    "plt.title('Frost Index')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"frost_index_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(permafrost, cmap=plt.get_cmap('tab20b', 5), vmin=-0.5, vmax=4.3,interpolation='none')\n",
    "plt.title('Permafrost Evaluation')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"permafrost_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'frost_index_'+revname+'.tif', frost_index)\n",
    "obj_utilities.saveRaster(mask_path, out_path+'permafrost_'+revname+'.tif', permafrost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fallow period requirement\n",
    "Fallow is an agricultural technique that consists of not sowing the arable land during one or more growing seasons. In AEZ framework, the fallow factors have been established by main crop groups and environmental conditions. The crop groups include cereals, legumes, roots and tubers, and a miscellaneous group consisting of long-term annuals/perennials. The fallow factors are expressed as percentage of time during the fallow-cropping cycle the land must be under fallow. PyAEZ determines the fallow requirements using Thermal Zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expect >1s run time for china\n",
    "# expect ~15 seconds run time for china\n",
    "start=timer()\n",
    "\n",
    "tzone_fallow = clim_reg.TZoneFallowRequirement(tzone)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''save and visualize result'''\n",
    "fig = plt.figure()\n",
    "plt.imshow(tzone_fallow, cmap=plt.get_cmap('tab10', 7), vmin=-0.5, vmax=6.3,interpolation='none')\n",
    "plt.title('Fallow Requirement')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"fallow_\"+revname+\".png\",bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'fallow_'+revname+'.tif', tzone_fallow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dtypes of all outputs\n",
    "outputs=[tclimate,tzone,lgpt0,lgpt5,lgpt10,tsum0,tsum5,tsum10,tprofile,lgp,lgp_class,lgp_equv,multi_crop_rainfed,multi_crop_irr,frost_index,permafrost,tzone_fallow]\n",
    "dtypes=[]\n",
    "for var in outputs:\n",
    "    # for arrays\n",
    "    try:\n",
    "        dt=var.dtype\n",
    "        dtypes.append(dt)\n",
    "    # for lists of arrays\n",
    "    except:\n",
    "        for v in var:\n",
    "            dt=v.dtype\n",
    "            dtypes.append(dt)\n",
    "\n",
    "print(dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agro-ecological zones classification\n",
    "The agro-ecological zones (AEZ) methodology provides a framework for establishing a spatial inventory of land resources compiled from global/national environmental data sets and assembled to quantify multiple spatial characteristics required for the assessments of land productivity under location-specific agro-ecological conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't run until we have the global soil_terrain_lulc\n",
    "\n",
    "# expect ~ minutes run time for global\n",
    "start=timer()\n",
    "\n",
    "aez = clim_reg.AEZClassification(\n",
    "    tclimate, lgp, lgp_equv, lgpt5, soil_terrain_lulc, permafrost)\n",
    "\n",
    "task_time=timer()-start\n",
    "task_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now visualizing result\n",
    "fig = plt.figure(dpi=600)\n",
    "plt.imshow(aez, cmap=plt.get_cmap('rainbow', 59), vmin=0, vmax=59,interpolation=None)\n",
    "plt.title('Agro-ecological Zonation')\n",
    "plt.colorbar()\n",
    "plt.savefig(out_path+\"aez_\"+revname+\".png\",bbox_inches=\"tight\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "obj_utilities.saveRaster(mask_path, out_path+'aez_'+revname+'.tif', aez)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### END OF MODULE 1: CLIMATE REGIME\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('pyaez_dask')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3cfdac6d9beea2e0b9985b5f9686869f04de34e5c7e3af03011a3e37a4b3d272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
